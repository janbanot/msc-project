{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMTkX9iHc9WWb2CMTO575k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/msc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N9kkURRXxcaG"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers datasets captum quantus accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "id": "rnzL_6SCy5qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7bbe3ea"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = '/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv'\n",
        "try:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(\"CSV file loaded successfully!\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file was not found at {csv_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(example):\n",
        "    \"\"\"Applies all cleaning steps to the 'comment_text' field.\"\"\"\n",
        "\n",
        "    # 1. Get the text\n",
        "    text = example['comment_text']\n",
        "\n",
        "    # 2. Lowercasing\n",
        "    # This is crucial for \"uncased\" BERT models\n",
        "    text = text.lower()\n",
        "\n",
        "    # 3. Remove URLs\n",
        "    # re.sub finds a pattern and replaces it\n",
        "    # r'http\\S+' finds 'http' followed by any non-space characters\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "\n",
        "    # 4. Remove IP Addresses\n",
        "    # \\d{1,3} means \"a digit, 1-to-3 times\". \\. means \"a literal dot\".\n",
        "    text = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', '', text)\n",
        "\n",
        "    # 5. Remove Wikipedia metadata like (talk), timestamps, etc.\n",
        "    # This is a simple regex to find things like (talk)\n",
        "    # You could make this more complex, but this is a good start.\n",
        "    text = re.sub(r'\\(talk\\)', '', text)\n",
        "    text = re.sub(r'\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)', '', text)\n",
        "\n",
        "    # 6. Remove newlines and other special characters\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('\\xa0', ' ')\n",
        "\n",
        "    # 7. Remove any text inside double quotes at the start/end\n",
        "    # This removes things like '\"\\n\\n ' from the beginning\n",
        "    text = text.strip(' \"')\n",
        "\n",
        "    # 8. Clean up whitespace\n",
        "    # \\s+ means \"one or more space characters\"\n",
        "    # We replace any group of spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # 9. Update the example\n",
        "    example['comment_text'] = text\n",
        "    return example"
      ],
      "metadata": {
        "id": "Baob8jOTYaBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "train_df = df.head(2000)\n",
        "data = datasets.Dataset.from_pandas(train_df)"
      ],
      "metadata": {
        "id": "XMcBMwOZZOYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaning data...\")\n",
        "cleaned_data = data.map(clean_text)\n",
        "print(\"Data cleaned!\")"
      ],
      "metadata": {
        "id": "1XSauFnTY4GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- BEFORE CLEANING ---\")\n",
        "print(data[1]['comment_text'])\n",
        "print(\"\\n\" + data[6]['comment_text'])\n",
        "print(\"\\n\" + data[0]['comment_text'])\n",
        "\n",
        "print(\"\\n\\n--- AFTER CLEANING ---\")\n",
        "print(cleaned_data[1]['comment_text'])\n",
        "print(\"\\n\" + cleaned_data[6]['comment_text'])\n",
        "print(\"\\n\" + cleaned_data[0]['comment_text'])"
      ],
      "metadata": {
        "id": "3Eij-Oi0ZTkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# This is the \"model card\" for the model\n",
        "# 'uncased' matches the .lower() step we did earlier.\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "\n",
        "try:\n",
        "    # This downloads and caches the tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    print(\"Tokenizer loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")"
      ],
      "metadata": {
        "id": "IdmXlYxUczCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    \"\"\"Applies the tokenizer to a batch of text.\"\"\"\n",
        "\n",
        "    # This is the main tokenization step.\n",
        "    # padding=\"max_length\" fills short comments with [PAD] tokens.\n",
        "    # truncation=True cuts off comments that are too long.\n",
        "    # max_length=256 is a good balance of speed and context for comments.\n",
        "    # You could use 512 (DistilBERT's max) but it's slower.\n",
        "    return tokenizer(\n",
        "        examples[\"comment_text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "# Apply the function with .map()\n",
        "# batched=True makes it MUCH faster by tokenizing many texts at once.\n",
        "print(\"\\nTokenizing data...\")\n",
        "tokenized_data = cleaned_data.map(tokenize_function, batched=True)\n",
        "print(\"Data tokenized!\")"
      ],
      "metadata": {
        "id": "7di3UMZHdB1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Example of a Tokenized Entry ---\")\n",
        "print(tokenized_data[0])"
      ],
      "metadata": {
        "id": "Mn-sppLedLSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Define your label columns in the correct order\n",
        "label_columns = [\n",
        "    'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'\n",
        "]\n",
        "\n",
        "def create_labels_column(example):\n",
        "    \"\"\"\n",
        "    Creates a new 'labels' column by combining the 6 label columns.\n",
        "    We convert them to float32, which is what ML models expect.\n",
        "    \"\"\"\n",
        "    # For each example, build a list of its label values\n",
        "    labels_list = [float(example[col]) for col in label_columns]\n",
        "    example['labels'] = labels_list\n",
        "    return example\n",
        "\n",
        "# 2. Apply the function\n",
        "print(\"\\nConsolidating labels...\")\n",
        "final_data = tokenized_data.map(create_labels_column)\n",
        "print(\"Labels consolidated!\")\n",
        "\n",
        "# 3. Let's see the result for a toxic comment\n",
        "print(\"\\n--- Example of a Processed Entry ---\")\n",
        "print(final_data[6])"
      ],
      "metadata": {
        "id": "c8F9I2V2d-I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. List all columns we want to remove\n",
        "columns_to_remove = [\n",
        "    'id', 'comment_text', 'toxic', 'severe_toxic',\n",
        "    'obscene', 'threat', 'insult', 'identity_hate'\n",
        "]\n",
        "\n",
        "# The '_' at the end means it modifies the dataset \"in-place\"\n",
        "print(f\"\\nOriginal columns: {final_data.column_names}\")\n",
        "final_data = final_data.remove_columns(columns_to_remove)\n",
        "print(f\"Cleaned columns: {final_data.column_names}\")\n",
        "\n",
        "# 2. Set the dataset format to \"torch\" (for PyTorch)\n",
        "try:\n",
        "    final_data.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "    print(\"\\nDataset format set to 'torch'!\")\n",
        "except ImportError:\n",
        "    print(\"\\nPyTorch not installed. Skipping .set_format('torch').\")\n",
        "    print(\"Please install with: pip install torch\")\n",
        "\n",
        "# Let's check the final, final output\n",
        "print(\"\\n--- Final, Model-Ready Item ---\")\n",
        "print(final_data[6])"
      ],
      "metadata": {
        "id": "GdvRwT_leOM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 6 # 6 toxic categories\n",
        "\n",
        "# Load the model, configuring it for multi-label classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    num_labels=num_labels,\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(\"Model configured for multi-label classification.\")"
      ],
      "metadata": {
        "id": "RY2kk5asekT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_splits = final_data.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_dataset = data_splits['train']\n",
        "eval_dataset = data_splits['test']\n",
        "\n",
        "print(f\"\\nData split complete:\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Evaluation samples: {len(eval_dataset)}\")"
      ],
      "metadata": {
        "id": "7EUdT7kYeyof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    # p.predictions are the raw logit outputs\n",
        "    # p.label_ids are the true labels\n",
        "\n",
        "    # First, apply sigmoid to logits to get probabilities\n",
        "    logits = p.predictions\n",
        "    probs = 1 / (1 + np.exp(-logits)) # Sigmoid function\n",
        "\n",
        "    # Next, set a threshold (0.5) to get binary predictions\n",
        "    threshold = 0.5\n",
        "    predictions = (probs > threshold).astype(int)\n",
        "\n",
        "    # Now, compute the metrics\n",
        "    labels = p.label_ids\n",
        "\n",
        "    # We'll use 'micro' averaging, which is good for imbalanced labels\n",
        "    f1_micro = f1_score(labels, predictions, average='micro')\n",
        "\n",
        "    # This measures how many individual labels (out of 6*num_samples) were correct\n",
        "    overall_accuracy = accuracy_score(labels.flatten(), predictions.flatten())\n",
        "\n",
        "    # Return metrics as a dictionary\n",
        "    return {\n",
        "        'f1_micro': f1_micro,\n",
        "        'accuracy': overall_accuracy\n",
        "    }"
      ],
      "metadata": {
        "id": "NX52g5ElfBO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "model_output_dir = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-finetuned\"\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_output_dir,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    # helps prevent overfitting\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_micro\",\n",
        "    # DISABLE WANDB\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "Gd4r8HXrfO8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    # We pass this so it can create batches correctly\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Training ---\")\n",
        "# This one line does all the work!\n",
        "trainer.train()\n",
        "print(\"--- Training Complete ---\")"
      ],
      "metadata": {
        "id": "hgN5hlo3fowE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}