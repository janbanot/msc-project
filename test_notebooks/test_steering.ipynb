{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test_steering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_config"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 1. IMPORTS & KONFIGURACJA\n",
        "# ===================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from datasets import Dataset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "\n",
        "# Parametry eksperymentu\n",
        "ALPHA_VALUES = [-1.0, -3.0, -5.0]  # Trzy warto≈õci alpha do por√≥wnania\n",
        "N_SAMPLES_PER_CLASS = 25  # Liczba przyk≈Çad√≥w na klasƒô\n",
        "TARGET_LAYER_INDEX = 5  # Warstwa do interwencji\n",
        "CLASSIFICATION_THRESHOLD = 0.5  # Pr√≥g klasyfikacji\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "# ≈öcie≈ºki (dostosuj do swojego ≈õrodowiska)\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260125_133112\"\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RESULTS_DIR = f\"/drive/MyDrive/msc-project/steering_test_{TIMESTAMP}\"\n",
        "\n",
        "# UrzƒÖdzenie\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Uruchomiono na: {device}\")\n",
        "\n",
        "# Tworzenie katalogu wynik√≥w\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(f\"Wyniki zostanƒÖ zapisane w: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_model_data"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2. FUNKCJE POMOCNICZE (z oryginalnego test.ipynb)\n",
        "# ===================================================\n",
        "\n",
        "def clean_text(example):\n",
        "    \"\"\"Czy≈õci tekst komentarza.\"\"\"\n",
        "    text = example[\"comment_text\"]\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    example[\"comment_text\"] = text\n",
        "    return example\n",
        "\n",
        "\n",
        "def prepare_environment():\n",
        "    \"\"\"Wczytuje dane, tokenizuje i ≈Çaduje model.\"\"\"\n",
        "    print(\">>> Wczytywanie i przetwarzanie danych...\")\n",
        "\n",
        "    # Wczytanie danych\n",
        "    df = pd.read_csv(DATA_PATH).head(10000)  # Wiƒôcej danych dla lepszego wektora\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "    dataset = dataset.map(clean_text)\n",
        "\n",
        "    # Tokenizer\n",
        "    print(f\">>> ≈Åadowanie tokenizera z: {MODEL_CHECKPOINT}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "    # Tokenizacja\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples[\"comment_text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Etykiety\n",
        "    def create_labels(example):\n",
        "        example[\"labels\"] = [float(example[\"toxic\"])]\n",
        "        return example\n",
        "\n",
        "    final_dataset = tokenized_dataset.map(create_labels)\n",
        "    final_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "    # Podzia≈Ç\n",
        "    splits = final_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "    eval_dataset = splits[\"test\"]\n",
        "\n",
        "    # Model\n",
        "    print(f\">>> ≈Åadowanie modelu z: {MODEL_CHECKPOINT}\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT, num_labels=1, problem_type=\"single_label_classification\"\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\">>> ≈örodowisko gotowe.\")\n",
        "    return model, tokenizer, eval_dataset\n",
        "\n",
        "\n",
        "# Inicjalizacja\n",
        "model, tokenizer, eval_dataset = prepare_environment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_vector_calculation"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3. OBLICZANIE WEKTORA STERUJƒÑCEGO Z SZCZEG√ì≈ÅOWYMI LOGAMI\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n=== 3. OBLICZANIE WEKTORA STERUJƒÑCEGO ===\")\n",
        "\n",
        "# Wyb√≥r pr√≥bek do obliczenia wektora (u≈ºywamy wiƒôcej pr√≥bek dla stabilno≈õci)\n",
        "N_SAMPLES_VECTOR = 1000\n",
        "subset_indices = list(range(min(N_SAMPLES_VECTOR, len(eval_dataset))))\n",
        "subset = eval_dataset.select(subset_indices)\n",
        "\n",
        "print(f\"Liczba pr√≥bek do obliczenia wektora: {len(subset)}\")\n",
        "\n",
        "# Ekstrakcja aktywacji z warstwy TARGET_LAYER_INDEX\n",
        "layers_data = {TARGET_LAYER_INDEX: []}\n",
        "all_labels = []\n",
        "\n",
        "loader = torch.utils.data.DataLoader(subset, batch_size=32)\n",
        "\n",
        "print(f\"Ekstrakcja aktywacji z warstwy {TARGET_LAYER_INDEX}...\")\n",
        "for batch in loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    mask = batch[\"attention_mask\"].to(device)\n",
        "    labels = batch[\"labels\"][:, 0].cpu().numpy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(input_ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "    all_labels.extend(labels)\n",
        "    # Token [CLS] (indeks 0)\n",
        "    layers_data[TARGET_LAYER_INDEX].append(out.hidden_states[TARGET_LAYER_INDEX][:, 0, :].cpu().numpy())\n",
        "\n",
        "# Po≈ÇƒÖczenie aktywacji\n",
        "X = np.concatenate(layers_data[TARGET_LAYER_INDEX], axis=0)\n",
        "y = np.array(all_labels)\n",
        "y_bin = (y > CLASSIFICATION_THRESHOLD).astype(int)\n",
        "\n",
        "print(f\"\\nStatystyki pr√≥bek:\")\n",
        "print(f\"  - Toksyczne: {np.sum(y_bin == 1)}\")\n",
        "print(f\"  - Bezpieczne: {np.sum(y_bin == 0)}\")\n",
        "print(f\"  - Kszta≈Çt aktywacji: {X.shape}\")\n",
        "\n",
        "# Obliczenie wektora sterujƒÖcego (Difference of Means)\n",
        "toxic_vecs = X[y_bin == 1]\n",
        "safe_vecs = X[y_bin == 0]\n",
        "\n",
        "mean_toxic = np.mean(toxic_vecs, axis=0)\n",
        "mean_safe = np.mean(safe_vecs, axis=0)\n",
        "direction = mean_toxic - mean_safe\n",
        "\n",
        "print(f\"\\n=== STATYSTYKI WEKTORA STERUJƒÑCEGO ===\")\n",
        "print(f\"Kszta≈Çt wektora: {direction.shape}\")\n",
        "print(f\"Mean: {np.mean(direction):.6f}\")\n",
        "print(f\"Std: {np.std(direction):.6f}\")\n",
        "print(f\"Min: {np.min(direction):.6f}\")\n",
        "print(f\"Max: {np.max(direction):.6f}\")\n",
        "print(f\"L2 Norm: {np.linalg.norm(direction):.6f}\")\n",
        "\n",
        "# Top-10 najwiƒôkszych element√≥w wektora\n",
        "top_indices = np.argsort(np.abs(direction))[-10:][::-1]\n",
        "print(f\"\\nTop-10 najwiƒôkszych element√≥w wektora (indeks | warto≈õƒá):\")\n",
        "for idx in top_indices:\n",
        "    print(f\"  [{idx:4d}] {direction[idx]:.6f}\")\n",
        "\n",
        "# Zapis wektora do pliku\n",
        "steering_tensor = torch.tensor(direction, dtype=torch.float32).to(device)\n",
        "np.save(f\"{RESULTS_DIR}/steering_vector.npy\", direction)\n",
        "print(f\"\\nWektor zapisany do: {RESULTS_DIR}/steering_vector.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_hook_class"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4. KLASA HOOK DO STEROWANIA\n",
        "# ===================================================\n",
        "\n",
        "class SteeringHook:\n",
        "    \"\"\"\n",
        "    PyTorch hook modyfikujƒÖcy hidden states poprzez dodanie wektora sterujƒÖcego.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vector, coeff):\n",
        "        self.vector = vector\n",
        "        self.coeff = coeff\n",
        "\n",
        "    def __call__(self, module, inputs, output):\n",
        "        is_tuple = isinstance(output, tuple)\n",
        "        hidden_states = output[0] if is_tuple else output\n",
        "        steering_vector = self.vector.to(hidden_states.device, dtype=hidden_states.dtype)\n",
        "        modified_hidden = hidden_states + (self.coeff * steering_vector)\n",
        "\n",
        "        if is_tuple:\n",
        "            return (modified_hidden,) + output[1:]\n",
        "        else:\n",
        "            return modified_hidden\n",
        "\n",
        "print(\">>> SteeringHook zdefiniowany.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_function_detailed"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 5. FUNKCJA TESTOWANIA Z SZCZEG√ì≈ÅOWYMI LOGAMI\n",
        "# ===================================================\n",
        "\n",
        "def test_steering_with_detailed_logs(model, tokenizer, dataset, steering_vector, alpha_value):\n",
        "    \"\"\"\n",
        "    Testuje steering dla danej warto≈õci alpha i zwraca szczeg√≥≈Çowe wyniki.\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z wynikami dla ka≈ºdego przyk≈Çadu\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TESTOWANIE Z ALPHA = {alpha_value}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Wyb√≥r pr√≥bek do testowania\n",
        "    toxic_indices = [i for i, label in enumerate(dataset[\"labels\"]) if label[0] == 1][:N_SAMPLES_PER_CLASS]\n",
        "    safe_indices = [i for i, label in enumerate(dataset[\"labels\"]) if label[0] == 0][:N_SAMPLES_PER_CLASS]\n",
        "\n",
        "    print(f\"Pr√≥bki do testowania:\")\n",
        "    print(f\"  - Toksyczne: {len(toxic_indices)}\")\n",
        "    print(f\"  - Bezpieczne: {len(safe_indices)}\")\n",
        "\n",
        "    # Modu≈Ç warstwy do interwencji\n",
        "    layer_module = model.distilbert.transformer.layer[TARGET_LAYER_INDEX]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # === TEST TOKSYCZNYCH PR√ìBEK ===\n",
        "    print(f\"\\n--- TEST TOKSYCZNYCH PR√ìBEK (cel: detoksykacja) ---\")\n",
        "    handle = layer_module.register_forward_hook(SteeringHook(steering_vector, alpha_value))\n",
        "\n",
        "    for idx in toxic_indices:\n",
        "        input_ids = dataset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        mask = dataset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "\n",
        "        # Prawdopodobie≈Ñstwo przed steering\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask)\n",
        "            prob_before = torch.sigmoid(out.logits)[0, 0].item()\n",
        "\n",
        "        # Prawdopodobie≈Ñstwo po steering (z hook)\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask)\n",
        "            prob_after = torch.sigmoid(out.logits)[0, 0].item()\n",
        "\n",
        "        delta = prob_after - prob_before\n",
        "        success = prob_after < CLASSIFICATION_THRESHOLD\n",
        "        status = \"‚úì SUCCESS\" if success else \"‚úó FAILED\"\n",
        "\n",
        "        # Oryginalny tekst\n",
        "        text = tokenizer.decode(dataset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "        text_short = text[:80] + \"...\" if len(text) > 80 else text\n",
        "\n",
        "        results.append({\n",
        "            \"text\": text,\n",
        "            \"label\": \"TOXIC\",\n",
        "            \"alpha\": alpha_value,\n",
        "            \"prob_before\": prob_before,\n",
        "            \"prob_after\": prob_after,\n",
        "            \"delta\": delta,\n",
        "            \"status\": \"SUCCESS\" if success else \"FAILED\"\n",
        "        })\n",
        "\n",
        "        print(f\"Tok #{idx:4d} | {status:8s} | Prob: {prob_before:.3f} ‚Üí {prob_after:.3f} ({delta:+.3f})\")\n",
        "        print(f\"           Text: \\\"{text_short}\\\"\")\n",
        "\n",
        "    handle.remove()\n",
        "\n",
        "    # === TEST BEZPIECZNYCH PR√ìBEK ===\n",
        "    print(f\"\\n--- TEST BEZPIECZNYCH PR√ìBEK (cel: brak efekt√≥w ubocznych) ---\")\n",
        "    handle = layer_module.register_forward_hook(SteeringHook(steering_vector, alpha_value))\n",
        "\n",
        "    for idx in safe_indices:\n",
        "        input_ids = dataset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        mask = dataset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "\n",
        "        # Prawdopodobie≈Ñstwo przed steering\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask)\n",
        "            prob_before = torch.sigmoid(out.logits)[0, 0].item()\n",
        "\n",
        "        # Prawdopodobie≈Ñstwo po steering (z hook)\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask)\n",
        "            prob_after = torch.sigmoid(out.logits)[0, 0].item()\n",
        "\n",
        "        delta = prob_after - prob_before\n",
        "        side_effect = prob_after > CLASSIFICATION_THRESHOLD\n",
        "        status = \"‚úó SIDE-EFFECT\" if side_effect else \"‚úì OK\"\n",
        "\n",
        "        # Oryginalny tekst\n",
        "        text = tokenizer.decode(dataset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "        text_short = text[:80] + \"...\" if len(text) > 80 else text\n",
        "\n",
        "        results.append({\n",
        "            \"text\": text,\n",
        "            \"label\": \"SAFE\",\n",
        "            \"alpha\": alpha_value,\n",
        "            \"prob_before\": prob_before,\n",
        "            \"prob_after\": prob_after,\n",
        "            \"delta\": delta,\n",
        "            \"status\": \"SIDE-EFFECT\" if side_effect else \"OK\"\n",
        "        })\n",
        "\n",
        "        print(f\"Safe #{idx:4d} | {status:8s} | Prob: {prob_before:.3f} ‚Üí {prob_after:.3f} ({delta:+.3f})\")\n",
        "        print(f\"            Text: \\\"{text_short}\\\"\")\n",
        "\n",
        "    handle.remove()\n",
        "\n",
        "    # Obliczenie wska≈∫nik√≥w\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    toxic_results = df[df[\"label\"] == \"TOXIC\"]\n",
        "    safe_results = df[df[\"label\"] == \"SAFE\"]\n",
        "\n",
        "    success_rate = (toxic_results[\"status\"] == \"SUCCESS\").sum() / len(toxic_results) * 100\n",
        "    side_effect_rate = (safe_results[\"status\"] == \"SIDE-EFFECT\").sum() / len(safe_results) * 100\n",
        "    avg_delta_toxic = toxic_results[\"delta\"].mean()\n",
        "    avg_delta_safe = safe_results[\"delta\"].mean()\n",
        "\n",
        "    print(f\"\\n=== PODSUMOWANIE ALPHA = {alpha_value} ===\")\n",
        "    print(f\"Success Rate (detoksykacja):   {success_rate:.2f}% ({(toxic_results['status'] == 'SUCCESS').sum()}/{len(toxic_results)})\")\n",
        "    print(f\"Side Effect Rate:              {side_effect_rate:.2f}% ({(safe_results['status'] == 'SIDE-EFFECT').sum()}/{len(safe_results)})\")\n",
        "    print(f\"≈örednia delta (toksyczne):     {avg_delta_toxic:+.4f}\")\n",
        "    print(f\"≈örednia delta (bezpieczne):    {avg_delta_safe:+.4f}\")\n",
        "\n",
        "    return df, success_rate, side_effect_rate, avg_delta_toxic, avg_delta_safe\n",
        "\n",
        "print(\">>> Funkcja test_steering_with_detailed_logs zdefiniowana.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_loop"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 6. G≈Å√ìWNA PƒòTLA - TESTOWANIE DLA 3 WARTO≈öCI ALPHA\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ROZPOCZƒòCIE TESTOWANIA STEERINGU DLA R√ì≈ªNYCH WARTO≈öCI ALPHA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_results = []\n",
        "summary_data = []\n",
        "\n",
        "for alpha in ALPHA_VALUES:\n",
        "    df_result, success_rate, side_effect_rate, avg_delta_toxic, avg_delta_safe = test_steering_with_detailed_logs(\n",
        "        model, tokenizer, eval_dataset, steering_tensor, alpha\n",
        "    )\n",
        "    all_results.append(df_result)\n",
        "    summary_data.append({\n",
        "        \"alpha\": alpha,\n",
        "        \"success_rate\": success_rate,\n",
        "        \"side_effect_rate\": side_effect_rate,\n",
        "        \"avg_delta_toxic\": avg_delta_toxic,\n",
        "        \"avg_delta_safe\": avg_delta_safe\n",
        "    })\n",
        "\n",
        "    # Zapis wynik√≥w dla tej warto≈õci alpha\n",
        "    df_result.to_csv(f\"{RESULTS_DIR}/results_alpha_{alpha}.csv\", index=False)\n",
        "    print(f\"\\nWyniki zapisane do: {RESULTS_DIR}/results_alpha_{alpha}.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Wszystkie testy zako≈Ñczone.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_summary"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 7. PODSUMOWANIE POR√ìWNAWCZE\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PODSUMOWANIE POR√ìWNAWCZE DLA WSZYSTKICH WARTO≈öCI ALPHA\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "print(df_summary.to_string(index=False))\n",
        "\n",
        "# Zapis podsumowania\n",
        "df_summary.to_csv(f\"{RESULTS_DIR}/summary_comparison.csv\", index=False)\n",
        "print(f\"\\nPodsumowanie zapisane do: {RESULTS_DIR}/summary_comparison.csv\")\n",
        "\n",
        "# Analiza\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANALIZA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, row in df_summary.iterrows():\n",
        "    alpha = row['alpha']\n",
        "    status = \"\"\n",
        "    if row['success_rate'] > 80 and row['side_effect_rate'] < 5:\n",
        "        status = \"‚úÖ OPTIMALNE\"\n",
        "    elif row['success_rate'] > 80:\n",
        "        status = \"‚ö†Ô∏è DOBRA SKUTECZNO≈öƒÜ, WYSOKIE SIDE EFFECTS\"\n",
        "    elif row['side_effect_rate'] < 5:\n",
        "        status = \"‚ö†Ô∏è NISKIE SIDE EFFECTS, S≈ÅABA SKUTECZNO≈öƒÜ\"\n",
        "    else:\n",
        "        status = \"‚ùå WYMAGA DOSTROJENIA\"\n",
        "\n",
        "    print(f\"\\nAlpha = {alpha}: {status}\")\n",
        "    print(f\"  - Success Rate: {row['success_rate']:.2f}% (cel: >80%)\")\n",
        "    print(f\"  - Side Effects:  {row['side_effect_rate']:.2f}% (cel: <5%)\")\n",
        "    print(f\"  - ≈örednia delta (toksyczne):  {row['avg_delta_toxic']:+.4f}\")\n",
        "    print(f\"  - ≈örednia delta (bezpieczne): {row['avg_delta_safe']:+.4f}\")\n",
        "\n",
        "# Znajd≈∫ najlepszƒÖ warto≈õƒá alpha\n",
        "best_idx = df_summary[\n",
        "    (df_summary['success_rate'] > 80) & \n",
        "    (df_summary['side_effect_rate'] < 5)\n",
        "]['success_rate'].idxmax()\n",
        "best_alpha = df_summary.loc[best_idx, 'alpha']\n",
        "\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(f\"REKOMENDACJA: Najlepsza warto≈õƒá alpha = {best_alpha}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "detailed_examples"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 8. PRZYK≈ÅADY SZCZEG√ì≈ÅOWE - PRZED I PO\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SZCZEG√ì≈ÅOWE PRZYK≈ÅADY PRZED I PO STEERINGU\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Po≈ÇƒÖcz wszystkie wyniki\n",
        "df_all = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "# Przyk≈Çady toksyczne przed i po\n",
        "print(\"\\n--- TOKSYCZNE PRZYK≈ÅADY (detoksykacja) ---\")\n",
        "toxic_examples = df_all[df_all['label'] == 'TOXIC'].groupby('text').first().reset_index()\n",
        "\n",
        "print(f\"\\nPrzyk≈Çady z najwiƒôkszƒÖ zmianƒÖ (delta) - Alpha = -3.0:\")\n",
        "top_delta_toxic = df_all[(df_all['label'] == 'TOXIC') & (df_all['alpha'] == -3.0)].nlargest(5, 'delta')\n",
        "\n",
        "for idx, row in top_delta_toxic.iterrows():\n",
        "    print(f\"\\n{'‚îÄ'*70}\")\n",
        "    print(f\"Tekst: \\\"{row['text'][:150]}\\\"\")\n",
        "    print(f\"Prawdopodobie≈Ñstwo przed: {row['prob_before']:.4f}\")\n",
        "    print(f\"Prawdopodobie≈Ñstwo po:    {row['prob_after']:.4f}\")\n",
        "    print(f\"Delta: {row['delta']:+.4f}\")\n",
        "    print(f\"Status: {row['status']}\")\n",
        "\n",
        "# Przyk≈Çady bezpieczne przed i po\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(\"BEZPIECZNE PRZYK≈ÅADY (efekty uboczne)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nPrzyk≈Çady z efektami ubocznymi - Alpha = -3.0:\")\n",
        "side_effects = df_all[(df_all['label'] == 'SAFE') & (df_all['alpha'] == -3.0) & (df_all['status'] == 'SIDE-EFFECT')]\n",
        "\n",
        "if len(side_effects) > 0:\n",
        "    for idx, row in side_effects.iterrows():\n",
        "        print(f\"\\n{'‚îÄ'*70}\")\n",
        "        print(f\"Tekst: \\\"{row['text'][:150]}\\\"\")\n",
        "        print(f\"Prawdopodobie≈Ñstwo przed: {row['prob_before']:.4f}\")\n",
        "        print(f\"Prawdopodobie≈Ñstwo po:    {row['prob_after']:.4f}\")\n",
        "        print(f\"Delta: {row['delta']:+.4f}\")\n",
        "        print(f\"Status: {row['status']} ‚ö†Ô∏è\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ Brak efekt√≥w ubocznych dla alpha = -3.0\")\n",
        "\n",
        "# Por√≥wnanie tego samego tekstu dla r√≥≈ºnych warto≈õci alpha\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(\"POR√ìWNANIE TEGO SAMEGO TEKSTU DLA R√ì≈ªNYCH ALPHA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Wybierz losowy tekst toksyczny\n",
        "if len(df_all[df_all['label'] == 'TOXIC']) > 0:\n",
        "    sample_text = df_all[df_all['label'] == 'TOXIC']['text'].iloc[0]\n",
        "    text_comparison = df_all[df_all['text'] == sample_text][['alpha', 'prob_before', 'prob_after', 'delta', 'status']]\n",
        "    \n",
        "    print(f\"\\nTekst: \\\"{sample_text[:150]}\\\"\")\n",
        "    print(f\"\\nPor√≥wnanie prawdopodobie≈Ñstw przed steering (alpha = 0):\")\n",
        "    print(f\"  Prob: {text_comparison['prob_before'].iloc[0]:.4f}\")\n",
        "    print(f\"\\nPor√≥wnanie prawdopodobie≈Ñstw po steering dla r√≥≈ºnych alpha:\")\n",
        "    for idx, row in text_comparison.iterrows():\n",
        "        print(f\"  Alpha = {row['alpha']:+.1f}: {row['prob_after']:.4f} (delta: {row['delta']:+.4f})\")\n",
        "\n",
        "# Zapis szczeg√≥≈Çowych przyk≈Çad√≥w\n",
        "df_all.to_csv(f\"{RESULTS_DIR}/all_results_detailed.csv\", index=False)\n",
        "print(f\"\\n\\nWszystkie wyniki zapisane do: {RESULTS_DIR}/all_results_detailed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_report"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 9. GENEROWANIE RAPORTU KO≈ÉCOWEGO\n",
        "# ===================================================\n",
        "\n",
        "report = f\"\"\"\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "                    RAPORT Z TESTOWANIA STEERINGU\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "Model: {MODEL_CHECKPOINT}\n",
        "Warstwa: {TARGET_LAYER_INDEX}\n",
        "Pr√≥bki na klasƒô: {N_SAMPLES_PER_CLASS}\n",
        "\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "                          PODSUMOWANIE\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "{df_summary.to_string(index=False)}\n",
        "\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "                         WNIOSKI\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "Warto≈õƒá STEERING_ALPHA zosta≈Ça dobrana eksperymentalnie. Cel to:\n",
        "  - Success Rate > 80% (skuteczna detoksykacja)\n",
        "  - Side Effects < 5% (minimalne fa≈Çszywe alarmy)\n",
        "\n",
        ""\"\n",
        "\n",
        "for idx, row in df_summary.iterrows():\n",
        "    if row['success_rate'] > 80 and row['side_effect_rate'] < 5:\n",
        "        report += f\"Alpha = {row['alpha']:+.1f}: ‚úÖ OPTIMALNE\n\"\n",
        "        report += f\"  - Success Rate: {row['success_rate']:.2f}%\n\"\n",
        "        report += f\"  - Side Effects:  {row['side_effect_rate']:.2f}%\n\n\"\n",
        "    elif row['success_rate'] > 80:\n",
        "        report += f\"Alpha = {row['alpha']:+.1f}: ‚ö†Ô∏è WYSOKIE SIDE EFFECTS ({row['side_effect_rate']:.2f}%)\n\n\"\n",
        "    elif row['side_effect_rate'] < 5:\n",
        "        report += f\"Alpha = {row['alpha']:+.1f}: ‚ö†Ô∏è S≈ÅABA SKUTECZNO≈öƒÜ ({row['success_rate']:.2f}%)\n\n\"\n",
        "    else:\n",
        "        report += f\"Alpha = {row['alpha']:+.1f}: ‚ùå WYMAGA DOSTROJENIA\n\n\"\n",
        "\n",
        "report += f\"\"\"\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "                        PLIKI WYNIK√ìW\n",
        "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "Katalog: {RESULTS_DIR}/\n",
        "\n",
        "  - steering_vector.npy          : Wektor sterujƒÖcy (768-dim)\n",
        "  - summary_comparison.csv       : Por√≥wnanie wszystkich warto≈õci alpha\n",
        "  - all_results_detailed.csv    : Szczeg√≥≈Çowe wyniki dla wszystkich przyk≈Çad√≥w\n",
        "  - results_alpha_-1.0.csv      : Wyniki dla alpha = -1.0\n",
        "  - results_alpha_-3.0.csv      : Wyniki dla alpha = -3.0\n",
        "  - results_alpha_-5.0.csv      : Wyniki dla alpha = -5.0\n",
        "  - steering_report.txt         : Ten raport\n",
        "\n",
        "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\"\"\"\n",
        "\n",
        "# Wy≈õwietlenie raportu\n",
        "print(report)\n",
        "\n",
        "# Zapis raportu\n",
        "with open(f\"{RESULTS_DIR}/steering_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(f\"\\nRaport zapisany do: {RESULTS_DIR}/steering_report.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "file_list"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 10. LISTA WYGENEROWANYCH PLIK√ìW\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WYGENEROWANE PLIKI\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "files = os.listdir(RESULTS_DIR)\n",
        "for f in sorted(files):\n",
        "    file_path = os.path.join(RESULTS_DIR, f)\n",
        "    if os.path.isfile(file_path):\n",
        "        size = os.path.getsize(file_path) / 1024  # KB\n",
        "        print(f\"  üìÑ {f:40s} ({size:8.2f} KB)\")\n",
        "\n",
        "print(f\"\\nüìÅ Katalog wynik√≥w: {RESULTS_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
