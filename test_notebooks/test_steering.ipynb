{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test_steering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports_config"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 1. IMPORTY i KONFIGURACJA\n",
        "# ===================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')\n",
        "\n",
        "# Parametry eksperymentu\n",
        "ALPHA_VALUES = [-10.0, -20.0, -50.0]\n",
        "\n",
        "N_SAMPLES_PER_CLASS = 25  # Liczba przykładów na klasę\n",
        "TARGET_LAYER_INDEX = 3  # Warstwa do interwencji 3 / 5\n",
        "CLASSIFICATION_THRESHOLD = 0.5  # Próg klasyfikacji\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "# Ścieżki (dostosuj do swojego środowiska)\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260125_133112\"\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RESULTS_DIR = f\"/drive/MyDrive/msc-project/steering_test_{TIMESTAMP}\"\n",
        "\n",
        "# Urządzenie\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Uruchomiono na: {device}\")\n",
        "\n",
        "# Tworzenie katalogu wyników\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(f\"Wyniki zostaną zapisane w: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_model_data"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2. FUNKCJE POMOCNICZE (z test.ipynb)\n",
        "# ===================================================\n",
        "\n",
        "def clean_text(example):\n",
        "    \"\"\"Czyści tekst komentarza.\"\"\"\n",
        "    text = example[\"comment_text\"]\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    example[\"comment_text\"] = text\n",
        "    return example\n",
        "\n",
        "\n",
        "def prepare_environment():\n",
        "    \"\"\"Wczytuje dane, tokenizuje i ładuje model.\"\"\"\n",
        "    print(\">>> Wczytywanie i przetwarzanie danych...\")\n",
        "\n",
        "    # Wczytanie danych\n",
        "    df = pd.read_csv(DATA_PATH).head(10000)  # Więcej danych dla lepszego wektora\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "    dataset = dataset.map(clean_text)\n",
        "\n",
        "    # Tokenizer\n",
        "    print(f\">>> Ładowanie tokenizera z: {MODEL_CHECKPOINT}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "    # Tokenizacja\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples[\"comment_text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # Etykiety\n",
        "    def create_labels(example):\n",
        "        example[\"labels\"] = [float(example[\"toxic\"])]\n",
        "        return example\n",
        "\n",
        "    final_dataset = tokenized_dataset.map(create_labels)\n",
        "    final_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "    # Podział\n",
        "    splits = final_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "    eval_dataset = splits[\"test\"]\n",
        "\n",
        "    # Model\n",
        "    print(f\">>> Ładowanie modelu z: {MODEL_CHECKPOINT}\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT, num_labels=1, problem_type=\"single_label_classification\"\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\">>> Środowisko gotowe.\")\n",
        "    return model, tokenizer, eval_dataset\n",
        "\n",
        "\n",
        "# Inicjalizacja\n",
        "model, tokenizer, eval_dataset = prepare_environment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_vector_calculation"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3. OBLICZANIE WEKTORA STERUJĄCEGO\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n=== 3. OBLICZANIE WEKTORA STERUJĄCEGO ===\")\n",
        "\n",
        "# Podział: 800 próbek do wyznaczenia wektora, reszta do testów (brak wycieku danych)\n",
        "N_FOR_VECTOR = 800\n",
        "vector_subset = eval_dataset.select(range(N_FOR_VECTOR))\n",
        "test_subset = eval_dataset.select(range(N_FOR_VECTOR, len(eval_dataset)))\n",
        "\n",
        "print(f\"Próbek do wektora: {len(vector_subset)} | Próbek do testów: {len(test_subset)}\")\n",
        "\n",
        "# Ekstrakcja aktywacji z warstwy TARGET_LAYER_INDEX\n",
        "layers_data = {TARGET_LAYER_INDEX: []}\n",
        "all_labels = []\n",
        "\n",
        "loader = torch.utils.data.DataLoader(vector_subset, batch_size=32)\n",
        "\n",
        "print(f\"Ekstrakcja aktywacji z warstwy {TARGET_LAYER_INDEX}...\")\n",
        "for batch in loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    mask = batch[\"attention_mask\"].to(device)\n",
        "    labels = batch[\"labels\"][:, 0].cpu().numpy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(input_ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "    all_labels.extend(labels)\n",
        "    # Token [CLS] (indeks 0)\n",
        "    layers_data[TARGET_LAYER_INDEX].append(\n",
        "        out.hidden_states[TARGET_LAYER_INDEX][:, 0, :].cpu().numpy()\n",
        "    )\n",
        "\n",
        "# Połączenie aktywacji\n",
        "X = np.concatenate(layers_data[TARGET_LAYER_INDEX], axis=0)\n",
        "y = np.array(all_labels)\n",
        "y_bin = (y > CLASSIFICATION_THRESHOLD).astype(int)\n",
        "\n",
        "print(\"\\nStatystyki próbek:\")\n",
        "print(f\"  - Toksyczne: {np.sum(y_bin == 1)}\")\n",
        "print(f\"  - Bezpieczne: {np.sum(y_bin == 0)}\")\n",
        "print(f\"  - Kształt aktywacji: {X.shape}\")\n",
        "\n",
        "# Obliczenie kierunku\n",
        "mean_toxic = np.mean(X[y_bin == 1], axis=0)\n",
        "mean_safe = np.mean(X[y_bin == 0], axis=0)\n",
        "direction = mean_toxic - mean_safe\n",
        "\n",
        "print(\"\\n=== STATYSTYKI WEKTORA PRZED NORMALIZACJĄ ===\")\n",
        "print(f\"Kształt wektora: {direction.shape}\")\n",
        "print(f\"Mean: {np.mean(direction):.6f}\")\n",
        "print(f\"Std: {np.std(direction):.6f}\")\n",
        "print(f\"Min: {np.min(direction):.6f}\")\n",
        "print(f\"Max: {np.max(direction):.6f}\")\n",
        "print(f\"L2 Norm: {np.linalg.norm(direction):.6f}\")\n",
        "\n",
        "# --- NORMALIZACJA L2 ---\n",
        "# Dzięki temu alpha będzie oznaczać \"o ile jednostek odchylenia standardowego/normy przesuwamy aktywacje\"\n",
        "direction_normed = direction / np.linalg.norm(direction)\n",
        "\n",
        "print(\"\\n=== STATYSTYKI WEKTORA PO NORMALIZACJI L2 ===\")\n",
        "print(f\"Nowa norma L2: {np.linalg.norm(direction_normed):.6f}\")\n",
        "\n",
        "# Top-10 największych elementów wektora\n",
        "top_indices = np.argsort(np.abs(direction_normed))[-10:][::-1]\n",
        "print(\"\\nTop-10 największych elementów wektora (indeks | wartość):\")\n",
        "for idx in top_indices:\n",
        "    print(f\"  [{idx:4d}] {direction_normed[idx]:.6f}\")\n",
        "\n",
        "# Zapis wektora do pliku\n",
        "steering_tensor = torch.tensor(direction_normed, dtype=torch.float32).to(device)\n",
        "np.save(f\"{RESULTS_DIR}/steering_vector.npy\", direction_normed)\n",
        "print(f\"\\nWektor znormalizowany. Nowa norma L2: {np.linalg.norm(direction_normed):.2f}\")\n",
        "print(f\"Wektor zapisany do: {RESULTS_DIR}/steering_vector.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_hook_class"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4. KLASA HOOK DO STEROWANIA\n",
        "# ===================================================\n",
        "\n",
        "class SteeringHook:\n",
        "    \"\"\"\n",
        "    PyTorch hook modyfikujący hidden states poprzez dodanie wektora sterującego.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vector, coeff):\n",
        "        self.vector = vector\n",
        "        self.coeff = coeff\n",
        "\n",
        "    def __call__(self, module, inputs, output):\n",
        "        is_tuple = isinstance(output, tuple)\n",
        "        hidden_states = output[0] if is_tuple else output\n",
        "        steering_vector = self.vector.to(hidden_states.device, dtype=hidden_states.dtype)\n",
        "        modified_hidden = hidden_states + (self.coeff * steering_vector)\n",
        "\n",
        "        if is_tuple:\n",
        "            return (modified_hidden,) + output[1:]\n",
        "        else:\n",
        "            return modified_hidden\n",
        "\n",
        "print(\">>> SteeringHook zdefiniowany.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_function_detailed"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 5. FUNKCJA TESTOWANIA - WERSJA Z RANKINGIEM PEWNOŚCI\n",
        "# ===================================================\n",
        "\n",
        "def test_steering_with_detailed_logs(\n",
        "    model, tokenizer, dataset, steering_vector, alpha_value\n",
        "):\n",
        "    print(f\"\\n{'='*30}\")\n",
        "    print(f\"TESTOWANIE ALPHA = {alpha_value}\")\n",
        "    print(f\"{'='*30}\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # --- KROK 1: INTELIGENTNY WYBÓR PRÓBEK (RANKING) ---\n",
        "    print(\">>> Analizowanie bazy próbek dla testu...\")\n",
        "    all_scores = []\n",
        "\n",
        "    # Sprawdzamy pierwsze 300 próbek z test_subset, żeby znaleźć najlepszych kandydatów\n",
        "    search_range = min(300, len(dataset))\n",
        "    for i in range(search_range):\n",
        "        input_ids = dataset[i][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        mask = dataset[i][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        label = dataset[i][\"labels\"][0].item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, attention_mask=mask).logits\n",
        "            prob = torch.sigmoid(logits)[0, 0].item()\n",
        "\n",
        "        all_scores.append({'idx': i, 'prob': prob, 'label': label})\n",
        "\n",
        "    # Wybieramy 25 toksycznych, które model uważa za NAJBARDZIEJ toksyczne (Label 1, najwyższe Prob)\n",
        "    toxic_candidates = [x for x in all_scores if x['label'] == 1]\n",
        "    toxic_indices = [x['idx'] for x in sorted(toxic_candidates, key=lambda x: x['prob'], reverse=True)[:N_SAMPLES_PER_CLASS]]\n",
        "\n",
        "    # Wybieramy 25 bezpiecznych, które model uważa za NAJMNIEJ toksyczne (Label 0, najniższe Prob)\n",
        "    safe_candidates = [x for x in all_scores if x['label'] == 0]\n",
        "    safe_indices = [x['idx'] for x in sorted(safe_candidates, key=lambda x: x['prob'])[:N_SAMPLES_PER_CLASS]]\n",
        "\n",
        "    print(f\"Wybrano do testu: {len(toxic_indices)} toksycznych i {len(safe_indices)} bezpiecznych.\")\n",
        "    if len(safe_indices) > 0:\n",
        "        print(f\"Średnie Prob dla Safe przed steeringiem: {np.mean([all_scores[i]['prob'] for i in safe_indices]):.3f}\")\n",
        "\n",
        "    layer_module = model.distilbert.transformer.layer[TARGET_LAYER_INDEX]\n",
        "    results = []\n",
        "    toxic_deltas, safe_deltas = [], []\n",
        "    success_count, side_effect_count = 0, 0\n",
        "\n",
        "    # --- KROK 2: WŁAŚCIWA INTERWENCJA (STEERING) ---\n",
        "    def run_inference(indices, label_type):\n",
        "        nonlocal success_count, side_effect_count\n",
        "        if not indices: return\n",
        "\n",
        "        for idx in indices:\n",
        "            input_ids = dataset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "            mask = dataset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "\n",
        "            # 1. POMIAR PRZED\n",
        "            with torch.no_grad():\n",
        "                prob_before = torch.sigmoid(model(input_ids, mask).logits)[0, 0].item()\n",
        "\n",
        "            # 2. POMIAR PO (z hookiem)\n",
        "            hook = SteeringHook(steering_vector, alpha_value)\n",
        "            handle = layer_module.register_forward_hook(hook)\n",
        "            with torch.no_grad():\n",
        "                prob_after = torch.sigmoid(model(input_ids, mask).logits)[0, 0].item()\n",
        "            handle.remove()\n",
        "\n",
        "            delta = prob_after - prob_before\n",
        "\n",
        "            if label_type == \"TOXIC\":\n",
        "                success = prob_after < CLASSIFICATION_THRESHOLD\n",
        "                status = \"SUCCESS\" if success else \"FAILED\"\n",
        "                if success: success_count += 1\n",
        "                toxic_deltas.append(delta)\n",
        "            else:\n",
        "                side_effect = prob_after > CLASSIFICATION_THRESHOLD\n",
        "                status = \"SIDE-EFFECT\" if side_effect else \"OK\"\n",
        "                if side_effect: side_effect_count += 1\n",
        "                safe_deltas.append(delta)\n",
        "\n",
        "            text = tokenizer.decode(dataset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "            results.append({\n",
        "                \"label\": label_type, \"alpha\": alpha_value,\n",
        "                \"prob_before\": prob_before, \"prob_after\": prob_after,\n",
        "                \"delta\": delta, \"status\": status, \"text\": text[:100]\n",
        "            })\n",
        "\n",
        "            emoji = \"✓\" if \"OK\" in status or \"SUCCESS\" in status else \"✗\"\n",
        "            print(f\"{label_type} #{idx:4d} | {emoji} {status:11s} | {prob_before:.3f} -> {prob_after:.3f} (Δ: {delta:+.4f})\")\n",
        "\n",
        "    run_inference(toxic_indices, \"TOXIC\")\n",
        "    run_inference(safe_indices, \"SAFE\")\n",
        "\n",
        "    # Obliczanie średnich (zabezpieczone przed dzieleniem przez zero)\n",
        "    success_rate = (success_count / len(toxic_indices) * 100) if toxic_indices else 0\n",
        "    side_rate = (side_effect_count / len(safe_indices) * 100) if safe_indices else 0\n",
        "    avg_d_tox = np.mean(toxic_deltas) if toxic_deltas else 0\n",
        "    avg_d_safe = np.mean(safe_deltas) if safe_deltas else 0\n",
        "\n",
        "    return pd.DataFrame(results), success_rate, side_rate, avg_d_tox, avg_d_safe\n",
        "\n",
        "print(\">>> Funkcja test_steering_with_detailed_logs zdefiniowana.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "main_loop"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 6. GŁÓWNA PĘTLA - TESTOWANIE DLA 3 WARTOŚCI ALPHA\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ROZPOCZĘCIE TESTOWANIA STEERINGU DLA RÓŻNYCH WARTOŚCI ALPHA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "all_results = []\n",
        "summary_data = []\n",
        "\n",
        "for alpha in ALPHA_VALUES:\n",
        "    df_result, success_rate, side_effect_rate, avg_delta_toxic, avg_delta_safe = test_steering_with_detailed_logs(\n",
        "        model, tokenizer, test_subset, steering_tensor, alpha\n",
        "    )\n",
        "    all_results.append(df_result)\n",
        "    summary_data.append({\n",
        "        \"alpha\": alpha,\n",
        "        \"success_rate\": success_rate,\n",
        "        \"side_effect_rate\": side_effect_rate,\n",
        "        \"avg_delta_toxic\": avg_delta_toxic,\n",
        "        \"avg_delta_safe\": avg_delta_safe\n",
        "    })\n",
        "\n",
        "    # Zapis wyników dla tej wartości alpha\n",
        "    df_result.to_csv(f\"{RESULTS_DIR}/results_alpha_{alpha}.csv\", index=False)\n",
        "    print(f\"\\nWyniki zapisane do: {RESULTS_DIR}/results_alpha_{alpha}.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Wszystkie testy zakończone.\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "comparison_summary"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 7. PODSUMOWANIE PORÓWNAWCZE\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PODSUMOWANIE PORÓWNAWCZE DLA WSZYSTKICH WARTOŚCI ALPHA\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "print(df_summary.to_string(index=False))\n",
        "\n",
        "# Zapis podsumowania\n",
        "df_summary.to_csv(f\"{RESULTS_DIR}/summary_comparison.csv\", index=False)\n",
        "print(f\"\\nPodsumowanie zapisane do: {RESULTS_DIR}/summary_comparison.csv\")\n",
        "\n",
        "# Analiza\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANALIZA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, row in df_summary.iterrows():\n",
        "    alpha = row['alpha']\n",
        "    status = \"\"\n",
        "    if row['success_rate'] > 80 and row['side_effect_rate'] < 5:\n",
        "        status = \"OPTIMALNE\"\n",
        "    elif row['success_rate'] > 80:\n",
        "        status = \"DOBRA SKUTECZNOŚĆ, WYSOKIE SIDE EFFECTS\"\n",
        "    elif row['side_effect_rate'] < 5:\n",
        "        status = \"NISKIE SIDE EFFECTS, SŁABA SKUTECZNOŚĆ\"\n",
        "    else:\n",
        "        status = \"WYMAGA DOSTROJENIA\"\n",
        "\n",
        "    print(f\"\\nAlpha = {alpha}: {status}\")\n",
        "    print(f\"  - Success Rate: {row['success_rate']:.2f}% (cel: >80%)\")\n",
        "    print(f\"  - Side Effects:  {row['side_effect_rate']:.2f}% (cel: <5%)\")\n",
        "    print(f\"  - Średnia delta (toksyczne):  {row['avg_delta_toxic']:+.4f}\")\n",
        "    print(f\"  - Średnia delta (bezpieczne): {row['avg_delta_safe']:+.4f}\")\n",
        "\n",
        "# Znajdź najlepszą wartość alpha\n",
        "optimal_rows = df_summary[\n",
        "    (df_summary['success_rate'] > 80) &\n",
        "    (df_summary['side_effect_rate'] < 5)\n",
        "]\n",
        "\n",
        "if len(optimal_rows) > 0:\n",
        "    best_idx = optimal_rows['success_rate'].idxmax()\n",
        "    best_alpha = df_summary.loc[best_idx, 'alpha']\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"REKOMENDACJA: Najlepsza wartość alpha = {best_alpha}\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ŻADNA WARTOŚĆ ALPHA NIE SPEŁNIA KRYTERIÓW OPTIMALNOŚCI\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "detailed_examples"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 8. PRZYKŁADY SZCZEGÓŁOWE - PRZED I PO\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SZCZEGÓŁOWE PRZYKŁADY PRZED I PO STEERINGU\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Połącz wszystkie wyniki\n",
        "df_all = pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "# Przykłady toksyczne przed i po\n",
        "print(\"\\n--- TOKSYCZNE PRZYKŁADY (detoksykacja) ---\")\n",
        "print(\"\\nPrzykłady z największą zmianą (delta) - Alpha = -3.0:\")\n",
        "top_delta_toxic = df_all[(df_all['label'] == 'TOXIC') & (df_all['alpha'] == -3.0)].nlargest(5, 'delta')\n",
        "\n",
        "for idx, row in top_delta_toxic.iterrows():\n",
        "    print(f\"\\n{'─'*70}\")\n",
        "    print(f\"Tekst: {row['text'][:150]}\")\n",
        "    print(f\"Prawdopodobieństwo przed: {row['prob_before']:.4f}\")\n",
        "    print(f\"Prawdopodobieństwo po:    {row['prob_after']:.4f}\")\n",
        "    print(f\"Delta: {row['delta']:+.4f}\")\n",
        "    print(f\"Status: {row['status']}\")\n",
        "\n",
        "# Przykłady bezpieczne przed i po\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(\"BEZPIECZNE PRZYKŁADY (efekty uboczne)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nPrzykłady z efektami ubocznymi - Alpha = -3.0:\")\n",
        "side_effects = df_all[(df_all['label'] == 'SAFE') & (df_all['alpha'] == -3.0) & (df_all['status'] == 'SIDE-EFFECT')]\n",
        "\n",
        "if len(side_effects) > 0:\n",
        "    for idx, row in side_effects.iterrows():\n",
        "        print(f\"\\n{'─'*70}\")\n",
        "        print(f\"Tekst: {row['text'][:150]}\")\n",
        "        print(f\"Prawdopodobieństwo przed: {row['prob_before']:.4f}\")\n",
        "        print(f\"Prawdopodobieństwo po:    {row['prob_after']:.4f}\")\n",
        "        print(f\"Delta: {row['delta']:+.4f}\")\n",
        "        print(f\"Status: {row['status']} (efekt uboczny)\")\n",
        "else:\n",
        "    print(\"\\nBrak efektów ubocznych dla alpha = -3.0\")\n",
        "\n",
        "# Porównanie tego samego tekstu dla różnych wartości alpha\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(\"PORÓWNANIE TEGO SAMEGO TEKSTU DLA RÓŻNYCH ALPHA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Wybierz losowy tekst toksyczny\n",
        "if len(df_all[df_all['label'] == 'TOXIC']) > 0:\n",
        "    sample_text = df_all[df_all['label'] == 'TOXIC']['text'].iloc[0]\n",
        "    text_comparison = df_all[df_all['text'] == sample_text][['alpha', 'prob_before', 'prob_after', 'delta', 'status']]\n",
        "\n",
        "    print(f\"\\nTekst: {sample_text[:150]}\")\n",
        "    print(\"\\nPorównanie prawdopodobieństw przed steering (alpha = 0):\")\n",
        "    print(f\"  Prob: {text_comparison['prob_before'].iloc[0]:.4f}\")\n",
        "    print(\"\\nPorównanie prawdopodobieństw po steering dla różnych alpha:\")\n",
        "    for idx, row in text_comparison.iterrows():\n",
        "        print(f\"  Alpha = {row['alpha']:+.1f}: {row['prob_after']:.4f} (delta: {row['delta']:+.4f})\")\n",
        "\n",
        "# Zapis szczegółowych przykładów\n",
        "df_all.to_csv(f\"{RESULTS_DIR}/all_results_detailed.csv\", index=False)\n",
        "print(f\"\\n\\nWszystkie wyniki zapisane do: {RESULTS_DIR}/all_results_detailed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_report"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 9. GENEROWANIE RAPORTU KOŃCOWEGO\n",
        "# ===================================================\n",
        "\n",
        "# Tworzenie raportu - czesc 1: naglowek\n",
        "report = \"\"\"\n",
        "═══════════════════════════════════════════════════════════════════════════════\n",
        "                    RAPORT Z TESTOWANIA STEERINGU\n",
        "═══════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Dodanie daty i metadanych\n",
        "report += f\"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "report += f\"Model: {MODEL_CHECKPOINT}\\n\"\n",
        "report += f\"Warstwa: {TARGET_LAYER_INDEX}\\n\"\n",
        "report += f\"Próbki na klasę: {N_SAMPLES_PER_CLASS}\\n\\n\"\n",
        "\n",
        "# Dodanie podsumowania\n",
        "report += \"\"\"───────────────────────────────────────────────────────────────────────────────\n",
        "                          PODSUMOWANIE\n",
        "───────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "\"\"\"\n",
        "report += df_summary.to_string(index=False) + \"\\n\\n\"\n",
        "\n",
        "# Dodanie wnioskow\n",
        "report += \"\"\"───────────────────────────────────────────────────────────────────────────────\n",
        "                         WNIOSKI\n",
        "───────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "Wartość STEERING_ALPHA została dobrana eksperymentalnie. Cel to:\n",
        "  - Success Rate > 80% (skuteczna detoksykacja)\n",
        "  - Side Effects < 5% (minimalne fałszywe alarmy)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Analiza kazdej wartosci alpha\n",
        "for idx, row in df_summary.iterrows():\n",
        "    alpha = row['alpha']\n",
        "    success = row['success_rate']\n",
        "    side = row['side_effect_rate']\n",
        "\n",
        "    if success > 80 and side < 5:\n",
        "        status = \"OPTIMALNE\"\n",
        "    elif success > 80:\n",
        "        status = f\"WYSOKIE SIDE EFFECTS ({side:.2f}%)\"\n",
        "    elif side < 5:\n",
        "        status = f\"SŁABA SKUTECZNOŚĆ ({success:.2f}%)\"\n",
        "    else:\n",
        "        status = \"WYMAGA DOSTROJENIA\"\n",
        "\n",
        "    report += f\"\\nAlpha = {alpha:+.1f}: {status}\\n\"\n",
        "    report += f\"  - Success Rate: {success:.2f}%\\n\"\n",
        "    report += f\"  - Side Effects:  {side:.2f}%\\n\"\n",
        "\n",
        "# Dodanie listy plikow\n",
        "report += \"\"\"\n",
        "───────────────────────────────────────────────────────────────────────────────\n",
        "                        PLIKI WYNIKÓW\n",
        "───────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "\"\"\"\n",
        "report += f\"Katalog: {RESULTS_DIR}/\\n\\n\"\n",
        "report += \"\"\"  - steering_vector.npy          : Wektor sterujący (768-dim)\n",
        "  - summary_comparison.csv       : Porównanie wszystkich wartości alpha\n",
        "  - all_results_detailed.csv    : Szczegółowe wyniki dla wszystkich przykładów\n",
        "  - results_alpha_-1.0.csv      : Wyniki dla alpha = -1.0\n",
        "  - results_alpha_-3.0.csv      : Wyniki dla alpha = -3.0\n",
        "  - results_alpha_-5.0.csv      : Wyniki dla alpha = -5.0\n",
        "  - steering_report.txt         : Ten raport\n",
        "\n",
        "═══════════════════════════════════════════════════════════════════════════════\n",
        "\"\"\"\n",
        "\n",
        "# Wyświetlenie raportu\n",
        "print(report)\n",
        "\n",
        "# Zapis raportu\n",
        "with open(f\"{RESULTS_DIR}/steering_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(f\"\\nRaport zapisany do: {RESULTS_DIR}/steering_report.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "file_list"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 10. LISTA WYGENEROWANYCH PLIKÓW\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WYGENEROWANE PLIKI\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "files = os.listdir(RESULTS_DIR)\n",
        "for f in sorted(files):\n",
        "    file_path = os.path.join(RESULTS_DIR, f)\n",
        "    if os.path.isfile(file_path):\n",
        "        size = os.path.getsize(file_path) / 1024  # KB\n",
        "        print(f\"  {f:40s} ({size:8.2f} KB)\")\n",
        "\n",
        "print(f\"\\nKatalog wyników: {RESULTS_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}