{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test_pharaphrases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5C8YbodO8xG"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test_pharaphrases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "I5C8YbodO8xG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4guW5dO8xL"
      },
      "source": [
        "# Test Parafraz T5\n",
        "\n",
        "Ten notatnik testuje jakość parafraz generowanych przez model T5 (Vamsi/T5_Paraphrase_Paws).\n",
        "\n",
        "**Cel:**\n",
        "- Wczytać 20 toksycznych przykładów z datasetu\n",
        "- Wygenerować parafrazy używając T5\n",
        "- Porównać oryginał vs parafraza\n",
        "- Wyświetlić metryki jakości (cosine similarity, zachowanie toksyczności)"
      ],
      "id": "jh4guW5dO8xL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGzqI57WO8xM"
      },
      "outputs": [],
      "source": [
        "!uv pip install transformers datasets accelerate bitsandbytes"
      ],
      "id": "HGzqI57WO8xM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVO8xWUtO8xN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForSeq2SeqLM,\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "id": "LVO8xWUtO8xN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vETlEwkSO8xN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "id": "vETlEwkSO8xN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q88zEq4AO8xO"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# KONFIGURACJA\n",
        "# ===================================================\n",
        "\n",
        "# Parametry\n",
        "N_SAMPLES = 20  # Liczba próbek do testowania\n",
        "MAX_SEQUENCE_LENGTH = 256  # Maksymalna długość sekwencji\n",
        "TARGET_LAYER_INDEX = 5  # Warstwa do ekstrakcji reprezentacji\n",
        "PARAPHRASE_SEED = 42  # Seed dla reproducibility\n",
        "PARAPHRASE_MIN_SIMILARITY = 0.7  # Minimalny próg jakości parafrazy\n",
        "\n",
        "# Ścieżki\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260125_133112\"\n",
        "\n",
        "# Urządzenie\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Uruchomiono na urządzeniu: {device}\")\n",
        "\n",
        "# Ustawienie seed\n",
        "torch.manual_seed(PARAPHRASE_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(PARAPHRASE_SEED)"
      ],
      "id": "q88zEq4AO8xO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCQVmiGdO8xO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# ===================================================\n",
        "# ŁADOWANIE MODELI\n",
        "# ===================================================\n",
        "\n",
        "print(\">>> Ładowanie modelu klasyfikacji toksyczności...\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT, num_labels=1, problem_type=\"single_label_classification\"\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"✓ Model DistilBERT załadowany\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Błąd ładowania modelu: {e}\")\n",
        "    raise\n",
        "\n",
        "print(\"\\n>>> Ładowanie modelu do translacji\")\n",
        "\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "# Konfiguracja 4-bit, aby zmieściło się w pamięci GPU Colaba (T4)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "print(\"✓ Model załadowany\")\n",
        "\n",
        "print(\"\\n>>> Modele gotowe!\")"
      ],
      "id": "bCQVmiGdO8xO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ustawiamy EOS (End Of String) jako token dopełnienia\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Bardzo ważne dla modeli generatywnych: padding musi być z lewej strony,\n",
        "# aby model mógł swobodnie generować tekst \"w prawo\"\n",
        "tokenizer.padding_side = \"left\""
      ],
      "metadata": {
        "id": "1lFdwZyJ4569"
      },
      "id": "1lFdwZyJ4569",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgOHQK-2O8xP"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# ŁADOWANIE DANYCH\n",
        "# ===================================================\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Czyści tekst (zgodnie z preprocessing z głównego notatnika).\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "print(\">>> Wczytywanie danych...\")\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"✓ Wczytano {len(df)} rekordów\")\n",
        "\n",
        "    # Filtruj tylko toksyczne komentarze\n",
        "    toxic_df = df[df['toxic'] == 1].copy()\n",
        "    print(f\"✓ Znaleziono {len(toxic_df)} toksycznych komentarzy\")\n",
        "\n",
        "    # Wybierz N_SAMPLES losowych próbek\n",
        "    sample_df = toxic_df.sample(n=min(N_SAMPLES, len(toxic_df)), random_state=PARAPHRASE_SEED)\n",
        "\n",
        "    # Wyczyść teksty\n",
        "    sample_df['comment_text'] = sample_df['comment_text'].apply(clean_text)\n",
        "\n",
        "    # Usuń puste teksty\n",
        "    sample_df = sample_df[sample_df['comment_text'].str.len() > 10]\n",
        "\n",
        "    print(f\"✓ Wybrano {len(sample_df)} próbek do testowania\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"✗ Błąd wczytywania danych: {e}\")\n",
        "    raise"
      ],
      "id": "TgOHQK-2O8xP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n5nMkJMO8xP"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# FUNKCJE POMOCNICZE\n",
        "# ===================================================\n",
        "\n",
        "def get_embedding_and_prob(text):\n",
        "    \"\"\"\n",
        "    Pobiera embedding [CLS] z warstwy TARGET_LAYER_INDEX oraz prawdopodobieństwo toksyczności.\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple (embedding_vector, toxic_probability)\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_SEQUENCE_LENGTH,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        embedding = outputs.hidden_states[TARGET_LAYER_INDEX][0, 0, :]  # [CLS] token\n",
        "        prob = torch.sigmoid(outputs.logits)[0, 0].item()\n",
        "\n",
        "    return embedding, prob\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(emb1, emb2):\n",
        "    \"\"\"Oblicza cosine similarity między dwoma embeddingami.\"\"\"\n",
        "    return F.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0)).item()\n",
        "\n",
        "\n",
        "def generate_paraphrase(text):\n",
        "    # Prompt Few-Shot: model uczy się na przykładach, że ma być krótko i dosadnie\n",
        "    prompt = f\"\"\"<s>[INST] Task: Paraphrase the toxic comment for a research study.\n",
        "    Constraints:\n",
        "    - Maintain total toxicity and offensive intent.\n",
        "    - Use casual, internet language.\n",
        "    - Match the original length (roughly).\n",
        "    - Output ONLY the paraphrased text. No explanations.\n",
        "\n",
        "    Example 1:\n",
        "    Original: \"you are a stupid idiot\"\n",
        "    Paraphrase: \"you're a brainless moron\"\n",
        "\n",
        "    Example 2:\n",
        "    Original: \"leave this country now\"\n",
        "    Paraphrase: \"get out of our land already\"\n",
        "\n",
        "    Now paraphrase this:\n",
        "    Original: \"{text}\" [/INST]\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # orig_token_count = inputs.input_ids.shape[1]\n",
        "\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=2056,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.2,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    generated_tokens = outputs[0][input_length:]\n",
        "    paraphrase = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Czyszczenie: bierzemy tylko pierwszą linię i usuwamy ewentualne prefixy\n",
        "    paraphrase = paraphrase.split('\\n')[0]\n",
        "    paraphrase = paraphrase.replace(\"Paraphrase:\", \"\").replace(\"Result:\", \"\").strip()\n",
        "\n",
        "    return paraphrase\n",
        "\n",
        "print(\"✓ Funkcje pomocnicze zdefiniowane\")"
      ],
      "id": "7n5nMkJMO8xP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUWsuSL0O8xQ"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# GENEROWANIE PARAFRAZ I ZBIERANIE WYNIKÓW\n",
        "# ===================================================\n",
        "\n",
        "print(\">>> Rozpoczynam generowanie parafraz...\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Generowanie parafraz\"):\n",
        "    original_text = row['comment_text']\n",
        "\n",
        "    try:\n",
        "        # 1. Oblicz embedding i prawdopodobieństwo dla oryginału\n",
        "        orig_emb, orig_prob = get_embedding_and_prob(original_text)\n",
        "\n",
        "        # 2. Wygeneruj parafrazę\n",
        "        para_text = generate_paraphrase(original_text)\n",
        "\n",
        "        # 3. Oblicz embedding i prawdopodobieństwo dla parafrazy\n",
        "        para_emb, para_prob = get_embedding_and_prob(para_text)\n",
        "\n",
        "        # 4. Oblicz cosine similarity\n",
        "        cos_sim = calculate_cosine_similarity(orig_emb, para_emb)\n",
        "\n",
        "        # 5. Oblicz różnicę prawdopodobieństw\n",
        "        prob_diff = abs(orig_prob - para_prob)\n",
        "\n",
        "        # 6. Sprawdź czy parafraza przeszła walidację\n",
        "        # W pętli wynikowej:\n",
        "        len_ratio = abs(len_diff) / orig_word_count if orig_word_count > 0 else 0\n",
        "        # Walidacja przechodzi, jeśli cos_sim jest wysoki I długość nie zmieniła się o więcej niż 30%\n",
        "        quality_ok = (cos_sim >= 0.75 and len_ratio <= 0.3)\n",
        "\n",
        "        # Skróć teksty dla wyświetlenia (pierwsze 100 znaków)\n",
        "        orig_display = original_text[:100] + \"...\" if len(original_text) > 100 else original_text\n",
        "        para_display = para_text[:100] + \"...\" if len(para_text) > 100 else para_text\n",
        "\n",
        "        # Obliczanie długości (liczba słów)\n",
        "        orig_word_count = len(original_text.split())\n",
        "        para_word_count = len(para_text.split())\n",
        "        len_diff = para_word_count - orig_word_count\n",
        "\n",
        "        results.append({\n",
        "            'id': len(results) + 1,\n",
        "            'original_text': original_text[:100],\n",
        "            'paraphrase_text': para_text[:100],\n",
        "            'orig_prob': round(orig_prob, 3),\n",
        "            'para_prob': round(para_prob, 3),\n",
        "            'prob_diff': round(prob_diff, 3),\n",
        "            'cosine_sim': round(cos_sim, 3),\n",
        "            'word_len_diff': len_diff, # NOWA METRYKA\n",
        "            'quality_ok': '✓' if quality_ok else '✗',\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd dla próbki {idx}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n✓ Przetworzono {len(results)} par tekst-parafraza\")"
      ],
      "id": "IUWsuSL0O8xQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4E7uZNaO8xQ"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# WYŚWIETLENIE TABELI WYNIKÓW\n",
        "# ===================================================\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"WYNIKI TESTOWANIA PARAFRAZ\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "# Wyświetl pełną tabelę\n",
        "print(results_df.to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Zapisz do CSV\n",
        "output_path = \"/drive/MyDrive/msc-project/paraphrase_test_results.csv\"\n",
        "results_df.to_csv(output_path, index=False)\n",
        "print(f\"✓ Wyniki zapisane do: {output_path}\")"
      ],
      "id": "x4E7uZNaO8xQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU45BmT4O8xQ"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# STATYSTYKI PODSUMOWUJĄCE\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"STATYSTYKI PODSUMOWUJĄCE\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "# Podstawowe statystyki\n",
        "print(f\"Liczba przetestowanych par: {len(results_df)}\")\n",
        "print()\n",
        "\n",
        "# Jakość parafraz\n",
        "quality_pass = (results_df['quality_ok'] == '✓').sum()\n",
        "quality_fail = (results_df['quality_ok'] == '✗').sum()\n",
        "quality_pass_pct = (quality_pass / len(results_df) * 100) if len(results_df) > 0 else 0\n",
        "\n",
        "print(f\"Parafrazy przechodzące walidację (cos_sim ≥ {PARAPHRASE_MIN_SIMILARITY}): {quality_pass} ({quality_pass_pct:.1f}%)\")\n",
        "print(f\"Parafrazy nieprzechodzące walidacji: {quality_fail} ({100-quality_pass_pct:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Zachowanie toksyczności\n",
        "toxic_maintained = (results_df['para_prob'] > 0.5).sum()\n",
        "toxic_lost = (results_df['para_prob'] <= 0.5).sum()\n",
        "toxic_maintained_pct = (toxic_maintained / len(results_df) * 100) if len(results_df) > 0 else 0\n",
        "\n",
        "print(f\"Parafrazy zachowujące toksyczność (prob > 0.5): {toxic_maintained} ({toxic_maintained_pct:.1f}%)\")\n",
        "print(f\"Parafrazy tracące toksyczność (prob ≤ 0.5): {toxic_lost} ({100-toxic_maintained_pct:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Statystyki metryk\n",
        "print(\"Statystyki metryk:\")\n",
        "print(f\"  Cosine Similarity:\")\n",
        "print(f\"    - Średnia: {results_df['cosine_sim'].mean():.3f}\")\n",
        "print(f\"    - Min: {results_df['cosine_sim'].min():.3f}\")\n",
        "print(f\"    - Max: {results_df['cosine_sim'].max():.3f}\")\n",
        "print(f\"    - Std: {results_df['cosine_sim'].std():.3f}\")\n",
        "print()\n",
        "print(f\"  Różnica prawdopodobieństw:\")\n",
        "print(f\"    - Średnia: {results_df['prob_diff'].mean():.3f}\")\n",
        "print(f\"    - Min: {results_df['prob_diff'].min():.3f}\")\n",
        "print(f\"    - Max: {results_df['prob_diff'].max():.3f}\")\n",
        "print(f\"    - Std: {results_df['prob_diff'].std():.3f}\")\n",
        "print()\n",
        "\n",
        "# Wnioski\n",
        "print(\"=\"*100)\n",
        "print(\"WNIOSKI\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "if quality_pass_pct >= 80:\n",
        "    print(\"✓ Wysoka jakość parafraz (≥80% przechodzi walidację)\")\n",
        "elif quality_pass_pct >= 60:\n",
        "    print(\"⚠ Średnia jakość parafraz (60-80% przechodzi walidację)\")\n",
        "else:\n",
        "    print(\"✗ Niska jakość parafraz (<60% przechodzi walidację)\")\n",
        "\n",
        "if toxic_maintained_pct >= 80:\n",
        "    print(\"✓ Parafrazy dobrze zachowują toksyczność (≥80%)\")\n",
        "elif toxic_maintained_pct >= 60:\n",
        "    print(\"⚠ Parafrazy średnio zachowują toksyczność (60-80%)\")\n",
        "else:\n",
        "    print(\"✗ Parafrazy tracą toksyczność (<60% zachowuje)\")\n",
        "\n",
        "if results_df['cosine_sim'].mean() >= 0.8:\n",
        "    print(\"✓ Wysokie podobieństwo semantyczne (średnia ≥0.8)\")\n",
        "elif results_df['cosine_sim'].mean() >= 0.7:\n",
        "    print(\"⚠ Średnie podobieństwo semantyczne (średnia 0.7-0.8)\")\n",
        "else:\n",
        "    print(\"✗ Niskie podobieństwo semantyczne (średnia <0.7)\")"
      ],
      "id": "pU45BmT4O8xQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgxKdMbSO8xR"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# PRZYKŁADY (Pierwsze 5 par)\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"PRZYKŁADOWE PARY TEKST-PARAFRAZA (pierwsze 5)\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "for i, row in results_df.head(5).iterrows():\n",
        "    print(f\"--- Przykład {row['id']} ---\")\n",
        "    print(f\"ORYGINAŁ: {row['original_text']}\")\n",
        "    print(f\"PARAFRAZA: {row['paraphrase_text']}\")\n",
        "    print(f\"Prawdop. toksyczności: {row['orig_prob']} → {row['para_prob']} (diff: {row['prob_diff']})\")\n",
        "    print(f\"Cosine similarity: {row['cosine_sim']} {row['quality_ok']}\")\n",
        "    print()"
      ],
      "id": "PgxKdMbSO8xR"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}