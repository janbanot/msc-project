{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test_pharaphrases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5C8YbodO8xG"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test_pharaphrases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "I5C8YbodO8xG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4guW5dO8xL"
      },
      "source": [
        "# Test Parafraz\n",
        "Ten notatnik testuje jakość parafraz generowanych przez modele"
      ],
      "id": "jh4guW5dO8xL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGzqI57WO8xM"
      },
      "outputs": [],
      "source": [
        "!uv pip install transformers datasets accelerate bitsandbytes nltk captum"
      ],
      "id": "HGzqI57WO8xM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVO8xWUtO8xN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForSeq2SeqLM,\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "id": "LVO8xWUtO8xN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vETlEwkSO8xN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "id": "vETlEwkSO8xN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q88zEq4AO8xO"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# KONFIGURACJA\n",
        "# ===================================================\n",
        "\n",
        "# Parametry\n",
        "N_SAMPLES = 20  # Liczba próbek do testowania\n",
        "MAX_SEQUENCE_LENGTH = 256  # Maksymalna długość sekwencji\n",
        "TARGET_LAYER_INDEX = 5  # Warstwa do ekstrakcji reprezentacji\n",
        "PARAPHRASE_SEED = 42  # Seed dla reproducibility\n",
        "PARAPHRASE_MIN_SIMILARITY = 0.7  # Minimalny próg jakości parafrazy\n",
        "\n",
        "# Ścieżki\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260125_133112\"\n",
        "\n",
        "# Urządzenie\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Uruchomiono na urządzeniu: {device}\")\n",
        "\n",
        "# Ustawienie seed\n",
        "torch.manual_seed(PARAPHRASE_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(PARAPHRASE_SEED)"
      ],
      "id": "q88zEq4AO8xO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCQVmiGdO8xO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# ===================================================\n",
        "# ŁADOWANIE MODELI\n",
        "# ===================================================\n",
        "\n",
        "print(\">>> Ładowanie modelu klasyfikacji toksyczności...\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_CHECKPOINT, num_labels=1, problem_type=\"single_label_classification\"\n",
        "    )\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"✓ Model DistilBERT załadowany\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Błąd ładowania modelu: {e}\")\n",
        "    raise"
      ],
      "id": "bCQVmiGdO8xO"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n>>> Ładowanie modelu do parafraz\")\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "# Konfiguracja 4-bit, aby zmieściło się w pamięci GPU Colaba (T4)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "print(\"✓ Model do parafraz załadowany\")\n",
        "\n",
        "# Ustawiamy EOS (End Of String) jako token dopełnienia\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Bardzo ważne dla modeli generatywnych: padding musi być z lewej strony,\n",
        "# aby model mógł swobodnie generować tekst \"w prawo\"\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "print(\"\\n>>> Modele gotowe!\")"
      ],
      "metadata": {
        "id": "Z2gP_d6nHjVJ"
      },
      "id": "Z2gP_d6nHjVJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgOHQK-2O8xP"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# ŁADOWANIE DANYCH\n",
        "# ===================================================\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Czyści tekst (zgodnie z preprocessing z głównego notatnika).\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "print(\">>> Wczytywanie danych...\")\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"✓ Wczytano {len(df)} rekordów\")\n",
        "\n",
        "    # Filtruj tylko toksyczne komentarze\n",
        "    toxic_df = df[df['toxic'] == 1].copy()\n",
        "    print(f\"✓ Znaleziono {len(toxic_df)} toksycznych komentarzy\")\n",
        "\n",
        "    # Wybierz N_SAMPLES losowych próbek\n",
        "    sample_df = toxic_df.sample(n=min(N_SAMPLES, len(toxic_df)), random_state=PARAPHRASE_SEED)\n",
        "\n",
        "    # Wyczyść teksty\n",
        "    sample_df['comment_text'] = sample_df['comment_text'].apply(clean_text)\n",
        "\n",
        "    # Usuń puste teksty\n",
        "    sample_df = sample_df[sample_df['comment_text'].str.len() > 10]\n",
        "\n",
        "    print(f\"✓ Wybrano {len(sample_df)} próbek do testowania\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"✗ Błąd wczytywania danych: {e}\")\n",
        "    raise"
      ],
      "id": "TgOHQK-2O8xP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n5nMkJMO8xP"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# FUNKCJE POMOCNICZE\n",
        "# ===================================================\n",
        "\n",
        "def get_embedding_and_prob(text):\n",
        "    \"\"\"\n",
        "    Pobiera embedding [CLS] z warstwy TARGET_LAYER_INDEX oraz prawdopodobieństwo toksyczności.\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple (embedding_vector, toxic_probability)\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_SEQUENCE_LENGTH,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "        embedding = outputs.hidden_states[TARGET_LAYER_INDEX][0, 0, :]  # [CLS] token\n",
        "        prob = torch.sigmoid(outputs.logits)[0, 0].item()\n",
        "\n",
        "    return embedding, prob\n",
        "\n",
        "\n",
        "def calculate_cosine_similarity(emb1, emb2):\n",
        "    \"\"\"Oblicza cosine similarity między dwoma embeddingami.\"\"\"\n",
        "    return F.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0)).item()\n",
        "\n",
        "\n",
        "def generate_paraphrase(text):\n",
        "    # Prompt Few-Shot: model uczy się na przykładach, że ma być krótko i dosadnie\n",
        "    prompt = f\"\"\"<s>[INST] Task: Paraphrase the toxic comment for a research study.\n",
        "    Constraints:\n",
        "    - Maintain total toxicity and offensive intent.\n",
        "    - Use casual, internet language.\n",
        "    - Match the original length (roughly).\n",
        "    - Output ONLY the paraphrased text. No explanations.\n",
        "\n",
        "    Example 1:\n",
        "    Original: \"you are a stupid idiot\"\n",
        "    Paraphrase: \"you're a brainless moron\"\n",
        "\n",
        "    Example 2:\n",
        "    Original: \"leave this country now\"\n",
        "    Paraphrase: \"get out of our land already\"\n",
        "\n",
        "    Now paraphrase this:\n",
        "    Original: \"{text}\" [/INST]\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
        "    input_length = inputs.input_ids.shape[1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # orig_token_count = inputs.input_ids.shape[1]\n",
        "\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=2056,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.2,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    generated_tokens = outputs[0][input_length:]\n",
        "    paraphrase = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    # Czyszczenie: bierzemy tylko pierwszą linię i usuwamy ewentualne prefixy\n",
        "    paraphrase = paraphrase.split('\\n')[0]\n",
        "    paraphrase = paraphrase.replace(\"Paraphrase:\", \"\").replace(\"Result:\", \"\").strip()\n",
        "\n",
        "    return paraphrase\n",
        "\n",
        "print(\"✓ Funkcje pomocnicze zdefiniowane\")"
      ],
      "id": "7n5nMkJMO8xP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUWsuSL0O8xQ"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# GENEROWANIE PARAFRAZ I ZBIERANIE WYNIKÓW\n",
        "# ===================================================\n",
        "\n",
        "print(\">>> Rozpoczynam generowanie parafraz...\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc=\"Generowanie parafraz\"):\n",
        "    original_text = row['comment_text']\n",
        "\n",
        "    try:\n",
        "        # 1. Oblicz embedding i prawdopodobieństwo dla oryginału\n",
        "        orig_emb, orig_prob = get_embedding_and_prob(original_text)\n",
        "\n",
        "        # 2. Wygeneruj parafrazę\n",
        "        para_text = generate_paraphrase(original_text)\n",
        "\n",
        "        # 3. Oblicz embedding i prawdopodobieństwo dla parafrazy\n",
        "        para_emb, para_prob = get_embedding_and_prob(para_text)\n",
        "\n",
        "        # 4. Oblicz cosine similarity\n",
        "        cos_sim = calculate_cosine_similarity(orig_emb, para_emb)\n",
        "\n",
        "        # 5. Oblicz różnicę prawdopodobieństw\n",
        "        prob_diff = abs(orig_prob - para_prob)\n",
        "\n",
        "        # 6. Sprawdź czy parafraza przeszła walidację\n",
        "        # W pętli wynikowej:\n",
        "        len_ratio = abs(len_diff) / orig_word_count if orig_word_count > 0 else 0\n",
        "        # Walidacja przechodzi, jeśli cos_sim jest wysoki I długość nie zmieniła się o więcej niż 30%\n",
        "        quality_ok = (cos_sim >= 0.75 and len_ratio <= 0.3)\n",
        "\n",
        "        # Skróć teksty dla wyświetlenia (pierwsze 100 znaków)\n",
        "        orig_display = original_text[:100] + \"...\" if len(original_text) > 100 else original_text\n",
        "        para_display = para_text[:100] + \"...\" if len(para_text) > 100 else para_text\n",
        "\n",
        "        # Obliczanie długości (liczba słów)\n",
        "        orig_word_count = len(original_text.split())\n",
        "        para_word_count = len(para_text.split())\n",
        "        len_diff = para_word_count - orig_word_count\n",
        "\n",
        "        results.append({\n",
        "            'id': len(results) + 1,\n",
        "            'original_text': original_text[:100],\n",
        "            'paraphrase_text': para_text[:100],\n",
        "            'orig_prob': round(orig_prob, 3),\n",
        "            'para_prob': round(para_prob, 3),\n",
        "            'prob_diff': round(prob_diff, 3),\n",
        "            'cosine_sim': round(cos_sim, 3),\n",
        "            'word_len_diff': len_diff, # NOWA METRYKA\n",
        "            'quality_ok': '✓' if quality_ok else '✗',\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd dla próbki {idx}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n✓ Przetworzono {len(results)} par tekst-parafraza\")"
      ],
      "id": "IUWsuSL0O8xQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4E7uZNaO8xQ"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# WYŚWIETLENIE TABELI WYNIKÓW\n",
        "# ===================================================\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"=\"*100)\n",
        "print(\"WYNIKI TESTOWANIA PARAFRAZ\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "# Wyświetl pełną tabelę\n",
        "print(results_df.to_string(index=False))\n",
        "print()\n",
        "\n",
        "# Zapisz do CSV\n",
        "output_path = \"/drive/MyDrive/msc-project/paraphrase_test_results.csv\"\n",
        "results_df.to_csv(output_path, index=False)\n",
        "print(f\"✓ Wyniki zapisane do: {output_path}\")"
      ],
      "id": "x4E7uZNaO8xQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU45BmT4O8xQ"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# STATYSTYKI PODSUMOWUJĄCE\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"STATYSTYKI PODSUMOWUJĄCE\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "# Podstawowe statystyki\n",
        "print(f\"Liczba przetestowanych par: {len(results_df)}\")\n",
        "print()\n",
        "\n",
        "# Jakość parafraz\n",
        "quality_pass = (results_df['quality_ok'] == '✓').sum()\n",
        "quality_fail = (results_df['quality_ok'] == '✗').sum()\n",
        "quality_pass_pct = (quality_pass / len(results_df) * 100) if len(results_df) > 0 else 0\n",
        "\n",
        "print(f\"Parafrazy przechodzące walidację (cos_sim ≥ {PARAPHRASE_MIN_SIMILARITY}): {quality_pass} ({quality_pass_pct:.1f}%)\")\n",
        "print(f\"Parafrazy nieprzechodzące walidacji: {quality_fail} ({100-quality_pass_pct:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Zachowanie toksyczności\n",
        "toxic_maintained = (results_df['para_prob'] > 0.5).sum()\n",
        "toxic_lost = (results_df['para_prob'] <= 0.5).sum()\n",
        "toxic_maintained_pct = (toxic_maintained / len(results_df) * 100) if len(results_df) > 0 else 0\n",
        "\n",
        "print(f\"Parafrazy zachowujące toksyczność (prob > 0.5): {toxic_maintained} ({toxic_maintained_pct:.1f}%)\")\n",
        "print(f\"Parafrazy tracące toksyczność (prob ≤ 0.5): {toxic_lost} ({100-toxic_maintained_pct:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Statystyki metryk\n",
        "print(\"Statystyki metryk:\")\n",
        "print(f\"  Cosine Similarity:\")\n",
        "print(f\"    - Średnia: {results_df['cosine_sim'].mean():.3f}\")\n",
        "print(f\"    - Min: {results_df['cosine_sim'].min():.3f}\")\n",
        "print(f\"    - Max: {results_df['cosine_sim'].max():.3f}\")\n",
        "print(f\"    - Std: {results_df['cosine_sim'].std():.3f}\")\n",
        "print()\n",
        "print(f\"  Różnica prawdopodobieństw:\")\n",
        "print(f\"    - Średnia: {results_df['prob_diff'].mean():.3f}\")\n",
        "print(f\"    - Min: {results_df['prob_diff'].min():.3f}\")\n",
        "print(f\"    - Max: {results_df['prob_diff'].max():.3f}\")\n",
        "print(f\"    - Std: {results_df['prob_diff'].std():.3f}\")\n",
        "print()\n",
        "\n",
        "# Wnioski\n",
        "print(\"=\"*100)\n",
        "print(\"WNIOSKI\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "if quality_pass_pct >= 80:\n",
        "    print(\"✓ Wysoka jakość parafraz (≥80% przechodzi walidację)\")\n",
        "elif quality_pass_pct >= 60:\n",
        "    print(\"⚠ Średnia jakość parafraz (60-80% przechodzi walidację)\")\n",
        "else:\n",
        "    print(\"✗ Niska jakość parafraz (<60% przechodzi walidację)\")\n",
        "\n",
        "if toxic_maintained_pct >= 80:\n",
        "    print(\"✓ Parafrazy dobrze zachowują toksyczność (≥80%)\")\n",
        "elif toxic_maintained_pct >= 60:\n",
        "    print(\"⚠ Parafrazy średnio zachowują toksyczność (60-80%)\")\n",
        "else:\n",
        "    print(\"✗ Parafrazy tracą toksyczność (<60% zachowuje)\")\n",
        "\n",
        "if results_df['cosine_sim'].mean() >= 0.8:\n",
        "    print(\"✓ Wysokie podobieństwo semantyczne (średnia ≥0.8)\")\n",
        "elif results_df['cosine_sim'].mean() >= 0.7:\n",
        "    print(\"⚠ Średnie podobieństwo semantyczne (średnia 0.7-0.8)\")\n",
        "else:\n",
        "    print(\"✗ Niskie podobieństwo semantyczne (średnia <0.7)\")"
      ],
      "id": "pU45BmT4O8xQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgxKdMbSO8xR"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# PRZYKŁADY (Pierwsze 5 par)\n",
        "# ===================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"PRZYKŁADOWE PARY TEKST-PARAFRAZA (pierwsze 5)\")\n",
        "print(\"=\"*100)\n",
        "print()\n",
        "\n",
        "for i, row in results_df.head(5).iterrows():\n",
        "    print(f\"--- Przykład {row['id']} ---\")\n",
        "    print(f\"ORYGINAŁ: {row['original_text']}\")\n",
        "    print(f\"PARAFRAZA: {row['paraphrase_text']}\")\n",
        "    print(f\"Prawdop. toksyczności: {row['orig_prob']} → {row['para_prob']} (diff: {row['prob_diff']})\")\n",
        "    print(f\"Cosine similarity: {row['cosine_sim']} {row['quality_ok']}\")\n",
        "    print()"
      ],
      "id": "PgxKdMbSO8xR"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# Mniej agresywne parafrazy\n",
        "# (tylko zmiany pojednynczych słów na synonimy)\n",
        "# ===================================================\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from captum.attr import IntegratedGradients\n",
        "\n",
        "# Pobieranie niezbędnych zasobów\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"Mapuje tagi NLTK na format akceptowany przez WordNet.\"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "oifEYDy1GyYN"
      },
      "id": "oifEYDy1GyYN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def synonym_paraphraser(text, n_changes=2):\n",
        "    \"\"\"Zamienia n_changes słów na ich synonimy przy użyciu WordNet.\"\"\"\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "    # Indeksy słów, które mają sensowne tagi (rzeczownik, czasownik, przymiotnik, przysłówek)\n",
        "    eligible_indices = [\n",
        "        i for i, (word, tag) in enumerate(pos_tags)\n",
        "        if get_wordnet_pos(tag) is not None and len(word) > 3\n",
        "    ]\n",
        "\n",
        "    if not eligible_indices:\n",
        "        return text\n",
        "\n",
        "    # Wybierz losowo słowa do zmiany\n",
        "    to_change = random.sample(eligible_indices, min(n_changes, len(eligible_indices)))\n",
        "    new_words = words.copy()\n",
        "\n",
        "    for idx in to_change:\n",
        "        word, tag = pos_tags[idx]\n",
        "        wn_pos = get_wordnet_pos(tag)\n",
        "        synonyms = []\n",
        "\n",
        "        for syn in wordnet.synsets(word, pos=wn_pos):\n",
        "            for lemma in syn.lemmas():\n",
        "                if lemma.name().lower() != word.lower():\n",
        "                    synonyms.append(lemma.name().replace('_', ' '))\n",
        "\n",
        "        if synonyms:\n",
        "            new_words[idx] = random.choice(list(set(synonyms)))\n",
        "\n",
        "    return \" \".join(new_words)"
      ],
      "metadata": {
        "id": "rpsyKKfUHK_O"
      },
      "id": "rpsyKKfUHK_O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import LayerIntegratedGradients\n",
        "\n",
        "def get_word_attributions(text, model, tokenizer):\n",
        "    \"\"\"Oblicza wagi ważności dla każdego słowa, celując w warstwę embeddings.\"\"\"\n",
        "\n",
        "    # 1. Przygotowanie wejścia\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
        "                       max_length=MAX_SEQUENCE_LENGTH).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    # 2. Definicja funkcji forward (musi zwracać tylko logity)\n",
        "    def predict(ids):\n",
        "        return model(ids).logits\n",
        "\n",
        "    # 3. Wybór warstwy embeddings (w DistilBERT to model.distilbert.embeddings)\n",
        "    # Jeśli używasz innego modelu, sprawdź nazwę warstwy przez print(model)\n",
        "    lig = LayerIntegratedGradients(predict, model.distilbert.embeddings)\n",
        "\n",
        "    # 4. Obliczanie atrybucji\n",
        "    # target=0 oznacza, że badamy wpływ na wyjście (dla regresji/binary classification)\n",
        "    attributions = lig.attribute(inputs=input_ids,\n",
        "                                 target=0,\n",
        "                                 n_steps=50) # n_steps to dokładność przybliżenia całki\n",
        "\n",
        "    # 5. Agregacja: Atrybucje są dla każdego wymiaru embeddingu (np. 768),\n",
        "    # musimy je zsumować, aby dostać jedną wartość na token.\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "\n",
        "    # Normalizacja dla lepszej porównywalności (L2)\n",
        "    if torch.norm(attributions) != 0:\n",
        "        attributions = attributions / torch.norm(attributions)\n",
        "\n",
        "    # 6. Mapowanie na tokeny\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    return list(zip(tokens, attributions.cpu().detach().numpy()))"
      ],
      "metadata": {
        "id": "ClxeEsIOHP35"
      },
      "id": "ClxeEsIOHP35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "case_studies = []\n",
        "\n",
        "print(\">>> Uruchamiam test stabilności atrybucji (Synonimy)...\")\n",
        "\n",
        "for idx, row in sample_df.head(10).iterrows():  # Test na 10 przykładach\n",
        "    orig_text = row['comment_text']\n",
        "\n",
        "    # 1. Parafraza synonimiczna\n",
        "    syn_text = synonym_paraphraser(orig_text, n_changes=2)\n",
        "\n",
        "    # 2. Pobranie atrybucji (XAI)\n",
        "    attr_orig = get_word_attributions(orig_text, model, tokenizer)\n",
        "    attr_syn = get_word_attributions(syn_text, model, tokenizer)\n",
        "\n",
        "    # 3. Obliczenie korelacji Spearmana (wymaga wektorów tej samej długości)\n",
        "    # Dla uproszczenia: porównujemy tylko średnią ważność top-tokenów\n",
        "    # lub przycinamy do krótszego tekstu\n",
        "    min_len = min(len(attr_orig), len(attr_syn))\n",
        "    vals_orig = [float(a[1]) for a in attr_orig[:min_len]]\n",
        "    vals_syn = [float(a[1]) for a in attr_syn[:min_len]]\n",
        "\n",
        "    correlation, _ = spearmanr(vals_orig, vals_syn)\n",
        "\n",
        "    case_studies.append({\n",
        "        \"case_id\": idx,\n",
        "        \"original\": {\n",
        "            \"text\": orig_text,\n",
        "            \"explanation\": [{\"t\": t, \"w\": float(w)} for t, w in attr_orig]\n",
        "        },\n",
        "        \"paraphrase_synonym\": {\n",
        "            \"text\": syn_text,\n",
        "            \"explanation\": [{\"t\": t, \"w\": float(w)} for t, w in attr_syn]\n",
        "        },\n",
        "        \"metrics\": {\n",
        "            \"spearman_correlation\": round(correlation, 4),\n",
        "            \"similarity\": calculate_cosine_similarity(*get_embedding_and_prob(orig_text)[0:1],\n",
        "                                                     *get_embedding_and_prob(syn_text)[0:1])\n",
        "        }\n",
        "    })\n",
        "\n",
        "# Zapis do JSON (idealne do wykresów w pracy mgr)\n",
        "with open('xai_case_studies.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(case_studies, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"✓ Zapisano {len(case_studies)} Case Studies do pliku JSON.\")"
      ],
      "metadata": {
        "id": "Z9eOiJxeHQ5p"
      },
      "id": "Z9eOiJxeHQ5p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# 1. Tabela podsumowująca metryki\n",
        "summary_data = []\n",
        "for study in case_studies:\n",
        "    summary_data.append({\n",
        "        \"ID\": study['case_id'],\n",
        "        \"Korelacja XAI (Spearman)\": study['metrics']['spearman_correlation'],\n",
        "        \"Podobieństwo Semantyczne\": round(study['metrics']['similarity'], 4),\n",
        "        \"Oryginał\": study['original']['text'][:50] + \"...\",\n",
        "        \"Parafraza (Synonim)\": study['paraphrase_synonym']['text'][:50] + \"...\"\n",
        "    })\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PODSUMOWANIE METRYK STABILNOŚCI\")\n",
        "print(\"=\"*50)\n",
        "df_summary = pd.DataFrame(summary_data)\n",
        "display(df_summary)\n",
        "\n",
        "# 2. Funkcja do kolorowania tekstu na podstawie wag XAI\n",
        "def colorize_text(explanation):\n",
        "    \"\"\"\n",
        "    Renderuje tekst z kolorowaniem wag.\n",
        "    Obsługuje format krotki (token, waga) oraz słownika {'t': token, 'w': waga}.\n",
        "    \"\"\"\n",
        "    if not explanation:\n",
        "        return \"\"\n",
        "\n",
        "    # Konwersja do wspólnego formatu (token, waga)\n",
        "    normalized_data = []\n",
        "    for item in explanation:\n",
        "        if isinstance(item, dict):\n",
        "            normalized_data.append((item['t'], item['w']))\n",
        "        else:\n",
        "            normalized_data.append((item[0], item[1]))\n",
        "\n",
        "    html_res = \"\"\n",
        "    # Znajdujemy max wartość do skalowania intensywności kolorów\n",
        "    abs_weights = [abs(w) for t, w in normalized_data]\n",
        "    max_w = max(abs_weights) if abs_weights else 1\n",
        "\n",
        "    for token, weight in normalized_data:\n",
        "        # Czyszczenie subtokenów WordPiece dla lepszej czytelności\n",
        "        clean_token = token.replace('##', '')\n",
        "\n",
        "        # Obliczanie przezroczystości (intensywność koloru)\n",
        "        alpha = abs(weight) / max_w\n",
        "\n",
        "        # Czerwony: wzmacnia toksyczność | Niebieski: osłabia/neutralizuje\n",
        "        color = f\"rgba(255, 0, 0, {alpha:.2f})\" if weight > 0 else f\"rgba(0, 0, 255, {alpha:.2f})\"\n",
        "\n",
        "        html_res += f'''<span style=\"background-color: {color};\n",
        "                                    padding: 2px 4px;\n",
        "                                    margin: 1px;\n",
        "                                    border-radius: 3px;\n",
        "                                    display: inline-block;\n",
        "                                    border: 0.5px solid rgba(0,0,0,0.1);\"\n",
        "                             title=\"Waga: {weight:.4f}\">{clean_token}</span> '''\n",
        "    return html_res\n",
        "\n",
        "# 3. Wyświetlenie Case Studies side-by-side\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"WIZUALIZACJA ATKRYBUCJI (MAPY CIEPŁA)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "html_output = \"<div style='font-family: sans-serif;'>\"\n",
        "for study in case_studies[:5]: # Wyświetlamy pierwsze 5 dla przejrzystości\n",
        "    html_output += f\"\"\"\n",
        "    <div style=\"border: 1px solid #ddd; margin-bottom: 20px; padding: 10px; border-radius: 8px;\">\n",
        "        <h4 style=\"margin-top: 0;\">Case ID: {study['case_id']} | Korelacja: {study['metrics']['spearman_correlation']}</h4>\n",
        "        <div style=\"display: flex; gap: 20px;\">\n",
        "            <div style=\"flex: 1;\">\n",
        "                <strong>Oryginał:</strong><br>\n",
        "                {colorize_text(study['original']['explanation'])}\n",
        "            </div>\n",
        "            <div style=\"flex: 1;\">\n",
        "                <strong>Parafraza (Synonim):</strong><br>\n",
        "                {colorize_text(study['paraphrase_synonym']['explanation'])}\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "html_output += \"</div>\"\n",
        "\n",
        "display(HTML(html_output))"
      ],
      "metadata": {
        "id": "1q7-kT7qIg5Y"
      },
      "id": "1q7-kT7qIg5Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_stability_analysis(case_studies):\n",
        "    # Przygotowanie danych\n",
        "    correlations = [s['metrics']['spearman_correlation'] for s in case_studies]\n",
        "    similarities = [s['metrics']['similarity'] for s in case_studies]\n",
        "    ids = [s['case_id'] for s in case_studies]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.set_style(\"whitegrid\")\n",
        "\n",
        "    # Wykres punktowy\n",
        "    scatter = plt.scatter(similarities, correlations, c=correlations, cmap='coolwarm', s=100, edgecolors='black')\n",
        "\n",
        "    # Dodanie etykiet dla skrajnych punktów\n",
        "    for i, txt in enumerate(ids):\n",
        "        if correlations[i] < 0.3 or similarities[i] < 0.8: # Etykiety dla najciekawszych przypadków\n",
        "            plt.annotate(txt, (similarities[i], correlations[i]), xytext=(5,5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "    plt.title('Stabilność Wyjaśnień XAI vs. Podobieństwo Semantyczne Parafraz', fontsize=14)\n",
        "    plt.xlabel('Podobieństwo Semantyczne (Cosine Similarity)', fontsize=12)\n",
        "    plt.ylabel('Korelacja Map Atrybucji (Spearman)', fontsize=12)\n",
        "    plt.colorbar(scatter, label='Korelacja')\n",
        "\n",
        "    # Linie pomocnicze dla interpretacji\n",
        "    plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.3, label='Próg stabilności')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('xai_stability_plot.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "plot_stability_analysis(case_studies)"
      ],
      "metadata": {
        "id": "cEcHUPewIrpZ"
      },
      "id": "cEcHUPewIrpZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_attributions_smoothed(text, model, tokenizer, n_samples=30, stdevs=0.05):\n",
        "    \"\"\"\n",
        "    Oblicza wygładzone atrybucje (SmoothGrad) z poprawką na typy danych maski.\n",
        "    \"\"\"\n",
        "    # 1. Przygotowanie wejścia\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
        "                       max_length=MAX_SEQUENCE_LENGTH).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    # Uzyskanie bazowych embeddingów\n",
        "    with torch.no_grad():\n",
        "        input_embeddings = model.distilbert.embeddings(input_ids)\n",
        "\n",
        "    # 2. Definicja funkcji forward operującej na embeddingach\n",
        "    def forward_with_embeddings(embeddings):\n",
        "        # KLUCZOWA POPRAWKA: Rzutujemy maskę na typ taki sam jak embeddingi (Float)\n",
        "        # To eliminuje błąd RuntimeError: Expected attn_mask dtype...\n",
        "        mask = inputs['attention_mask'].to(embeddings.dtype)\n",
        "\n",
        "        # Wykorzystujemy oficjalny parametr inputs_embeds modelu\n",
        "        outputs = model(inputs_embeds=embeddings, attention_mask=mask)\n",
        "        return outputs.logits\n",
        "\n",
        "    # 3. Konfiguracja XAI\n",
        "    from captum.attr import IntegratedGradients, NoiseTunnel\n",
        "    ig = IntegratedGradients(forward_with_embeddings)\n",
        "    nt = NoiseTunnel(ig)\n",
        "\n",
        "    # 4. Obliczanie atrybucji\n",
        "    # n_steps ustawiamy na 5, aby przyspieszyć obliczenia przy wielu próbach SmoothGrad\n",
        "    attributions = nt.attribute(input_embeddings,\n",
        "                                 nt_type='smoothgrad',\n",
        "                                 nt_samples=n_samples,\n",
        "                                 stdevs=stdevs,\n",
        "                                 target=0,\n",
        "                                 n_steps=5)\n",
        "\n",
        "    # 5. Agregacja i normalizacja\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "\n",
        "    if torch.norm(attributions) != 0:\n",
        "        attributions = attributions / torch.norm(attributions)\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    return list(zip(tokens, attributions.cpu().detach().numpy()))"
      ],
      "metadata": {
        "id": "njnrrWulJysC"
      },
      "id": "njnrrWulJysC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_comparison = []\n",
        "\n",
        "print(\">>> Testowanie poprawy stabilności przez SmoothGrad...\")\n",
        "\n",
        "# Testujemy na tych samych przykładach co wcześniej\n",
        "for idx, row in sample_df.head(10).iterrows():\n",
        "    orig_text = row['comment_text']\n",
        "    syn_text = synonym_paraphraser(orig_text, n_changes=2)\n",
        "\n",
        "    # 1. Standardowe IG (to co miałeś)\n",
        "    attr_orig_std = get_word_attributions(orig_text, model, tokenizer)\n",
        "    attr_syn_std = get_word_attributions(syn_text, model, tokenizer)\n",
        "\n",
        "    # 2. SmoothGrad IG (nowość)\n",
        "    attr_orig_smooth = get_word_attributions_smoothed(orig_text, model, tokenizer, n_samples=15)\n",
        "    attr_syn_smooth = get_word_attributions_smoothed(syn_text, model, tokenizer, n_samples=15)\n",
        "\n",
        "    # Funkcja pomocnicza do korelacji\n",
        "    def get_corr(a1, a2):\n",
        "        min_l = min(len(a1), len(a2))\n",
        "        return spearmanr([float(x[1]) for x in a1[:min_l]],\n",
        "                         [float(x[1]) for x in a2[:min_l]])[0]\n",
        "\n",
        "    corr_std = get_corr(attr_orig_std, attr_syn_std)\n",
        "    corr_smooth = get_corr(attr_orig_smooth, attr_syn_smooth)\n",
        "\n",
        "    results_comparison.append({\n",
        "        \"ID\": idx,\n",
        "        \"Korelacja Standardowa\": round(corr_std, 4),\n",
        "        \"Korelacja SmoothGrad\": round(corr_smooth, 4),\n",
        "        \"Poprawa\": round(corr_smooth - corr_std, 4)\n",
        "    })\n",
        "\n",
        "# Wyświetlenie porównania\n",
        "df_comp = pd.DataFrame(results_comparison)\n",
        "display(df_comp)\n",
        "\n",
        "print(f\"\\nŚrednia poprawa korelacji: {df_comp['Poprawa'].mean():.4f}\")"
      ],
      "metadata": {
        "id": "bL_RvpqKJ2iE"
      },
      "id": "bL_RvpqKJ2iE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wizualizacja przypadku, który najbardziej zyskał (9074)\n",
        "best_improvement_id = 9074\n",
        "\n",
        "# Pobieramy wyjaśnienia obiema metodami\n",
        "attr_orig_std = get_word_attributions(sample_df.loc[best_improvement_id, 'comment_text'], model, tokenizer)\n",
        "attr_orig_smooth = get_word_attributions_smoothed(sample_df.loc[best_improvement_id, 'comment_text'], model, tokenizer, n_samples=30, stdevs=0.05)\n",
        "\n",
        "html_compare = f\"\"\"\n",
        "<h3>Analiza poprawy stabilności dla Case ID: {best_improvement_id}</h3>\n",
        "<div style=\"display: flex; gap: 20px;\">\n",
        "    <div style=\"flex: 1;\">\n",
        "        <strong>Standard IG (Mała stabilność):</strong><br>\n",
        "        {colorize_text(attr_orig_std)}\n",
        "    </div>\n",
        "    <div style=\"flex: 1;\">\n",
        "        <strong>SmoothGrad (Większa stabilność):</strong><br>\n",
        "        {colorize_text(attr_orig_smooth)}\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "display(HTML(html_compare))"
      ],
      "metadata": {
        "id": "2uPtMdiXKyyl"
      },
      "id": "2uPtMdiXKyyl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "final_results = []\n",
        "\n",
        "print(\">>> Generowanie ostatecznego zestawienia danych...\")\n",
        "\n",
        "# Łączymy wyniki z różnych testów (Mistral, Synonimy, SmoothGrad)\n",
        "for study in case_studies:\n",
        "    case_id = study['case_id']\n",
        "\n",
        "    # Próbujemy znaleźć odpowiadający wynik z testu SmoothGrad\n",
        "    smooth_data = next((item for item in results_comparison if item['ID'] == case_id), None)\n",
        "\n",
        "    final_results.append({\n",
        "        \"ID\": case_id,\n",
        "        \"Original_Text\": study['original']['text'],\n",
        "        \"Paraphrase_Text\": study['paraphrase_synonym']['text'],\n",
        "        \"Semantic_Similarity\": study['metrics']['similarity'],\n",
        "        \"XAI_Corr_Standard\": study['metrics']['spearman_correlation'],\n",
        "        \"XAI_Corr_SmoothGrad\": smooth_data['Korelacja SmoothGrad'] if smooth_data else \"N/A\",\n",
        "        \"Improvement\": smooth_data['Poprawa'] if smooth_data else 0\n",
        "    })\n",
        "\n",
        "# Zapis do CSV\n",
        "output_file = 'final_xai_analysis.csv'\n",
        "keys = final_results[0].keys()\n",
        "\n",
        "with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
        "    dict_writer = csv.DictWriter(f, fieldnames=keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(final_results)\n",
        "\n",
        "print(f\"✓ Sukces! Plik '{output_file}' jest gotowy do pobrania.\")"
      ],
      "metadata": {
        "id": "8MccmjMGLSi1"
      },
      "id": "8MccmjMGLSi1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}