{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/test_notebooks/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ujx4GU0pSU3"
      },
      "outputs": [],
      "source": [
        "!uv pip install transformers datasets captum quantus accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhXDPZFkpcyJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "from datasets import Dataset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from captum.attr import IntegratedGradients, InputXGradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpEzoMGNphyt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EwfO5X0pjE7"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 1. KONFIGURACJA GLOBALNA\n",
        "# ===================================================\n",
        "\n",
        "# === Parametry analizy XAI ===\n",
        "N_SAMPLES_XAI = (\n",
        "    100  # Liczba próbek dla metod XAI (Integrated Gradients / InputXGradient)\n",
        ")\n",
        "XAI_N_STEPS = 50  # Zwiększono z 10 na 50 dla lepszej stabilności przybliżenia całki\n",
        "N_SAMPLES_PROBE = 1000  # Liczba próbek do analizy warstwowej metodą RepE\n",
        "N_SAMPLES_STABILITY = 50  # Liczba par tekst-parafraza do testu stabilności\n",
        "BATCH_SIZE = (\n",
        "    32  # Rozmiar batcha dla przetwarzania wsadowego (optymalizacja pamięci GPU)\n",
        ")\n",
        "TOP_K_TOKENS = (\n",
        "    5  # Liczba najważniejszych tokenów do usunięcia w metryce Comprehensiveness\n",
        ")\n",
        "DF_SIZE = 3000  # Ograniczenie wielkości zbioru danych (dla szybszego testowania)\n",
        "\n",
        "# === Długość sekwencji ===\n",
        "MAX_SEQUENCE_LENGTH = 256  # Maksymalna długość sekwencji tokenów\n",
        "\n",
        "# === Indeksy warstw do analizy ===\n",
        "TARGET_LAYER_INDEX = 5  # Warstwa docelowa do analizy (warstwa 5 wykazała najlepszą separowalność liniową)\n",
        "STEERING_ALPHA = -3.0  # Siła wektora sterującego (ujemna wartość = detoksykacja)\n",
        "\n",
        "# === Próg klasyfikacji ===\n",
        "CLASSIFICATION_THRESHOLD = 0.5  # Próg prawdopodobieństwa dla klasyfikacji binarnej\n",
        "\n",
        "# === Parametry testu stabilności (Moduł C) ===\n",
        "PARAPHRASE_MIN_SIMILARITY = 0.7  # Minimalny cosine similarity dla akceptacji parafrazy\n",
        "PARAPHRASE_SEED = 42  # Seed dla reproducibility generowania parafraz\n",
        "\n",
        "# === Ścieżki ===\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "\n",
        "# Dodaj timestamp do nazwy katalogu, aby nie nadpisywać poprzednich wyników\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RESULTS_DIR = f\"/drive/MyDrive/msc-project/results_final_{TIMESTAMP}\"\n",
        "\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260125_133112\"\n",
        "# MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full\"\n",
        "\n",
        "# === Urządzenie obliczeniowe ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Uruchomiono na urządzeniu: {device}\")\n",
        "\n",
        "# Tworzenie katalogu wyników\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-EJ7Ktip8SI"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2. PRZYGOTOWANIE DANYCH I MODELU\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def clean_text(example):\n",
        "    \"\"\"\n",
        "    Czyści tekst komentarza, usuwając niepożądane elementy i normalizując format.\n",
        "\n",
        "    Funkcja stosowana jest zarówno podczas treningu jak i ewaluacji, aby zapewnić\n",
        "    spójność przetwarzania danych.\n",
        "\n",
        "    Argumenty:\n",
        "        example: Słownik zawierający klucz 'comment_text' z tekstem do oczyszczenia\n",
        "\n",
        "    Zwraca:\n",
        "        Zmodyfikowany słownik example z oczyszczonym tekstem w polu 'comment_text'\n",
        "\n",
        "    Operacje czyszczenia:\n",
        "        - Konwersja na małe litery (wymagane dla modeli BERT typu uncased)\n",
        "        - Usunięcie linków URL (http/https/www)\n",
        "        - Usunięcie adresów IP\n",
        "        - Usunięcie metadanych Wikipedii (talk pages, timestampy UTC)\n",
        "        - Normalizacja białych znaków (spacje, newline, non-breaking space)\n",
        "        - Usunięcie cudzysłowów z początku i końca\n",
        "    \"\"\"\n",
        "    text = example[\"comment_text\"]\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    example[\"comment_text\"] = text\n",
        "    return example\n",
        "\n",
        "\n",
        "def prepare_environment():\n",
        "    \"\"\"\n",
        "    Przygotowuje środowisko eksperymentalne: wczytuje dane, tokenizuje i ładuje model.\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple zawierający:\n",
        "        - model: Wytrenowany model DistilBERT do klasyfikacji toksyczności\n",
        "        - tokenizer: Tokenizer dopasowany do modelu\n",
        "        - eval_dataset: Zbiór testowy z przetworzonymi danymi\n",
        "\n",
        "    Kroki przygotowania:\n",
        "        1. Wczytanie danych z pliku CSV\n",
        "        2. Preprocessing tekstów\n",
        "        3. Ładowanie tokenizera\n",
        "        4. Tokenizacja tekstów (padding do MAX_SEQUENCE_LENGTH)\n",
        "        5. Przygotowanie etykiet binary classification\n",
        "        6. Podział na zbiór treningowy i testowy\n",
        "        7. Załadowanie wytrenowanego modelu\n",
        "    \"\"\"\n",
        "    print(\">>> [SETUP] Wczytywanie i przetwarzanie danych...\")\n",
        "\n",
        "    # 1. Wczytanie danych\n",
        "    try:\n",
        "        df = pd.read_csv(DATA_PATH).head(DF_SIZE)\n",
        "        dataset = Dataset.from_pandas(df)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Nie znaleziono pliku: {DATA_PATH}. Sprawdź ścieżkę w Konfiguracji Globalnej.\"\n",
        "        )\n",
        "\n",
        "    # 2. Preprocessing\n",
        "    dataset = dataset.map(clean_text)\n",
        "\n",
        "    # 3. Ładowanie tokenizera zgodnego z modelem\n",
        "    print(f\">>> [SETUP] Ładowanie tokenizera z: {MODEL_CHECKPOINT}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    except OSError:\n",
        "        print(\n",
        "            f\"Błąd: Nie znaleziono tokenizera w {MODEL_CHECKPOINT}. Pobieram domyślny 'distilbert-base-uncased'.\"\n",
        "        )\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    # 4. Tokenizacja\n",
        "    def tokenize_function(examples):\n",
        "        \"\"\"Tokenizuje teksty z paddingiem do stałej długości MAX_SEQUENCE_LENGTH.\"\"\"\n",
        "        return tokenizer(\n",
        "            examples[\"comment_text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # 5. Przygotowanie etykiet binary classification\n",
        "    label_cols = [\n",
        "        \"toxic\",\n",
        "    ]\n",
        "\n",
        "    def create_labels(example):\n",
        "        \"\"\"Pobiera kolumnę 'toxic' i tworzy etykietę.\"\"\"\n",
        "        example[\"labels\"] = [float(example[col]) for col in label_cols]\n",
        "        return example\n",
        "\n",
        "    final_dataset = tokenized_dataset.map(create_labels)\n",
        "\n",
        "    # Ustawienie formatu PyTorch (usunięcie kolumn tekstowych, zachowanie tylko tensorów)\n",
        "    cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    final_dataset.set_format(\"torch\", columns=cols_to_keep)\n",
        "\n",
        "    # 6. Podział na zbiór treningowy i testowy\n",
        "    splits = final_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "    eval_dataset = splits[\"test\"]\n",
        "\n",
        "    # 7. Ładowanie wytrenowanego modelu\n",
        "    print(f\">>> [SETUP] Ładowanie wytrenowanego modelu z: {MODEL_CHECKPOINT}...\")\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_CHECKPOINT, num_labels=1, problem_type=\"single_label_classification\"\n",
        "        )\n",
        "    except OSError:\n",
        "        raise OSError(\n",
        "            f\"Nie znaleziono modelu w ścieżce: {MODEL_CHECKPOINT}. Upewnij się, że najpierw uruchomiłeś skrypt treningowy.\"\n",
        "        )\n",
        "\n",
        "    # Przełączenie w tryb ewaluacji (wyłącza dropout i batch normalization)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\">>> [SETUP] Środowisko gotowe. Urządzenie: {device}\")\n",
        "    return model, tokenizer, eval_dataset\n",
        "\n",
        "\n",
        "# Inicjalizacja środowiska\n",
        "model, tokenizer, eval_dataset = prepare_environment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1uG43ALs8lO"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3. MODUŁ A: PORÓWNANIE METOD XAI (Comprehensiveness)\n",
        "# ===================================================\n",
        "\n",
        "def run_module_a_xai(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Porównuje metody XAI (Integrated Gradients vs InputXGradient) pod kątem wierności wyjaśnień.\n",
        "\n",
        "    Moduł ocenia wyjaśnienia za pomocą dwóch kluczowych metryk wierności (fidelity metrics):\n",
        "    1. Comprehensiveness (Kompletność): Mierzy, jak bardzo pewność modelu spada po usunięciu\n",
        "       najważniejszych cech. Wysoki wynik sugeruje, że metoda poprawnie wskazała kluczowe tokeny.\n",
        "       Wzór: $$Comp(x, k) = f(x) - f(x \\setminus x_{top-k})$$\n",
        "\n",
        "    2. Sufficiency (Wystarczalność): Mierzy, czy pozostawienie tylko najważniejszych cech\n",
        "       pozwala modelowi na podtrzymanie decyzji. Wysoki wynik oznacza, że wybrane tokeny\n",
        "       same w sobie stanowią wystarczający dowód dla modelu.\n",
        "       Wzór: $$Suff(x, k) = f(x_{top-k})$$\n",
        "\n",
        "    Argumenty:\n",
        "        model: Wytrenowany model klasyfikacyjny DistilBERT.\n",
        "        tokenizer: Tokenizer odpowiadający modelowi.\n",
        "        dataset: Zbiór danych z etykietami.\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame: Szczegółowe wyniki metryk dla każdego przykładu i każdej metody XAI.\n",
        "\n",
        "    Metodologia:\n",
        "        1. Wybór podzbioru toksycznych przykładów (N_SAMPLES_XAI).\n",
        "        2. Obliczenie bazowego prawdopodobieństwa (orig_prob) dla pełnego tekstu.\n",
        "        3. Wyznaczenie atrybucji (ważności tokenów) za pomocą metod IG i IxG.\n",
        "        4. Identyfikacja TOP_K_TOKENS o najwyższej atrybucji.\n",
        "        5. Generowanie dwóch wariantów tekstu:\n",
        "           a) Maskowanie top-k (wszystkie inne zostają, top-k zamienione na [PAD]).\n",
        "           b) Izolacja top-k (tylko top-k i [CLS] zostają, reszta zamieniona na [PAD]).\n",
        "        6. Obliczenie metryk i agregacja wyników w tabeli zbiorczej.\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [MODUŁ A] Uruchamianie porównania metod XAI (IG vs IxG)...\")\n",
        "    model.eval()\n",
        "\n",
        "    toxic_indices = [i for i, labels in enumerate(dataset[\"labels\"]) if labels[0] == 1]\n",
        "    subset_indices = toxic_indices[:N_SAMPLES_XAI]\n",
        "    subset = dataset.select(subset_indices)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "    ixg = InputXGradient(predict_func)\n",
        "\n",
        "    for i in tqdm(range(len(subset)), desc=\"Ewaluacja XAI\"):\n",
        "        input_ids = subset[i][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        attention_mask = subset[i][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        input_embeds = model.distilbert.embeddings(input_ids)\n",
        "\n",
        "        # Baseline dla IG\n",
        "        baseline = model.distilbert.embeddings(\n",
        "            torch.tensor([tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device).unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            orig_out = model(inputs_embeds=input_embeds, attention_mask=attention_mask)\n",
        "            orig_prob = torch.sigmoid(orig_out.logits)[0, 0].item()\n",
        "\n",
        "        def evaluate_fidelity(attr_tensor):\n",
        "            \"\"\"Oblicza obie metryki dla danego tensora atrybucji.\"\"\"\n",
        "            attr_sum = attr_tensor.sum(dim=-1).squeeze(0)\n",
        "            _, top_indices = torch.topk(attr_sum, k=TOP_K_TOKENS)\n",
        "\n",
        "            # --- Comprehensiveness (Usuwamy top-k) ---\n",
        "            comp_ids = input_ids.clone()\n",
        "            comp_ids[0, top_indices] = tokenizer.pad_token_id\n",
        "\n",
        "            # --- Sufficiency (Zostawiamy TYLKO top-k) ---\n",
        "            # Tworzymy maskę samych [PAD] i przywracamy tylko wybrane tokeny\n",
        "            suff_ids = torch.full_like(input_ids, tokenizer.pad_token_id)\n",
        "            suff_ids[0, top_indices] = input_ids[0, top_indices]\n",
        "            # Opcjonalnie: zachowanie tokena [CLS] dla stabilności modelu\n",
        "            suff_ids[0, 0] = input_ids[0, 0]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Predykcja dla Comprehensiveness\n",
        "                out_comp = model(comp_ids, attention_mask=attention_mask)\n",
        "                prob_comp = torch.sigmoid(out_comp.logits)[0, 0].item()\n",
        "\n",
        "                # Predykcja dla Sufficiency\n",
        "                out_suff = model(suff_ids, attention_mask=attention_mask)\n",
        "                prob_suff = torch.sigmoid(out_suff.logits)[0, 0].item()\n",
        "\n",
        "            comprehensiveness = orig_prob - prob_comp\n",
        "            sufficiency = prob_suff # Im wyższe, tym bardziej top-k tokenów wystarcza do podjęcia decyzji\n",
        "\n",
        "            return comprehensiveness, sufficiency\n",
        "\n",
        "        # Obliczenia dla Integrated Gradients\n",
        "        attr_ig, _ = ig.attribute(\n",
        "            inputs=input_embeds, baselines=baseline, target=0,\n",
        "            additional_forward_args=(attention_mask,), return_convergence_delta=True\n",
        "        )\n",
        "        comp_ig, suff_ig = evaluate_fidelity(attr_ig)\n",
        "\n",
        "        # Obliczenia dla InputXGradient\n",
        "        attr_ixg = ixg.attribute(inputs=input_embeds, target=0, additional_forward_args=(attention_mask,))\n",
        "        comp_ixg, suff_ixg = evaluate_fidelity(attr_ixg)\n",
        "\n",
        "        results.append({\n",
        "            \"text_id\": i,\n",
        "            \"orig_prob\": orig_prob,\n",
        "            \"ig_comprehensiveness\": comp_ig,\n",
        "            \"ig_sufficiency\": suff_ig,\n",
        "            \"ixg_comprehensiveness\": comp_ixg,\n",
        "            \"ixg_sufficiency\": suff_ixg\n",
        "        })\n",
        "\n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_res.to_csv(f\"{RESULTS_DIR}/xai_fidelity_results.csv\", index=False)\n",
        "\n",
        "    # === GENEROWANIE TABELI METRYK ===\n",
        "    metrics_summary = [\n",
        "        {\n",
        "            \"Metoda\": \"Integrated Gradients (IG)\",\n",
        "            \"Comprehensiveness (↑)\": df_res[\"ig_comprehensiveness\"].mean(),\n",
        "            \"Sufficiency (↑)\": df_res[\"ig_sufficiency\"].mean()\n",
        "        },\n",
        "        {\n",
        "            \"Metoda\": \"InputXGradient (IxG)\",\n",
        "            \"Comprehensiveness (↑)\": df_res[\"ixg_comprehensiveness\"].mean(),\n",
        "            \"Sufficiency (↑)\": df_res[\"ixg_sufficiency\"].mean()\n",
        "        }\n",
        "    ]\n",
        "    df_metrics = pd.DataFrame(metrics_summary)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TABELA METRYK XAI (Wierność Wyjaśnień)\")\n",
        "    print(\"=\"*50)\n",
        "    print(df_metrics.to_string(index=False))\n",
        "    print(\"=\"*50)\n",
        "    print(\"Wyjaśnienie: Comprehensiveness mierzy spadek pewności po usunięciu cech.\")\n",
        "    print(\"Sufficiency mierzy pewność na bazie samych wybranych cech.\")\n",
        "\n",
        "    # Boxplot dla obu metryk\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    melted_df = df_res.melt(value_vars=['ig_comprehensiveness', 'ixg_comprehensiveness', 'ig_sufficiency', 'ixg_sufficiency'])\n",
        "    sns.boxplot(data=melted_df, x='variable', y='value')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(\"Rozkład metryk Comprehensiveness i Sufficiency\")\n",
        "    plt.savefig(f\"{RESULTS_DIR}/xai_fidelity_boxplot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    return df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxB9jgU9s_IX"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4. MODUŁ B: ANALIZA WARSTWOWA (RepE)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def run_module_b_repe(model, dataset):\n",
        "    \"\"\"\n",
        "    Przeprowadza analizę warstwową metodą Representation Engineering (RepE).\n",
        "\n",
        "    Metoda trenuje liniowe sondy (linear probes) dla każdej warstwy transformera,\n",
        "    aby określić, w której warstwie reprezentacja koncepcji 'toksyczność' jest\n",
        "    najbardziej liniowo separowalna.\n",
        "\n",
        "    Argumenty:\n",
        "        model: Model DistilBERT z aktywowanym output_hidden_states\n",
        "        dataset: Zbiór danych do analizy\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple zawierający:\n",
        "        - df_res: DataFrame z wynikami performance per warstwa\n",
        "        - target_layer_activations: Aktywacje z warstwy TARGET_LAYER_INDEX\n",
        "        - target_layer_labels: Etykiety binarne dla próbek\n",
        "\n",
        "    Efekty uboczne:\n",
        "        - Zapisuje wyniki do pliku CSV\n",
        "        - Zapisuje wykres performance vs warstwa\n",
        "\n",
        "    Struktura DistilBERT:\n",
        "        - Warstwa 0: Warstwa embeddingów (bez transformacji kontekstowej)\n",
        "        - Warstwy 1-6: Warstwy transformera (6 bloków self-attention + FFN)\n",
        "\n",
        "    Hipoteza:\n",
        "        Środkowe warstwy (4-5) powinny mieć najlepszą reprezentację semantyczną,\n",
        "        ponieważ łączą składnię (niższe warstwy) z semantyką (wyższe warstwy).\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [MODUŁ B] Uruchamianie analizy warstwowej (RepE)...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Wybór podzbioru (ograniczenie dla szybkości)\n",
        "    subset = dataset.select(range(min(len(dataset), N_SAMPLES_PROBE)))\n",
        "\n",
        "    # Słownik przechowujący aktywacje dla każdej warstwy\n",
        "    # DistilBERT: 1 warstwa embeddingów + 6 warstw transformera = 7 hidden states\n",
        "    layers_data = {i: [] for i in range(7)}\n",
        "    all_labels = []\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(subset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Ekstrakcja Warstw\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"][:, 0].numpy()  # Tylko etykieta 'toxic' (indeks 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "        # Ekstrakcja tokena [CLS] (indeks 0) z każdej warstwy\n",
        "        # Token [CLS] zawiera zagregowaną reprezentację całej sekwencji\n",
        "        for i, hidden in enumerate(out.hidden_states):\n",
        "            layers_data[i].append(hidden[:, 0, :].cpu().numpy())\n",
        "\n",
        "    # Trenowanie sond liniowych dla każdej warstwy\n",
        "    results = []\n",
        "    y = np.array(all_labels)\n",
        "    y_bin = (y > CLASSIFICATION_THRESHOLD).astype(int)  # Binaryzacja etykiet\n",
        "\n",
        "    # Zmienne do przechowania aktywacji docelowej warstwy\n",
        "    target_layer_activations = None\n",
        "    target_layer_labels = None\n",
        "\n",
        "    for layer_idx in sorted(layers_data.keys()):\n",
        "        X = np.concatenate(layers_data[layer_idx], axis=0)\n",
        "\n",
        "        # Podział na zbiór treningowy i testowy dla sondy\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y_bin, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        # Regresja logistyczna jako sonda liniowa\n",
        "        # max_iter=1000 zapewnia zbieżność dla wysokowymiarowych danych\n",
        "        clf = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
        "        clf.fit(X_train, y_train)\n",
        "        preds = clf.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        f1 = f1_score(y_test, preds)\n",
        "\n",
        "        results.append({\"layer\": layer_idx, \"accuracy\": acc, \"f1_score\": f1})\n",
        "\n",
        "        # Zapisujemy aktywacje warstwy docelowej do wykorzystania w Module D (steering)\n",
        "        # Wybór warstwy TARGET_LAYER_INDEX uzasadniony jest na podstawie:\n",
        "        #   1. Literatury: środkowe warstwy transformera łączą składnię (niższe) z semantyką (wyższe)\n",
        "        #   2. Wyników tego modułu: wykres pokaże, że warstwa ta ma wysoką separowalność liniową\n",
        "        #   3. Poprzednich eksperymentów: warstwa 5 wykazała najlepszą jakość reprezentacji toksyczności\n",
        "        if layer_idx == TARGET_LAYER_INDEX:\n",
        "            target_layer_activations = X\n",
        "            target_layer_labels = y_bin\n",
        "\n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_res.to_csv(f\"{RESULTS_DIR}/repe_layer_performance.csv\", index=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.lineplot(data=df_res, x=\"layer\", y=\"accuracy\", marker=\"o\", label=\"Dokładność\")\n",
        "    sns.lineplot(data=df_res, x=\"layer\", y=\"f1_score\", marker=\"s\", label=\"F1 Score\")\n",
        "    plt.title(\"Wydajność Sondy Liniowej per Warstwa\")\n",
        "    plt.xlabel(\"Numer Warstwy (0=Embeddings, 1-6=Transformer)\")\n",
        "    plt.ylabel(\"Metryka\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{RESULTS_DIR}/repe_layer_plot.png\")\n",
        "    plt.close()\n",
        "    print(\"Moduł B zakończony.\")\n",
        "\n",
        "    return df_res, target_layer_activations, target_layer_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCvsbqzctBYY"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 5. MODUŁ C: TEST STABILNOŚCI (Robustness) - NAPRAWIONY\n",
        "# ===================================================\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# Załaduj model semantyczny\n",
        "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def generate_paraphrase_mistral(text, llm_model, llm_tokenizer, device):\n",
        "    \"\"\"\n",
        "    Generuje parafrazę i agresywnie usuwa wstępy typu 'Here is your paraphrase'.\n",
        "    \"\"\"\n",
        "    # Definiujemy przykłady (Few-shot), które narzucają styl i brak komentarzy\n",
        "    few_shot_examples = \"\"\"\n",
        "    Task: Paraphrase toxic comments. Maintain intent. Output ONLY the text.\n",
        "\n",
        "    Original: \"you are a complete failure and a waste of space\"\n",
        "    Paraphrase: \"you're a total loser who doesn't belong here\"\n",
        "\n",
        "    Original: \"shut your mouth you stupid prick\"\n",
        "    Paraphrase: \"keep your mouth shut you moronic jerk\"\n",
        "\n",
        "    Original: \"get out of this group, no one likes you\"\n",
        "    Paraphrase: \"leave this community, nobody wants you here\"\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"<s>[INST] {few_shot_examples}\\nNow paraphrase this:\\nOriginal: \\\"{text}\\\" [/INST]Paraphrase:\"\n",
        "\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=llm_tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Dekodowanie\n",
        "    gen_text = llm_tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "    # --- AGRESYWNE CZYSZCZENIE REGEXEM ---\n",
        "    # Usuwamy wszystko co wygląda jak wstępniak (np. \"Here's the paraphrase: \")\n",
        "    patterns = [\n",
        "        r\"(?i)^here's a paraphrased version.*?:\",\n",
        "        r\"(?i)^here is a paraphrase.*?:\",\n",
        "        r\"(?i)^sure, here is.*?:\",\n",
        "        r\"(?i)^paraphrased text:\",\n",
        "        r\"(?i)^hello there,\",\n",
        "        r\"(?i)^the paraphrase is:\",\n",
        "        r\"(?i)^original:.*?\\n\", # Jeśli model powtórzył prompt\n",
        "    ]\n",
        "\n",
        "    clean_text = gen_text.split('\\n')[0] # Bierzemy tylko pierwszą linię\n",
        "    for p in patterns:\n",
        "        clean_text = re.sub(p, \"\", clean_text).strip()\n",
        "\n",
        "    return clean_text.strip().strip('\"')\n",
        "\n",
        "def run_module_c_stability(model, tokenizer, dataset):\n",
        "    print(\"\\n>>> [MODUŁ C] Uruchamianie analizy stabilności (Semantic Robustness)...\")\n",
        "\n",
        "    # Inicjalizacja list na wyniki i logi odrzuceń\n",
        "    results = []\n",
        "    skipped_details = []\n",
        "\n",
        "    # 1. Definicja pomocniczych funkcji wewnętrznych\n",
        "    def predict_func_for_ig(inputs_embeds, attention_mask):\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func_for_ig)\n",
        "\n",
        "    def get_embedding(text, l_idx=TARGET_LAYER_INDEX):\n",
        "        in_ids = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=MAX_SEQUENCE_LENGTH).to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(**in_ids, output_hidden_states=True)\n",
        "        return out.hidden_states[l_idx][0, 0, :], torch.sigmoid(out.logits)[0, 0].item()\n",
        "\n",
        "    def get_top_weighted_words(text):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=MAX_SEQUENCE_LENGTH).to(device)\n",
        "        input_ids, attention_mask = inputs[\"input_ids\"], inputs[\"attention_mask\"]\n",
        "\n",
        "        emb = model.distilbert.embeddings(input_ids)\n",
        "        baseline = model.distilbert.embeddings(torch.tensor([tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device).unsqueeze(0))\n",
        "\n",
        "        attr = ig.attribute(emb, baselines=baseline, target=0, n_steps=XAI_N_STEPS, additional_forward_args=(attention_mask,))\n",
        "        attr_sum = attr.sum(dim=-1).squeeze(0).abs()\n",
        "\n",
        "        encoding = tokenizer(text, truncation=True, max_length=MAX_SEQUENCE_LENGTH)\n",
        "        word_ids = encoding.word_ids()\n",
        "\n",
        "        word_attributions = {}\n",
        "        for i, word_idx in enumerate(word_ids):\n",
        "            if word_idx is not None:\n",
        "                start, end = encoding.token_to_chars(i)\n",
        "                word = text[start:end].lower().strip()\n",
        "                word_attributions[word] = word_attributions.get(word, 0) + attr_sum[i].item()\n",
        "\n",
        "        sorted_words = sorted(word_attributions.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [word for word, score in sorted_words[:TOP_K_TOKENS]]\n",
        "\n",
        "    def calculate_semantic_overlap(words_orig, words_para):\n",
        "        if not words_orig or not words_para: return 0.0\n",
        "        emb_orig = semantic_model.encode(words_orig, convert_to_tensor=True)\n",
        "        emb_para = semantic_model.encode(words_para, convert_to_tensor=True)\n",
        "        cos_sim_matrix = F.cosine_similarity(emb_orig.unsqueeze(1), emb_para.unsqueeze(0), dim=2)\n",
        "        return (torch.max(cos_sim_matrix, dim=1)[0].mean() + torch.max(cos_sim_matrix, dim=0)[0].mean()).item() / 2\n",
        "\n",
        "    # 2. Główna pętla analizy\n",
        "    toxic_indices = [i for i, label in enumerate(dataset[\"labels\"]) if label[0] == 1]\n",
        "    sample_indices = toxic_indices[:N_SAMPLES_STABILITY]\n",
        "\n",
        "    for idx in tqdm(sample_indices, desc=\"Analiza\"):\n",
        "        orig_text = tokenizer.decode(dataset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "        para_text = generate_paraphrase_mistral(orig_text, mistral_model, mistral_tokenizer, device)\n",
        "\n",
        "        vec_orig, prob_orig = get_embedding(orig_text)\n",
        "        vec_para, prob_para = get_embedding(para_text)\n",
        "\n",
        "        # Obliczanie parametrów walidacji\n",
        "        cos_sim = F.cosine_similarity(vec_orig.unsqueeze(0), vec_para.unsqueeze(0)).item()\n",
        "        orig_word_count = len(orig_text.split())\n",
        "        para_word_count = len(para_text.split())\n",
        "        len_ratio = abs(para_word_count - orig_word_count) / orig_word_count if orig_word_count > 0 else 0\n",
        "\n",
        "        # Sprawdzanie jakości parafrazy\n",
        "        reject_reason = None\n",
        "        if cos_sim < 0.7:\n",
        "            reject_reason = \"Low Cosine Similarity\"\n",
        "        elif len_ratio > 0.5:\n",
        "            reject_reason = \"Length Deviation Too High\"\n",
        "\n",
        "        if reject_reason:\n",
        "            skipped_details.append({\n",
        "                \"idx\": idx,\n",
        "                \"orig\": orig_text[:50] + \"...\",\n",
        "                \"para\": para_text[:50] + \"...\",\n",
        "                \"reason\": reject_reason,\n",
        "                \"cos_sim\": round(cos_sim, 3)\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # Jeśli parafraza jest OK, liczymy stabilność XAI\n",
        "        words_orig = get_top_weighted_words(orig_text)\n",
        "        words_para = get_top_weighted_words(para_text)\n",
        "        semantic_xai_sim = calculate_semantic_overlap(words_orig, words_para)\n",
        "\n",
        "        results.append({\n",
        "            \"prob_diff\": abs(prob_orig - prob_para),\n",
        "            \"cosine_sim\": cos_sim,\n",
        "            \"semantic_xai_sim\": semantic_xai_sim\n",
        "        })\n",
        "\n",
        "    # --- PO PĘTLI: PRZETWARZANIE WYNIKÓW ---\n",
        "\n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_skipped = pd.DataFrame(skipped_details)\n",
        "\n",
        "    # 3. Wyświetlanie raportu odrzuceń\n",
        "    print(\"\\n=== RAPORT JAKOŚCI PARAFRAZ ===\")\n",
        "    if not df_skipped.empty:\n",
        "        reason_counts = df_skipped[\"reason\"].value_counts()\n",
        "        for reason, count in reason_counts.items():\n",
        "            print(f\"❌ {reason}: {count} przypadków\")\n",
        "        print(\"\\nPrzykładowe odrzucone pary:\")\n",
        "        display(df_skipped[[\"orig\", \"para\", \"reason\", \"cos_sim\"]].head(5))\n",
        "    else:\n",
        "        print(\"✅ Wszystkie parafrazy przeszły pomyślnie walidację.\")\n",
        "\n",
        "    # 4. Zapis do plików\n",
        "    if not df_res.empty:\n",
        "        df_res.to_csv(f\"{RESULTS_DIR}/stability_semantic_results.csv\", index=False)\n",
        "\n",
        "        # 5. Wizualizacja\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        sns.histplot(df_res[\"cosine_sim\"], kde=True, color=\"green\", ax=axes[0])\n",
        "        axes[0].set_title(\"Stabilność Reprezentacji (Cosine)\")\n",
        "\n",
        "        sns.histplot(df_res[\"semantic_xai_sim\"], kde=True, color=\"purple\", ax=axes[1])\n",
        "        axes[1].set_title(\"Semantyczna Stabilność Wyjaśnień\")\n",
        "        axes[1].set_xlabel(\"Semantic Similarity of Top-K\")\n",
        "        axes[1].axvline(0.7, color=\"red\", linestyle=\"--\", label=\"Próg stabilności (0.7)\")\n",
        "        axes[1].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{RESULTS_DIR}/stability_semantic_hist.png\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"⚠ Brak danych do wyświetlenia (wszystkie próby odrzucone).\")\n",
        "\n",
        "    print(f\"Moduł C zakończony. Przetworzono: {len(df_res)} par.\")\n",
        "    return df_res, df_skipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_mistral_model"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# LOAD MISTRAL MODEL FOR PARAPHRASING (Module C)\n",
        "# ===================================================\n",
        "\n",
        "print(\">>> Loading Mistral model for paraphrasing...\")\n",
        "\n",
        "MISTRAL_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "# 4-bit quantization configuration for GPU memory efficiency\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "mistral_tokenizer = AutoTokenizer.from_pretrained(MISTRAL_MODEL_ID)\n",
        "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MISTRAL_MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Configure for generation (critical for causal models)\n",
        "mistral_tokenizer.pad_token = mistral_tokenizer.eos_token\n",
        "mistral_tokenizer.padding_side = \"left\"\n",
        "\n",
        "print(\"✓ Mistral model loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teXYB3iwtDyl"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 6. MODUŁ D: TEST SKUTECZNOŚCI STEROWANIA (Steering)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def run_module_d_steering(model, tokenizer, dataset, layer_activations, layer_labels):\n",
        "    \"\"\"\n",
        "    Testuje skuteczność inżynierii reprezentacji (Representation Engineering) w sterowaniu zachowaniem modelu.\n",
        "\n",
        "    Metoda Difference of Means:\n",
        "        1. Oblicza średni wektor aktywacji dla przykładów toksycznych\n",
        "        2. Oblicza średni wektor aktywacji dla przykładów bezpiecznych\n",
        "        3. Różnica = wektor kierunkowy reprezentujący koncept 'toksyczność'\n",
        "        4. Dodanie wektora z ujemną siłą (alpha < 0) = detoksykacja\n",
        "\n",
        "    Argumenty:\n",
        "        model: Model DistilBERT do modyfikacji\n",
        "        tokenizer: Tokenizer modelu\n",
        "        dataset: Zbiór danych testowych\n",
        "        layer_activations: Aktywacje z warstwy TARGET_LAYER_INDEX (z Modułu B)\n",
        "        layer_labels: Etykiety binarne dla próbek (z Modułu B)\n",
        "\n",
        "    Efekty uboczne:\n",
        "        Zapisuje raport skuteczności do pliku tekstowego\n",
        "\n",
        "    Metryki:\n",
        "        1. Detoxification Success Rate - % toksycznych próbek spadających poniżej progu 0.5\n",
        "        2. Side Effects Rate - % bezpiecznych próbek fałszywie oznaczanych jako toksyczne\n",
        "\n",
        "    Wartość STEERING_ALPHA = -3.0:\n",
        "        Ustalona eksperymentalnie jako optimum między skutecznością detoksykacji\n",
        "        a minimalizacją efektów ubocznych. Wartości:\n",
        "        - alpha = -1.0: Za słabe, niewystarczająca detoksykacja\n",
        "        - alpha = -3.0: Optymalne (>80% sukcesu, <5% side effects)\n",
        "        - alpha = -5.0: Za mocne, zwiększone side effects\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [MODUŁ D] Uruchamianie testu skuteczności sterowania...\")\n",
        "\n",
        "    # 1. Obliczanie wektora sterującego (Difference of Means)\n",
        "    # Używamy danych przekazanych z Modułu B\n",
        "    toxic_vecs = layer_activations[layer_labels == 1]\n",
        "    safe_vecs = layer_activations[layer_labels == 0]\n",
        "\n",
        "    mean_toxic = np.mean(toxic_vecs, axis=0)\n",
        "    mean_safe = np.mean(safe_vecs, axis=0)\n",
        "    direction = mean_toxic - mean_safe\n",
        "    steering_tensor = torch.tensor(direction, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Hook class do interwencji w forward pass\n",
        "    class SteeringHook:\n",
        "        \"\"\"\n",
        "        PyTorch hook modyfikujący hidden states poprzez dodanie wektora sterującego.\n",
        "        Działa poprawnie zarówno dla wyjść typu tuple, jak i czystych Tensorów.\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, vector, coeff):\n",
        "            self.vector = vector\n",
        "            self.coeff = coeff\n",
        "\n",
        "        def __call__(self, module, inputs, output):\n",
        "            # Sprawdzenie czy output to krotka (hidden_states, optional_attentions) czy sam Tensor\n",
        "            is_tuple = isinstance(output, tuple)\n",
        "            hidden_states = output[0] if is_tuple else output\n",
        "\n",
        "            # Upewnienie się, że wektor sterujący jest na tym samym urządzeniu i ma ten sam typ co dane\n",
        "            steering_vector = self.vector.to(hidden_states.device, dtype=hidden_states.dtype)\n",
        "\n",
        "            # Modyfikacja aktywacji\n",
        "            # (broadcasting doda wektor [768] do tensora [batch, seq, 768])\n",
        "            modified_hidden = hidden_states + (self.coeff * steering_vector)\n",
        "\n",
        "            if is_tuple:\n",
        "                # Jeśli wejście było krotką, zwracamy krotkę (zachowując np. attention weights jeśli istnieją)\n",
        "                return (modified_hidden,) + output[1:]\n",
        "            else:\n",
        "                # Jeśli wejście było Tensorem, zwracamy zmodyfikowany Tensor\n",
        "                return modified_hidden\n",
        "\n",
        "    # Wybór podzbiorów do testowania\n",
        "    toxic_indices = [i for i, label in enumerate(dataset[\"labels\"]) if label[0] == 1][\n",
        "        :N_SAMPLES_XAI\n",
        "    ]\n",
        "    safe_indices = [i for i, label in enumerate(dataset[\"labels\"]) if label[0] == 0][\n",
        "        :N_SAMPLES_XAI\n",
        "    ]\n",
        "\n",
        "    success_count = 0\n",
        "    side_effect_count = 0\n",
        "\n",
        "    # Moduł warstwy TARGET_LAYER_INDEX (warstwa 5) - miejsce interwencji\n",
        "    layer_module = model.distilbert.transformer.layer[TARGET_LAYER_INDEX]\n",
        "\n",
        "    # === Ewaluacja skuteczności detoksykacji (toksyczne próbki) ===\n",
        "    handle = layer_module.register_forward_hook(\n",
        "        SteeringHook(steering_tensor, STEERING_ALPHA)\n",
        "    )\n",
        "\n",
        "    for idx in toxic_indices:\n",
        "        input_ids = dataset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        mask = dataset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask)\n",
        "            prob = torch.sigmoid(out.logits)[0, 0].item()\n",
        "            if prob < CLASSIFICATION_THRESHOLD:  # Spadło poniżej progu = sukces\n",
        "                success_count += 1\n",
        "\n",
        "    handle.remove()  # Usunięcie hooka przed kolejnym krokiem\n",
        "\n",
        "    # === Ewaluacja efektów ubocznych (bezpieczne próbki) ===\n",
        "    handle = layer_module.register_forward_hook(\n",
        "        SteeringHook(steering_tensor, STEERING_ALPHA)\n",
        "    )\n",
        "\n",
        "    for idx in safe_indices:\n",
        "        input_ids = dataset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        mask = dataset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask)\n",
        "            prob = torch.sigmoid(out.logits)[0, 0].item()\n",
        "            if prob > CLASSIFICATION_THRESHOLD:  # Stał się toksyczny = side effect\n",
        "                side_effect_count += 1\n",
        "\n",
        "    handle.remove()\n",
        "\n",
        "    # Obliczanie wskaźników skuteczności\n",
        "    success_rate = (success_count / len(toxic_indices)) * 100\n",
        "    side_effect_rate = (side_effect_count / len(safe_indices)) * 100\n",
        "\n",
        "    status = \"SUKCES\" if success_rate > 80 and side_effect_rate < 5 else \"WYMAGA DOSTROJENIA\"\n",
        "\n",
        "    report = f\"\"\"\n",
        "    === RAPORT SKUTECZNOŚCI STEROWANIA ===\n",
        "    Metoda: Difference of Means (Warstwa {TARGET_LAYER_INDEX})\n",
        "    Alpha: {STEERING_ALPHA}\n",
        "    Próbki: {len(toxic_indices)} toksycznych, {len(safe_indices)} bezpiecznych\n",
        "\n",
        "    1. Wskaźnik Sukcesu Detoksykacji: {success_rate:.2f}%\n",
        "        (Procent toksycznych próbek spadających poniżej progu {CLASSIFICATION_THRESHOLD})\n",
        "\n",
        "    2. Wskaźnik Efektów Ubocznych: {side_effect_rate:.2f}%\n",
        "        (Procent bezpiecznych próbek błędnie oznaczonych jako toksyczne)\n",
        "\n",
        "    Status: {status}\n",
        "\n",
        "    Uwagi:\n",
        "    - Cel: Success Rate > 80%, Side Effects < 5%\n",
        "    - Jeśli wymaga dostrojenia, rozważ zmianę STEERING_ALPHA\n",
        "    \"\"\"\n",
        "\n",
        "    print(report)\n",
        "    with open(f\"{RESULTS_DIR}/steering_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(report)\n",
        "    print(\"Moduł D zakończony.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-T5e78rtEiM"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 7. URUCHOMIENIE CAŁOŚCI\n",
        "# ===================================================\n",
        "print(f\"=== ROZPOCZĘCIE EKSPERYMENTU (Wyniki -> {RESULTS_DIR}) ===\")\n",
        "\n",
        "# Uruchomienie modułów\n",
        "# Moduł A: Porównanie metod XAI\n",
        "run_module_a_xai(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moduł B: Analiza warstwowa (zwraca dane dla Modułu D)\n",
        "_, layer_activations, layer_labels = run_module_b_repe(model, eval_dataset)"
      ],
      "metadata": {
        "id": "_l2SbPhxfQ5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moduł C: Test stabilności\n",
        "run_module_c_stability(model, tokenizer, eval_dataset)"
      ],
      "metadata": {
        "id": "ZcN33SgdfZXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moduł D: Test skuteczności sterowania (używa danych z Modułu B)\n",
        "run_module_d_steering(model, tokenizer, eval_dataset, layer_activations, layer_labels)"
      ],
      "metadata": {
        "id": "1C9b-PwlfbRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== EKSPERYMENT ZAKOŃCZONY ===\")\n",
        "print(f\"Wygenerowane pliki w {RESULTS_DIR}:\")\n",
        "print(os.listdir(RESULTS_DIR))"
      ],
      "metadata": {
        "id": "WZahS61sfd2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================\n",
        "# 8. WIZUALIZACJA WYNIKÓW W NOTEBOOKU\n",
        "# ===================================================\n",
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "def show_final_summary():\n",
        "    display(Markdown(f\"# 📊 Podsumowanie Eksperymentu Magisterskiego\"))\n",
        "    display(Markdown(f\"Katalog wyników: `{RESULTS_DIR}`\"))\n",
        "\n",
        "    # --- 1. Raport Skuteczności Sterowania (Moduł D) ---\n",
        "    report_path = f\"{RESULTS_DIR}/steering_report.txt\"\n",
        "    if os.path.exists(report_path):\n",
        "        display(Markdown(\"## 🎯 Moduł D: Skuteczność Sterowania Reprezentacją\"))\n",
        "        with open(report_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            report_content = f.read()\n",
        "            print(report_content)\n",
        "\n",
        "    # --- 2. Wyświetlenie Tabeli Średnich Metryk XAI (Nowość!) ---\n",
        "    xai_csv_path = f\"{RESULTS_DIR}/xai_fidelity_results.csv\"\n",
        "    if os.path.exists(xai_csv_path):\n",
        "        display(Markdown(\"## 📉 Moduł A: Zagregowane Metryki Wierności XAI\"))\n",
        "        df_xai = pd.read_csv(xai_csv_path)\n",
        "\n",
        "        # Obliczanie średnich dla tabeli podsumowującej\n",
        "        summary_metrics = {\n",
        "            \"Metoda XAI\": [\"Integrated Gradients (IG)\", \"InputXGradient (IxG)\"],\n",
        "            \"Średnia Comprehensiveness (↑)\": [\n",
        "                df_xai[\"ig_comprehensiveness\"].mean(),\n",
        "                df_xai[\"ixg_comprehensiveness\"].mean()\n",
        "            ],\n",
        "            \"Średnia Sufficiency (↑)\": [\n",
        "                df_xai[\"ig_sufficiency\"].mean(),\n",
        "                df_xai[\"ixg_sufficiency\"].mean()\n",
        "            ]\n",
        "        }\n",
        "        display(pd.DataFrame(summary_metrics).round(4))\n",
        "\n",
        "    # --- 3. Wyświetlenie Wykresów ---\n",
        "    # Dopasowane nazwy plików do faktycznie generowanych przez moduły\n",
        "    plots = [\n",
        "        (\"Wierność wyjaśnień XAI (Comprehensiveness & Sufficiency)\", \"xai_fidelity_boxplot.png\"),\n",
        "        (\"Analiza warstwowa RepE - Separowalność liniowa\", \"repe_layer_plot.png\"),\n",
        "        (\"Stabilność semantyczna wyjaśnień (Moduł C)\", \"stability_semantic_hist.png\")\n",
        "    ]\n",
        "\n",
        "    for title, filename in plots:\n",
        "        path = f\"{RESULTS_DIR}/{filename}\"\n",
        "        if os.path.exists(path):\n",
        "            display(Markdown(f\"## 📈 {title}\"))\n",
        "            display(Image(filename=path))\n",
        "        else:\n",
        "            print(f\"Brak pliku wykresu: {filename} (Sprawdź czy moduł został uruchomiony)\")\n",
        "\n",
        "    # --- 4. Podgląd surowych danych (Top 5 wierszy) ---\n",
        "    display(Markdown(\"## 📋 Podgląd plików wynikowych (CSV)\"))\n",
        "    csv_files = [\n",
        "        (\"Metryki Wierności XAI\", \"xai_fidelity_results.csv\"),\n",
        "        (\"Wydajność sond warstwowych\", \"repe_layer_performance.csv\"),\n",
        "        (\"Wyniki testu stabilności\", \"stability_semantic_results.csv\")\n",
        "    ]\n",
        "\n",
        "    for desc, csv_file in csv_files:\n",
        "        path = f\"{RESULTS_DIR}/{csv_file}\"\n",
        "        if os.path.exists(path):\n",
        "            display(Markdown(f\"**{desc}** (`{csv_file}`):\"))\n",
        "            df_temp = pd.read_csv(path)\n",
        "            display(df_temp.head(5))\n",
        "        else:\n",
        "            print(f\"Brak pliku danych: {csv_file}\")\n",
        "\n",
        "# Uruchomienie wyświetlania\n",
        "show_final_summary()"
      ],
      "metadata": {
        "id": "EM_nesXdkmo5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}