{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!uv pip install transformers datasets captum quantus accelerate bitsandbytes sentence-transformers nltk scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 0.1 IMPORTY\n",
        "# ===================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Dane i preprocessing\n",
        "from datasets import Dataset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Modele\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "# XAI\n",
        "from captum.attr import IntegratedGradients, InputXGradient, NoiseTunnel\n",
        "\n",
        "# Stabilnosc semantyczna (Modul C)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Synonimy (Modul C - alternatywa dla Mistrala)\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Zarzadzanie pamiecia\n",
        "import gc\n",
        "\n",
        "# Wizualizacja w notebooku\n",
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "# Opcje wyswietlania Pandas\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drive_mount"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "global_config"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 0.2 KONFIGURACJA GLOBALNA\n",
        "# ===================================================\n",
        "\n",
        "# === Sciezki ===\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260215_220526_FULL\"\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RESULTS_DIR = f\"/drive/MyDrive/msc-project/results_{TIMESTAMP}\"\n",
        "\n",
        "# === Parametry ogolne ===\n",
        "BATCH_SIZE = 16 # 32\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "CLASSIFICATION_THRESHOLD = 0.5\n",
        "DF_SIZE = 20000  # Ograniczenie wielkosci zbioru danych\n",
        "\n",
        "# === Parametry XAI (Modul A) ===\n",
        "N_SAMPLES_XAI = 200  # Liczba probek dla metod XAI (IG / InputXGradient)\n",
        "XAI_N_STEPS = 50     # Liczba krokow dla Integrated Gradients\n",
        "TOP_K_TOKENS = 5     # Liczba najwazniejszych tokenow do analizy Comprehensiveness\n",
        "\n",
        "# === Parametry RepE (Modul B) ===\n",
        "N_SAMPLES_PROBE = 2000  # Liczba probek do analizy warstwowej\n",
        "TARGET_LAYER_INDEX = 5  # Warstwa docelowa (najlepsza separowalnosc liniowa)\n",
        "\n",
        "# === Parametry stabilnosci (Modul C) ===\n",
        "N_SAMPLES_STABILITY = 100     # Liczba par tekst-parafraza\n",
        "PARAPHRASE_MIN_SIMILARITY = 0.7  # Minimalny cosine similarity dla akceptacji parafrazy\n",
        "PARAPHRASE_SEED = 42        # Seed dla reproducibility\n",
        "SMOOTHGRAD_N_SAMPLES = 20   # Liczba probek szumu w SmoothGrad\n",
        "SMOOTHGRAD_NOISE_STD = 0.1  # Odchylenie standardowe szumu gaussowskiego\n",
        "SYNONYM_REPLACE_RATIO = 0.3 # Procent slow do zamiany na synonimy\n",
        "\n",
        "# === Parametry Steering (Modul D) ===\n",
        "STEERING_ALPHA = -3.0       # Sila wektora sterujacego (ujemna = detoksykacja)\n",
        "ALPHA_VALUES = [-5.0, -10.0, -15.0, -18.0, -20.0, -21.0, -22.0, -23.0, -24.0, -25.0, 5.0, 10.0, 15.0, 20.0, 21.0]  # Wartosci alpha do testowania\n",
        "N_SAMPLES_PER_CLASS = 50    # Liczba probek na klase do testu steeringu\n",
        "MISTRAL_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Model LLM do parafrazowania\n",
        "\n",
        "# === Urzadzenie obliczeniowe ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Urzadzenie: {device}\")\n",
        "\n",
        "# Tworzenie katalogu wynikow\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(f\"Wyniki beda zapisane w: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_functions"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 0.3 PRZYGOTOWANIE DANYCH I MODELU\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def clean_text(example):\n",
        "    \"\"\"\n",
        "    Czysci tekst komentarza, usuwajac niepozadane elementy i normalizujac format.\n",
        "\n",
        "    Funkcja stosowana zarowno podczas treningu jak i ewaluacji, aby zapewnic\n",
        "    spojnosc przetwarzania danych.\n",
        "\n",
        "    Argumenty:\n",
        "        example: Slownik zawierajacy klucz 'comment_text' z tekstem do oczyszczenia\n",
        "\n",
        "    Zwraca:\n",
        "        Zmodyfikowany slownik example z oczyszczonym tekstem w polu 'comment_text'\n",
        "\n",
        "    Operacje czyszczenia:\n",
        "        - Konwersja na male litery (wymagane dla modeli BERT typu uncased)\n",
        "        - Usuniecie linkow URL (http/https/www)\n",
        "        - Usuniecie adresow IP\n",
        "        - Usuniecie metadanych Wikipedii (talk pages, timestampy UTC)\n",
        "        - Normalizacja bialych znakow (spacje, newline, non-breaking space)\n",
        "        - Usuniecie cudzyslowow z poczatku i konca\n",
        "    \"\"\"\n",
        "    text = example[\"comment_text\"]\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    example[\"comment_text\"] = text\n",
        "    return example\n",
        "\n",
        "\n",
        "def prepare_environment():\n",
        "    \"\"\"\n",
        "    Przygotowuje srodowisko eksperymentalne: wczytuje dane, tokenizuje i laduje model.\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple zawierajacy:\n",
        "        - model: Wytrenowany model DistilBERT do klasyfikacji toksycznosci\n",
        "        - tokenizer: Tokenizer dopasowany do modelu\n",
        "        - eval_dataset: Zbior testowy z przetworzonymi danymi\n",
        "\n",
        "    Kroki przygotowania:\n",
        "        1. Wczytanie danych z pliku CSV\n",
        "        2. Preprocessing tekstow\n",
        "        3. Ladowanie tokenizera\n",
        "        4. Tokenizacja tekstow (padding do MAX_SEQUENCE_LENGTH)\n",
        "        5. Przygotowanie etykiet binary classification\n",
        "        6. Podzial na zbior treningowy i testowy\n",
        "        7. Zaladowanie wytrenowanego modelu\n",
        "    \"\"\"\n",
        "    print(\">>> [SETUP] Wczytywanie i przetwarzanie danych...\")\n",
        "\n",
        "    # 1. Wczytanie danych\n",
        "    try:\n",
        "        # Naturalny rozklad klas z calego zbioru\n",
        "        df = pd.read_csv(DATA_PATH).sample(frac=1, random_state=42).head(DF_SIZE)\n",
        "        dataset = Dataset.from_pandas(df)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Nie znaleziono pliku: {DATA_PATH}. Sprawdz sciezke w Konfiguracji Globalnej.\"\n",
        "        )\n",
        "\n",
        "    # 2. Preprocessing\n",
        "    dataset = dataset.map(clean_text)\n",
        "\n",
        "    # 3. Ladowanie tokenizera zgodnego z modelem\n",
        "    print(f\">>> [SETUP] Ladowanie tokenizera z: {MODEL_CHECKPOINT}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    except OSError:\n",
        "        print(\n",
        "            f\"Blad: Nie znaleziono tokenizera w {MODEL_CHECKPOINT}. Pobieram domyslny 'distilbert-base-uncased'.\"\n",
        "        )\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    # 4. Tokenizacja\n",
        "    def tokenize_function(examples):\n",
        "        \"\"\"Tokenizuje teksty z paddingiem do stalej dlugosci MAX_SEQUENCE_LENGTH.\"\"\"\n",
        "        return tokenizer(\n",
        "            examples[\"comment_text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # 5. Przygotowanie etykiet binary classification\n",
        "    label_cols = [\"toxic\"]\n",
        "\n",
        "    def create_labels(example):\n",
        "        \"\"\"Mapuje wartosc 0/1 na format Long oczekiwany przez klasyfikator.\"\"\"\n",
        "        # Model z num_labels=2 oczekuje pojedynczej liczby int jako indeksu klasy\n",
        "        example[\"labels\"] = int(example[\"toxic\"])\n",
        "        return example\n",
        "\n",
        "    final_dataset = tokenized_dataset.map(create_labels)\n",
        "\n",
        "    # Ustawienie formatu PyTorch (usuniecie kolumn tekstowych, zachowanie tylko tensorow)\n",
        "    cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    final_dataset.set_format(\"torch\", columns=cols_to_keep)\n",
        "\n",
        "    # 6. Podzial na zbior treningowy i testowy\n",
        "    splits = final_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "    eval_dataset = splits[\"test\"]\n",
        "\n",
        "    # 7. Ladowanie wytrenowanego modelu\n",
        "    print(f\">>> [SETUP] Ladowanie wytrenowanego modelu z: {MODEL_CHECKPOINT}...\")\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_CHECKPOINT,\n",
        "            num_labels=2,\n",
        "            id2label={0: \"NON_TOXIC\", 1: \"TOXIC\"},\n",
        "            label2id={\"NON_TOXIC\": 0, \"TOXIC\": 1}\n",
        "        )\n",
        "    except OSError:\n",
        "        raise OSError(\n",
        "            f\"Nie znaleziono modelu w sciezce: {MODEL_CHECKPOINT}. Upewnij sie, ze najpierw uruchomiles skrypt treningowy.\"\n",
        "        )\n",
        "\n",
        "    # Przelaczenie w tryb ewaluacji (wylacza dropout i batch normalization)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\">>> [SETUP] Srodowisko gotowe. Urzadzenie: {device}\")\n",
        "    print(f\">>> [SETUP] Zbior ewaluacyjny: {len(eval_dataset)} probek\")\n",
        "    return model, tokenizer, eval_dataset\n",
        "\n",
        "\n",
        "# Inicjalizacja srodowiska\n",
        "model, tokenizer, eval_dataset = prepare_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidelity_header"
      },
      "source": [
        "---\n",
        "## Czesc 1: Analiza Wiernosci (Fidelity Check)\n",
        "\n",
        "Cel: Wykazanie, ze metody XAI wskazuja faktycznie wazne cechy.\n",
        "\n",
        "Metryki:\n",
        "- **Comprehensiveness**: Czy usuniecie najwazniejszych tokenow zmienia decyzje modelu? (wysoka wartosc = dobra metoda)\n",
        "- **Sufficiency**: Czy same najwazniejsze tokeny wystarczaja do utrzymania decyzji? (niska wartosc = dobra metoda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "experiment_fidelity"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 1. ANALIZA WIERNOSCI (FIDELITY CHECK)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def experiment_fidelity(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Porownuje metody XAI (Integrated Gradients vs InputXGradient) pod katem wiernosci wyjasnien.\n",
        "\n",
        "    Metryki:\n",
        "        - Comprehensiveness: mierzy spadek pewnosci po usunieciu TOP_K najwazniejszych tokenow.\n",
        "          Wysoki spadek = metoda XAI dobrze identyfikuje kluczowe cechy.\n",
        "        - Sufficiency: mierzy spadek pewnosci gdy zachowamy TYLKO TOP_K najwazniejszych tokenow.\n",
        "          Niski spadek = same najwazniejsze tokeny wystarczaja do utrzymania predykcji.\n",
        "\n",
        "    Argumenty:\n",
        "        model: Wytrenowany model klasyfikacyjny DistilBERT\n",
        "        tokenizer: Tokenizer odpowiadajacy modelowi\n",
        "        dataset: Zbior danych z etykietami\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z wynikami porownania metod (comprehensiveness i sufficiency dla IG i IxG)\n",
        "\n",
        "    Metodologia:\n",
        "        1. Wybor podzbioru toksycznych przykladow (N_SAMPLES_XAI)\n",
        "        2. Dla kazdego przykladu:\n",
        "            a) Obliczenie oryginalnego prawdopodobienstwa toksycznosci\n",
        "            b) Identyfikacja TOP_K_TOKENS najwazniejszych tokenow (IG i InputXGradient)\n",
        "            c) Comprehensiveness: maskowanie tych tokenow i ponowna predykcja\n",
        "            d) Sufficiency: zachowanie TYLKO tych tokenow i ponowna predykcja\n",
        "        3. Wizualizacja wynikow jako boxplot (2 subploty)\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 1] Uruchamianie analizy wiernosci (IG vs IxG)...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Filtrowanie tylko toksycznych przykladow\n",
        "    toxic_indices = [i for i, labels in enumerate(dataset[\"labels\"]) if labels.item() == 1]\n",
        "    subset_indices = toxic_indices[:N_SAMPLES_XAI]\n",
        "    subset = dataset.select(subset_indices)\n",
        "    print(f\"    Wybrano {len(subset)} toksycznych probek do analizy.\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Funkcja pomocnicza dla Captum (zwraca logity na podstawie embeddings)\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        \"\"\"Wrapper predykcji dla biblioteki Captum.\"\"\"\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "    ixg = InputXGradient(predict_func)\n",
        "\n",
        "    for i in tqdm(range(len(subset)), desc=\"Ewaluacja XAI (Fidelity)\"):\n",
        "        input_ids = subset[i][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        attention_mask = subset[i][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        input_embeds = model.distilbert.embeddings(input_ids)\n",
        "\n",
        "        # Baseline = embedding tokena [PAD] (punkt odniesienia dla IG)\n",
        "        baseline = model.distilbert.embeddings(\n",
        "            torch.tensor(\n",
        "                [tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device\n",
        "            ).unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        # 1. Oryginalne prawdopodobienstwo toksycznosci\n",
        "        with torch.no_grad():\n",
        "            orig_out = model(inputs_embeds=input_embeds, attention_mask=attention_mask)\n",
        "            # Uzywamy softmax zamiast sigmoid dla 2-wyjsciowego modelu\n",
        "            probs = torch.softmax(orig_out.logits, dim=-1)\n",
        "            orig_prob = probs[0, 1].item() # Indeks 1 to klasa TOXIC\n",
        "\n",
        "        # --- Funkcje pomocnicze do obliczania metryk ---\n",
        "\n",
        "        def calculate_comprehensiveness(attr_tensor):\n",
        "            \"\"\"\n",
        "            Comprehensiveness: maskuje TOP_K najwazniejszych tokenow (zamiana na [PAD]).\n",
        "            Wysoki wynik = metoda dobrze identyfikuje wazne tokeny.\n",
        "\n",
        "            Zwraca:\n",
        "                Spadek prawdopodobienstwa (orig_prob - new_prob)\n",
        "            \"\"\"\n",
        "            # Suma po wymiarze embeddingow -> waznosc na poziomie tokenow\n",
        "            attr_sum = attr_tensor.sum(dim=-1).squeeze(0)\n",
        "            # Znajdz TOP_K najwazniejszych tokenow\n",
        "            _, top_indices = torch.topk(attr_sum, k=TOP_K_TOKENS)\n",
        "\n",
        "            # Maskowanie tokenow (zamiana na [PAD])\n",
        "            masked_ids = input_ids.clone()\n",
        "            masked_ids[0, top_indices] = tokenizer.pad_token_id\n",
        "\n",
        "            with torch.no_grad():\n",
        "                new_out = model(masked_ids, attention_mask=attention_mask)\n",
        "                new_probs = torch.softmax(new_out.logits, dim=-1)\n",
        "                new_prob = new_probs[0, 1].item()\n",
        "\n",
        "            return orig_prob - new_prob\n",
        "\n",
        "        def calculate_sufficiency(attr_tensor):\n",
        "            \"\"\"\n",
        "            Sufficiency: zachowuje TYLKO TOP_K najwazniejszych tokenow, reszta -> [PAD].\n",
        "            Niski wynik = same najwazniejsze tokeny wystarczaja do utrzymania predykcji.\n",
        "\n",
        "            Zwraca:\n",
        "                Spadek prawdopodobienstwa (orig_prob - new_prob)\n",
        "            \"\"\"\n",
        "            attr_sum = attr_tensor.sum(dim=-1).squeeze(0)\n",
        "            _, top_indices = torch.topk(attr_sum, k=TOP_K_TOKENS)\n",
        "\n",
        "            # Zachowaj TYLKO top-K tokenow, reszta -> [PAD]\n",
        "            masked_ids = torch.full_like(input_ids, tokenizer.pad_token_id)\n",
        "            masked_ids[0, top_indices] = input_ids[0, top_indices]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                new_out = model(masked_ids, attention_mask=attention_mask)\n",
        "                new_probs = torch.softmax(new_out.logits, dim=-1)\n",
        "                new_prob = new_probs[0, 1].item()\n",
        "\n",
        "            return orig_prob - new_prob\n",
        "\n",
        "        # 2. Metoda Integrated Gradients\n",
        "        attr_ig, _ = ig.attribute(\n",
        "            inputs=input_embeds,\n",
        "            baselines=baseline,\n",
        "            target=1,\n",
        "            n_steps=XAI_N_STEPS,\n",
        "            additional_forward_args=(attention_mask,),\n",
        "            return_convergence_delta=True,\n",
        "        )\n",
        "        comp_ig = calculate_comprehensiveness(attr_ig)\n",
        "        suff_ig = calculate_sufficiency(attr_ig)\n",
        "\n",
        "        # 3. Metoda InputXGradient\n",
        "        attr_ixg = ixg.attribute(\n",
        "            inputs=input_embeds, target=1, additional_forward_args=(attention_mask,)\n",
        "        )\n",
        "        comp_ixg = calculate_comprehensiveness(attr_ixg)\n",
        "        suff_ixg = calculate_sufficiency(attr_ixg)\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"text_id\": i,\n",
        "                \"original_prob\": orig_prob,\n",
        "                \"ig_comprehensiveness\": comp_ig,\n",
        "                \"ixg_comprehensiveness\": comp_ixg,\n",
        "                \"ig_sufficiency\": suff_ig,\n",
        "                \"ixg_sufficiency\": suff_ixg,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # Zapis wynikow\n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_res.to_csv(f\"{RESULTS_DIR}/fidelity_results.csv\", index=False)\n",
        "\n",
        "    # Wizualizacja: 2 subploty (Comprehensiveness | Sufficiency)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Subplot 1: Comprehensiveness\n",
        "    sns.boxplot(\n",
        "        data=df_res[[\"ig_comprehensiveness\", \"ixg_comprehensiveness\"]],\n",
        "        ax=axes[0],\n",
        "    )\n",
        "    axes[0].set_title(\n",
        "        f\"Comprehensiveness - Usunieto {TOP_K_TOKENS} Najwazniejszych Tokenow\"\n",
        "    )\n",
        "    axes[0].set_ylabel(\"Spadek Prawdopodobienstwa\")\n",
        "    axes[0].set_xticklabels([\"IG\", \"IxG\"])\n",
        "\n",
        "    # Subplot 2: Sufficiency\n",
        "    sns.boxplot(\n",
        "        data=df_res[[\"ig_sufficiency\", \"ixg_sufficiency\"]],\n",
        "        ax=axes[1],\n",
        "    )\n",
        "    axes[1].set_title(\n",
        "        f\"Sufficiency - Zachowano TYLKO {TOP_K_TOKENS} Najwazniejszych Tokenow\"\n",
        "    )\n",
        "    axes[1].set_ylabel(\"Spadek Prawdopodobienstwa\")\n",
        "    axes[1].set_xticklabels([\"IG\", \"IxG\"])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fidelity_boxplot.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    # Podsumowanie statystyk\n",
        "    print(\"\\n=== PODSUMOWANIE WIERNOSCI (FIDELITY) ===\")\n",
        "    print(f\"Probek: {len(df_res)}\")\n",
        "    print(f\"\\nComprehensiveness (wyzsza = lepsza metoda):\")\n",
        "    print(f\"  IG  - srednia: {df_res['ig_comprehensiveness'].mean():.4f}, mediana: {df_res['ig_comprehensiveness'].median():.4f}\")\n",
        "    print(f\"  IxG - srednia: {df_res['ixg_comprehensiveness'].mean():.4f}, mediana: {df_res['ixg_comprehensiveness'].median():.4f}\")\n",
        "    print(f\"\\nSufficiency (nizsza = lepsza metoda):\")\n",
        "    print(f\"  IG  - srednia: {df_res['ig_sufficiency'].mean():.4f}, mediana: {df_res['ig_sufficiency'].median():.4f}\")\n",
        "    print(f\"  IxG - srednia: {df_res['ixg_sufficiency'].mean():.4f}, mediana: {df_res['ixg_sufficiency'].median():.4f}\")\n",
        "\n",
        "    print(\"\\nCzesc 1 zakonczona.\")\n",
        "    return df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_fidelity"
      },
      "outputs": [],
      "source": [
        "df_fidelity = experiment_fidelity(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stability_header"
      },
      "source": [
        "---\n",
        "## Czesc 2: Analiza Stabilnosci (Robustness & Stability)\n",
        "\n",
        "Cel: Wykazanie, ze standardowe metody XAI (IG) sa niestabilne przy parafrazach tekstu,\n",
        "a technika SmoothGrad znaczaco poprawia stabilnosc wyjasnien.\n",
        "\n",
        "Podejscie:\n",
        "- **Dwie metody parafrazowania**: Mistral-7B (semantyczna parafraza) + zamiana synonimow (WordNet)\n",
        "- **Dwie metody XAI**: Standard IG vs SmoothGrad (IG + szum gaussowski)\n",
        "- **Dwie metryki porownania**: Korelacja Spearmana (na wspolnym slowniku) + Semantic Overlap (top-K slow)\n",
        "\n",
        "Oczekiwany wynik: SmoothGrad daje wyzsza korelacje miedzy wyjasnieniam dla oryginalow i parafraz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_paraphrase_gen"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.1 GENEROWANIE PARAFRAZ (MISTRAL + SYNONIMY)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def generate_paraphrase_mistral(text, llm_model, llm_tokenizer, llm_device):\n",
        "    \"\"\"\n",
        "    Generuje parafraze toksycznego komentarza za pomoca Mistral-7B z few-shot promptingiem.\n",
        "\n",
        "    Wykorzystuje agresywne czyszczenie regexem, aby usunac typowe wstepy generowane\n",
        "    przez model (np. 'Here is your paraphrase').\n",
        "\n",
        "    Argumenty:\n",
        "        text: Tekst oryginalny do sparafrazowania\n",
        "        llm_model: Zaladowany model Mistral-7B\n",
        "        llm_tokenizer: Tokenizer Mistrala\n",
        "        llm_device: Urzadzenie obliczeniowe\n",
        "\n",
        "    Zwraca:\n",
        "        Oczyszczona parafraza jako string\n",
        "    \"\"\"\n",
        "    few_shot_examples = \"\"\"\n",
        "    Task: Paraphrase toxic comments. Maintain intent. Output ONLY the text.\n",
        "\n",
        "    Original: \"you are a complete failure and a waste of space\"\n",
        "    Paraphrase: \"you're a total loser who doesn't belong here\"\n",
        "\n",
        "    Original: \"shut your mouth you stupid prick\"\n",
        "    Paraphrase: \"keep your mouth shut you moronic jerk\"\n",
        "\n",
        "    Original: \"get out of this group, no one likes you\"\n",
        "    Paraphrase: \"leave this community, nobody wants you here\"\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"<s>[INST] {few_shot_examples}\\nNow paraphrase this:\\nOriginal: \\\"{text}\\\" [/INST]Paraphrase:\"\n",
        "\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(llm_model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=llm_tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    gen_text = llm_tokenizer.decode(\n",
        "        outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True\n",
        "    ).strip()\n",
        "\n",
        "    # Agresywne czyszczenie regexem\n",
        "    patterns = [\n",
        "        r\"(?i)^here's a paraphrased version.*?:\",\n",
        "        r\"(?i)^here is a paraphrase.*?:\",\n",
        "        r\"(?i)^sure, here is.*?:\",\n",
        "        r\"(?i)^paraphrased text:\",\n",
        "        r\"(?i)^hello there,\",\n",
        "        r\"(?i)^the paraphrase is:\",\n",
        "        r\"(?i)^original:.*?\\n\",\n",
        "    ]\n",
        "\n",
        "    clean = gen_text.split('\\n')[0]\n",
        "    for p in patterns:\n",
        "        clean = re.sub(p, \"\", clean).strip()\n",
        "\n",
        "    return clean.strip().strip('\"')\n",
        "\n",
        "\n",
        "def generate_synonym_paraphrase(text, replace_ratio=SYNONYM_REPLACE_RATIO):\n",
        "    \"\"\"\n",
        "    Generuje parafraze przez losowa zamiane slow na synonimy z WordNet.\n",
        "\n",
        "    Metoda deterministyczna i szybka - nie wymaga modelu LLM.\n",
        "    Zamienia tylko rzeczowniki, czasowniki, przymiotniki i przyslowki.\n",
        "\n",
        "    Argumenty:\n",
        "        text: Tekst oryginalny\n",
        "        replace_ratio: Jaki procent slow zamienic (domyslnie SYNONYM_REPLACE_RATIO)\n",
        "\n",
        "    Zwraca:\n",
        "        Tekst z zamienionymi slowami na synonimy\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    n_to_replace = max(1, int(len(words) * replace_ratio))\n",
        "\n",
        "    # Wybierz losowe indeksy do zamiany\n",
        "    np.random.seed(None)  # Losowy seed dla roznorodnosci\n",
        "    candidate_indices = list(range(len(words)))\n",
        "    np.random.shuffle(candidate_indices)\n",
        "\n",
        "    replaced = 0\n",
        "    new_words = words.copy()\n",
        "\n",
        "    for idx in candidate_indices:\n",
        "        if replaced >= n_to_replace:\n",
        "            break\n",
        "\n",
        "        word = words[idx].lower().strip('.,!?;:')\n",
        "        if len(word) < 3:  # Pomijaj krotkie slowa\n",
        "            continue\n",
        "\n",
        "        # Szukaj synonimow w WordNet\n",
        "        synsets = wordnet.synsets(word)\n",
        "        synonyms = set()\n",
        "        for syn in synsets:\n",
        "            for lemma in syn.lemmas():\n",
        "                name = lemma.name().replace('_', ' ')\n",
        "                if name.lower() != word:\n",
        "                    synonyms.add(name)\n",
        "\n",
        "        if synonyms:\n",
        "            synonym = np.random.choice(list(synonyms))\n",
        "            # Zachowaj oryginalna interpunkcje\n",
        "            suffix = ''\n",
        "            if words[idx][-1] in '.,!?;:':\n",
        "                suffix = words[idx][-1]\n",
        "            new_words[idx] = synonym + suffix\n",
        "            replaced += 1\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "\n",
        "def generate_all_paraphrases(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Generuje parafrazy obiema metodami (Mistral + Synonimy) dla N_SAMPLES_STABILITY\n",
        "    toksycznych przykladow. Zarzadza pamiecia GPU - laduje i zwalnia Mistrala.\n",
        "\n",
        "    Argumenty:\n",
        "        model: Model DistilBERT (potrzebny do walidacji jakosci parafraz)\n",
        "        tokenizer: Tokenizer DistilBERT\n",
        "        dataset: Zbior ewaluacyjny\n",
        "\n",
        "    Zwraca:\n",
        "        Lista slownikow z parami (oryginal, parafraza_mistral, parafraza_synonym)\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 2] Generowanie parafraz...\")\n",
        "\n",
        "    # Pobieranie NLTK data (jednorazowo)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "    # Filtrowanie toksycznych przykladow\n",
        "    toxic_indices = [i for i, labels in enumerate(dataset[\"labels\"]) if labels.item() == 1]\n",
        "    sample_indices = toxic_indices[:N_SAMPLES_STABILITY]\n",
        "    print(f\"    Wybrano {len(sample_indices)} toksycznych probek.\")\n",
        "\n",
        "    # Dekodowanie tekstow z tokenow\n",
        "    original_texts = [\n",
        "        tokenizer.decode(dataset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "        for idx in sample_indices\n",
        "    ]\n",
        "\n",
        "    # --- FAZA 1: Generowanie parafraz Mistralem ---\n",
        "    print(\"\\n    [Faza 1/3] Ladowanie Mistral-7B do generowania parafraz...\")\n",
        "\n",
        "    # Tymczasowo przenosimy DistilBERT na CPU, zeby zwolnic VRAM\n",
        "    model.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "    mistral_tokenizer = AutoTokenizer.from_pretrained(MISTRAL_MODEL_ID)\n",
        "    mistral_tokenizer.pad_token = mistral_tokenizer.eos_token\n",
        "    mistral_tokenizer.padding_side = \"left\"\n",
        "\n",
        "    mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "        MISTRAL_MODEL_ID,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    print(\"    Mistral zaladowany.\")\n",
        "\n",
        "    mistral_paraphrases = []\n",
        "    for text in tqdm(original_texts, desc=\"Generowanie parafraz (Mistral)\"):\n",
        "        try:\n",
        "            para = generate_paraphrase_mistral(text, mistral_model, mistral_tokenizer, device)\n",
        "            mistral_paraphrases.append(para)\n",
        "        except Exception as e:\n",
        "            print(f\"    Blad Mistral: {e}\")\n",
        "            mistral_paraphrases.append(None)\n",
        "\n",
        "    # Czyszczenie pamieci po Mistralu\n",
        "    print(\"\\n    [Faza 2/3] Czyszczenie pamieci GPU po Mistralu...\")\n",
        "    del mistral_model\n",
        "    del mistral_tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Przywracamy DistilBERT na GPU\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"    Pamiec GPU zwolniona. DistilBERT przywrocony na GPU.\")\n",
        "\n",
        "    # --- FAZA 2: Generowanie parafraz synonimami ---\n",
        "    print(\"\\n    [Faza 3/3] Generowanie parafraz synonimami (WordNet)...\")\n",
        "    synonym_paraphrases = []\n",
        "    for text in tqdm(original_texts, desc=\"Generowanie parafraz (Synonimy)\"):\n",
        "        try:\n",
        "            para = generate_synonym_paraphrase(text)\n",
        "            synonym_paraphrases.append(para)\n",
        "        except Exception as e:\n",
        "            print(f\"    Blad Synonimy: {e}\")\n",
        "            synonym_paraphrases.append(None)\n",
        "\n",
        "    # --- FAZA 3: Walidacja jakosci i zapis ---\n",
        "    print(\"\\n    Walidacja jakosci parafraz...\")\n",
        "    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    paraphrase_data = []\n",
        "    for i, orig_text in enumerate(original_texts):\n",
        "        entry = {\n",
        "            \"idx\": i,\n",
        "            \"original\": orig_text,\n",
        "            \"mistral_para\": mistral_paraphrases[i],\n",
        "            \"synonym_para\": synonym_paraphrases[i],\n",
        "            \"mistral_valid\": False,\n",
        "            \"synonym_valid\": False,\n",
        "        }\n",
        "\n",
        "        # Walidacja parafrazy Mistral\n",
        "        if mistral_paraphrases[i] is not None and len(mistral_paraphrases[i].strip()) > 5:\n",
        "            embs = semantic_model.encode(\n",
        "                [orig_text, mistral_paraphrases[i]], convert_to_tensor=True\n",
        "            )\n",
        "            cos_sim = F.cosine_similarity(embs[0].unsqueeze(0), embs[1].unsqueeze(0)).item()\n",
        "            entry[\"mistral_cos_sim\"] = cos_sim\n",
        "            entry[\"mistral_valid\"] = cos_sim >= PARAPHRASE_MIN_SIMILARITY\n",
        "\n",
        "        # Walidacja parafrazy synonimowej\n",
        "        if synonym_paraphrases[i] is not None and len(synonym_paraphrases[i].strip()) > 5:\n",
        "            embs = semantic_model.encode(\n",
        "                [orig_text, synonym_paraphrases[i]], convert_to_tensor=True\n",
        "            )\n",
        "            cos_sim = F.cosine_similarity(embs[0].unsqueeze(0), embs[1].unsqueeze(0)).item()\n",
        "            entry[\"synonym_cos_sim\"] = cos_sim\n",
        "            entry[\"synonym_valid\"] = cos_sim >= PARAPHRASE_MIN_SIMILARITY\n",
        "\n",
        "        paraphrase_data.append(entry)\n",
        "\n",
        "    # Zapis checkpoint\n",
        "    df_paraphrases = pd.DataFrame(paraphrase_data)\n",
        "    df_paraphrases.to_csv(f\"{RESULTS_DIR}/paraphrase_data.csv\", index=False)\n",
        "\n",
        "    n_mistral_valid = sum(1 for d in paraphrase_data if d[\"mistral_valid\"])\n",
        "    n_synonym_valid = sum(1 for d in paraphrase_data if d[\"synonym_valid\"])\n",
        "    print(f\"\\n    Mistral: {n_mistral_valid}/{len(paraphrase_data)} parafraz przeszlo walidacje\")\n",
        "    print(f\"    Synonimy: {n_synonym_valid}/{len(paraphrase_data)} parafraz przeszlo walidacje\")\n",
        "    print(\"    Dane parafraz zapisane do CSV.\")\n",
        "\n",
        "    del semantic_model\n",
        "    gc.collect()\n",
        "\n",
        "    return paraphrase_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_paraphrase_gen"
      },
      "outputs": [],
      "source": [
        "paraphrase_data = generate_all_paraphrases(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_attribution_funcs"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.2 FUNKCJE ATRYBUCJI (STANDARD IG + SMOOTHGRAD)\n",
        "# ===================================================\n",
        "\n",
        "def get_word_attributions(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Oblicza atrybucje na poziomie slow za pomoca Standard Integrated Gradients.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "\n",
        "    # JEDNO wywolanie tokenizera dla modelu i dla mapowania slow\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_SEQUENCE_LENGTH\n",
        "    ).to(device)\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "    emb = model.distilbert.embeddings(input_ids)\n",
        "    baseline = model.distilbert.embeddings(\n",
        "        torch.tensor(\n",
        "            [tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device\n",
        "        ).unsqueeze(0)\n",
        "    )\n",
        "\n",
        "    attr, _ = ig.attribute(\n",
        "        emb, baselines=baseline, target=1,\n",
        "        n_steps=XAI_N_STEPS,\n",
        "        additional_forward_args=(attention_mask,),\n",
        "        return_convergence_delta=True,\n",
        "    )\n",
        "\n",
        "    # Suma po wymiarze embeddingow + wartosc bezwzgledna\n",
        "    attr_sum = attr.sum(dim=-1).squeeze(0).abs()\n",
        "\n",
        "    # Pobieramy word_ids z tego samego obiektu encoding\n",
        "    word_ids = encoding.word_ids(0)\n",
        "\n",
        "    word_attributions = {}\n",
        "    for i, word_idx in enumerate(word_ids):\n",
        "        # Sprawdzamy czy i nie wykracza poza obliczone atrybucje (bezpieczenstwo przy paddingu)\n",
        "        if word_idx is not None and i < attr_sum.shape[0]:\n",
        "            try:\n",
        "                start, end = encoding.token_to_chars(0, i)\n",
        "                word = text[start:end].lower().strip()\n",
        "                if word:\n",
        "                    # Agregujemy sub-tokeny do slow\n",
        "                    word_attributions[word] = word_attributions.get(word, 0) + attr_sum[i].item()\n",
        "            except (TypeError, ValueError):\n",
        "                continue\n",
        "\n",
        "    return word_attributions\n",
        "\n",
        "\n",
        "def get_word_attributions_smoothgrad(text, model, tokenizer,\n",
        "                                     n_samples=SMOOTHGRAD_N_SAMPLES,\n",
        "                                     noise_std=SMOOTHGRAD_NOISE_STD):\n",
        "    \"\"\"\n",
        "    Oblicza atrybucje na poziomie slow za pomoca SmoothGrad (usrednianie zaszumionych prob).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "\n",
        "    # JEDNO wywolanie tokenizera\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_SEQUENCE_LENGTH\n",
        "    ).to(device)\n",
        "\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "    emb = model.distilbert.embeddings(input_ids)\n",
        "    baseline = model.distilbert.embeddings(\n",
        "        torch.tensor(\n",
        "            [tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device\n",
        "        ).unsqueeze(0)\n",
        "    )\n",
        "\n",
        "    # Akumulacja atrybucji (rozmiar zgodny z seq_len)\n",
        "    accumulated_attr = torch.zeros(MAX_SEQUENCE_LENGTH, device=device)\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        # Dodaj szum gaussowski do embeddingow\n",
        "        noise = torch.randn_like(emb) * noise_std\n",
        "        noisy_emb = emb + noise\n",
        "\n",
        "        attr, _ = ig.attribute(\n",
        "            noisy_emb, baselines=baseline, target=1,\n",
        "            n_steps=XAI_N_STEPS,\n",
        "            additional_forward_args=(attention_mask,),\n",
        "            return_convergence_delta=True,\n",
        "        )\n",
        "\n",
        "        # Suma po embeddingach -> waznosc tokenu\n",
        "        attr_sum = attr.sum(dim=-1).squeeze(0).abs()\n",
        "        accumulated_attr += attr_sum\n",
        "\n",
        "    # Usrednienie wynikow ze wszystkich prob\n",
        "    averaged_attr = accumulated_attr / n_samples\n",
        "\n",
        "    # Agregacja sub-tokenow do slow\n",
        "    word_ids = encoding.word_ids(0)\n",
        "    word_attributions = {}\n",
        "\n",
        "    for i, word_idx in enumerate(word_ids):\n",
        "        if word_idx is not None and i < averaged_attr.shape[0]:\n",
        "            try:\n",
        "                start, end = encoding.token_to_chars(0, i)\n",
        "                word = text[start:end].lower().strip()\n",
        "                if word:\n",
        "                    # UZYWAMY averaged_attr (poprzednio byl blad z attr_sum)\n",
        "                    word_attributions[word] = word_attributions.get(word, 0) + averaged_attr[i].item()\n",
        "            except (TypeError, ValueError):\n",
        "                continue\n",
        "\n",
        "    return word_attributions\n",
        "\n",
        "\n",
        "def calculate_spearman_on_shared_vocab(attrs_orig, attrs_para):\n",
        "    \"\"\"\n",
        "    Oblicza korelacje Spearmana miedzy atrybucjami oryginalnego tekstu i parafrazy\n",
        "    na wspolnym slowniku (unii slow z obu tekstow).\n",
        "\n",
        "    Slowa nieobecne w jednym z tekstow otrzymuja atrybucje 0.\n",
        "\n",
        "    Argumenty:\n",
        "        attrs_orig: dict {slowo: atrybucja} dla tekstu oryginalnego\n",
        "        attrs_para: dict {slowo: atrybucja} dla parafrazy\n",
        "\n",
        "    Zwraca:\n",
        "        float: Wspolczynnik korelacji Spearmana (lub 0.0 jesli zbyt malo danych)\n",
        "    \"\"\"\n",
        "    # Unia slow z obu tekstow\n",
        "    all_words = set(attrs_orig.keys()) | set(attrs_para.keys())\n",
        "\n",
        "    if len(all_words) < 3:  # Zbyt malo danych do korelacji\n",
        "        return 0.0\n",
        "\n",
        "    # Budowanie wektorow na wspolnym slowniku (brakujace = 0)\n",
        "    vec_orig = [attrs_orig.get(w, 0.0) for w in all_words]\n",
        "    vec_para = [attrs_para.get(w, 0.0) for w in all_words]\n",
        "\n",
        "    # Sprawdzenie czy wektory nie sa stalymi (spearmanr wymaga wariancji)\n",
        "    if len(set(vec_orig)) < 2 or len(set(vec_para)) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    corr, _ = spearmanr(vec_orig, vec_para)\n",
        "    return corr if not np.isnan(corr) else 0.0\n",
        "\n",
        "\n",
        "def calculate_semantic_overlap(words_orig, words_para, semantic_model):\n",
        "    \"\"\"\n",
        "    Mierzy semantyczne podobienstwo miedzy dwoma listami najwazniejszych slow.\n",
        "\n",
        "    Uzywa modelu SentenceTransformer do kodowania slow, nastepnie oblicza\n",
        "    srednie maksymalne cosine similarity w obu kierunkach.\n",
        "\n",
        "    Argumenty:\n",
        "        words_orig: Lista top-K slow z oryginalnego tekstu\n",
        "        words_para: Lista top-K slow z parafrazy\n",
        "        semantic_model: Zaladowany model SentenceTransformer\n",
        "\n",
        "    Zwraca:\n",
        "        float: Srednie semantyczne podobienstwo (0.0 - 1.0)\n",
        "    \"\"\"\n",
        "    if not words_orig or not words_para:\n",
        "        return 0.0\n",
        "    emb_orig = semantic_model.encode(words_orig, convert_to_tensor=True)\n",
        "    emb_para = semantic_model.encode(words_para, convert_to_tensor=True)\n",
        "    cos_sim_matrix = F.cosine_similarity(\n",
        "        emb_orig.unsqueeze(1), emb_para.unsqueeze(0), dim=2\n",
        "    )\n",
        "    score = (\n",
        "        torch.max(cos_sim_matrix, dim=1)[0].mean()\n",
        "        + torch.max(cos_sim_matrix, dim=0)[0].mean()\n",
        "    ).item() / 2\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_eval_loop"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.3 PETLA EWALUACJI STABILNOSCI\n",
        "# ===================================================\n",
        "\n",
        "# Slownik do zapamietywania obliczen dla oryginalow, zeby nie liczyc ich 2 razy\n",
        "# (raz dla pary z Mistralem, drugi raz dla Synonimow)\n",
        "ORIGINAL_ATTR_CACHE = {}\n",
        "\n",
        "def run_stability_single_mode(model, tokenizer, paraphrase_data, mode=\"mistral\"):\n",
        "    \"\"\"\n",
        "    Uruchamia analize stabilnosci TYLKO dla jednego typu parafraz (mode='mistral' lub 'synonym').\n",
        "    Korzysta z globalnego cache ORIGINAL_ATTR_CACHE.\n",
        "    \"\"\"\n",
        "    print(f\"\\n>>> [STABILITY] Uruchamianie analizy dla trybu: {mode.upper()}...\")\n",
        "    model.eval()\n",
        "    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Konfiguracja kluczy w zaleznosci od trybu\n",
        "    if mode == \"mistral\":\n",
        "        para_key = \"mistral_para\"\n",
        "        valid_key = \"mistral_valid\"\n",
        "    else:\n",
        "        para_key = \"synonym_para\"\n",
        "        valid_key = \"synonym_valid\"\n",
        "\n",
        "    # Filtrowanie par\n",
        "    valid_pairs = [d for d in paraphrase_data if d.get(valid_key, False)]\n",
        "    print(f\"    Liczba par do przetworzenia: {len(valid_pairs)}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for entry in tqdm(valid_pairs, desc=f\"Analiza {mode}\"):\n",
        "        idx = entry[\"idx\"]\n",
        "        orig_text = entry[\"original\"]\n",
        "        para_text = entry[para_key]\n",
        "\n",
        "        try:\n",
        "            # 1. Obliczanie (lub pobranie z cache) atrybucji ORYGINALU\n",
        "            if idx in ORIGINAL_ATTR_CACHE:\n",
        "                attrs_orig_std = ORIGINAL_ATTR_CACHE[idx][\"std\"]\n",
        "                attrs_orig_smooth = ORIGINAL_ATTR_CACHE[idx][\"smooth\"]\n",
        "            else:\n",
        "                # Jesli nie ma w cache, policz i zapisz\n",
        "                attrs_orig_std = get_word_attributions(orig_text, model, tokenizer)\n",
        "                attrs_orig_smooth = get_word_attributions_smoothgrad(\n",
        "                    orig_text, model, tokenizer,\n",
        "                    n_samples=SMOOTHGRAD_N_SAMPLES  # Uzycie zoptymalizowanego parametru\n",
        "                )\n",
        "                ORIGINAL_ATTR_CACHE[idx] = {\n",
        "                    \"std\": attrs_orig_std,\n",
        "                    \"smooth\": attrs_orig_smooth\n",
        "                }\n",
        "\n",
        "            # 2. Obliczanie atrybucji PARAFRAZY (to musimy policzyc zawsze)\n",
        "            attrs_para_std = get_word_attributions(para_text, model, tokenizer)\n",
        "            attrs_para_smooth = get_word_attributions_smoothgrad(\n",
        "                para_text, model, tokenizer,\n",
        "                n_samples=SMOOTHGRAD_N_SAMPLES\n",
        "            )\n",
        "\n",
        "            # 3. Metryki (Spearman)\n",
        "            spearman_std = calculate_spearman_on_shared_vocab(attrs_orig_std, attrs_para_std)\n",
        "            spearman_smooth = calculate_spearman_on_shared_vocab(attrs_orig_smooth, attrs_para_smooth)\n",
        "\n",
        "            # 4. Metryki (Semantic Overlap)\n",
        "            # Pomocnicza lambda do sortowania\n",
        "            get_top_k = lambda attrs: [w for w, _ in sorted(attrs.items(), key=lambda x: x[1], reverse=True)[:TOP_K_TOKENS]]\n",
        "\n",
        "            top_orig_std = get_top_k(attrs_orig_std)\n",
        "            top_para_std = get_top_k(attrs_para_std)\n",
        "            top_orig_smooth = get_top_k(attrs_orig_smooth)\n",
        "            top_para_smooth = get_top_k(attrs_para_smooth)\n",
        "\n",
        "            sem_overlap_std = calculate_semantic_overlap(top_orig_std, top_para_std, semantic_model)\n",
        "            sem_overlap_smooth = calculate_semantic_overlap(top_orig_smooth, top_para_smooth, semantic_model)\n",
        "\n",
        "            # Zapis wyniku\n",
        "            results.append({\n",
        "                \"para_type\": mode,\n",
        "                \"idx\": idx,\n",
        "                \"spearman_standard_ig\": spearman_std,\n",
        "                \"spearman_smoothgrad\": spearman_smooth,\n",
        "                \"sem_overlap_standard_ig\": sem_overlap_std,\n",
        "                \"sem_overlap_smoothgrad\": sem_overlap_smooth,\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Blad przy idx={idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Zwalnianie pamieci po modelu semantycznym\n",
        "    del semantic_model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_stability_eval"
      },
      "outputs": [],
      "source": [
        "# === URUCHOMIENIE DLA MISTRALA ===\n",
        "# Czyscimy cache przed startem (opcjonalnie)\n",
        "ORIGINAL_ATTR_CACHE = {}\n",
        "\n",
        "df_mistral = run_stability_single_mode(model, tokenizer, paraphrase_data, mode=\"mistral\")\n",
        "\n",
        "# Zapiszmy wynik posredni, zeby go nie stracic\n",
        "df_mistral.to_csv(f\"{RESULTS_DIR}/stability_results_mistral_PARTIAL.csv\", index=False)\n",
        "print(\"Wyniki dla Mistrala zapisane.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dME4HEbFmzA"
      },
      "outputs": [],
      "source": [
        "# === URUCHOMIENIE DLA SYNONIMOW ===\n",
        "\n",
        "df_synonym = run_stability_single_mode(model, tokenizer, paraphrase_data, mode=\"synonym\")\n",
        "\n",
        "# Zapiszmy wynik posredni\n",
        "df_synonym.to_csv(f\"{RESULTS_DIR}/stability_results_synonym_PARTIAL.csv\", index=False)\n",
        "print(\"Wyniki dla Synonimow zapisane.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-9SbiJ8FtXC"
      },
      "outputs": [],
      "source": [
        "# === POLACZENIE WYNIKOW ===\n",
        "\n",
        "if not df_mistral.empty and not df_synonym.empty:\n",
        "    df_stability = pd.concat([df_mistral, df_synonym], ignore_index=True)\n",
        "elif not df_mistral.empty:\n",
        "    df_stability = df_mistral\n",
        "else:\n",
        "    df_stability = df_synonym\n",
        "\n",
        "# Zapisz finalny plik (tak jak w oryginalnym kodzie)\n",
        "df_stability.to_csv(f\"{RESULTS_DIR}/stability_results.csv\", index=False)\n",
        "print(f\"Finalna tabela zapisana. Razem wierszy: {len(df_stability)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_visualization"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.4 WIZUALIZACJA I PODSUMOWANIE STABILNOSCI\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def visualize_stability(df_stability):\n",
        "    \"\"\"\n",
        "    Wizualizuje wyniki analizy stabilnosci: porownanie Standard IG vs SmoothGrad\n",
        "    dla obu typow parafraz (Mistral i Synonimy).\n",
        "\n",
        "    Tworzy 4 subploty (2x2):\n",
        "        - Wiersz 1: Korelacja Spearmana (Mistral | Synonimy)\n",
        "        - Wiersz 2: Semantic Overlap (Mistral | Synonimy)\n",
        "\n",
        "    Argumenty:\n",
        "        df_stability: DataFrame z wynikami experiment_stability()\n",
        "\n",
        "    Zwraca:\n",
        "        None (wyswietla wykresy i drukuje podsumowanie)\n",
        "    \"\"\"\n",
        "    if df_stability.empty:\n",
        "        print(\"Brak danych do wizualizacji.\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle(\n",
        "        \"Analiza Stabilnosci: Standard IG vs SmoothGrad\",\n",
        "        fontsize=16, fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "    para_types = [\"mistral\", \"synonym\"]\n",
        "    para_labels = [\"Parafrazy Mistral\", \"Parafrazy Synonimowe\"]\n",
        "\n",
        "    for col_idx, (ptype, plabel) in enumerate(zip(para_types, para_labels)):\n",
        "        df_sub = df_stability[df_stability[\"para_type\"] == ptype]\n",
        "\n",
        "        if df_sub.empty:\n",
        "            axes[0, col_idx].text(0.5, 0.5, f\"Brak danych: {plabel}\",\n",
        "                                   ha='center', va='center', fontsize=12)\n",
        "            axes[1, col_idx].text(0.5, 0.5, f\"Brak danych: {plabel}\",\n",
        "                                   ha='center', va='center', fontsize=12)\n",
        "            continue\n",
        "\n",
        "        # Wiersz 1: Korelacja Spearmana\n",
        "        spearman_data = df_sub[[\"spearman_standard_ig\", \"spearman_smoothgrad\"]]\n",
        "        sns.boxplot(data=spearman_data, ax=axes[0, col_idx], palette=\"Set2\")\n",
        "        axes[0, col_idx].set_title(f\"Korelacja Spearmana - {plabel}\")\n",
        "        axes[0, col_idx].set_ylabel(\"Spearman rho\")\n",
        "        axes[0, col_idx].set_xticklabels([\"Standard IG\", \"SmoothGrad\"])\n",
        "        axes[0, col_idx].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "        # Wiersz 2: Semantic Overlap\n",
        "        sem_data = df_sub[[\"sem_overlap_standard_ig\", \"sem_overlap_smoothgrad\"]]\n",
        "        sns.boxplot(data=sem_data, ax=axes[1, col_idx], palette=\"Set2\")\n",
        "        axes[1, col_idx].set_title(f\"Semantic Overlap (Top-{TOP_K_TOKENS}) - {plabel}\")\n",
        "        axes[1, col_idx].set_ylabel(\"Semantic Overlap\")\n",
        "        axes[1, col_idx].set_xticklabels([\"Standard IG\", \"SmoothGrad\"])\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.savefig(f\"{RESULTS_DIR}/stability_boxplot.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Tabela podsumowujaca ---\n",
        "    print(\"\\n=== PODSUMOWANIE STABILNOSCI ===\")\n",
        "    for ptype, plabel in zip(para_types, para_labels):\n",
        "        df_sub = df_stability[df_stability[\"para_type\"] == ptype]\n",
        "        if df_sub.empty:\n",
        "            print(f\"\\n{plabel}: Brak danych.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- {plabel} (n={len(df_sub)}) ---\")\n",
        "        print(f\"\\nKorelacja Spearmana:\")\n",
        "        print(f\"  Standard IG  - srednia: {df_sub['spearman_standard_ig'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['spearman_standard_ig'].median():.4f}, \"\n",
        "              f\"std: {df_sub['spearman_standard_ig'].std():.4f}\")\n",
        "        print(f\"  SmoothGrad   - srednia: {df_sub['spearman_smoothgrad'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['spearman_smoothgrad'].median():.4f}, \"\n",
        "              f\"std: {df_sub['spearman_smoothgrad'].std():.4f}\")\n",
        "\n",
        "        print(f\"\\nSemantic Overlap (Top-{TOP_K_TOKENS}):\")\n",
        "        print(f\"  Standard IG  - srednia: {df_sub['sem_overlap_standard_ig'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['sem_overlap_standard_ig'].median():.4f}, \"\n",
        "              f\"std: {df_sub['sem_overlap_standard_ig'].std():.4f}\")\n",
        "        print(f\"  SmoothGrad   - srednia: {df_sub['sem_overlap_smoothgrad'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['sem_overlap_smoothgrad'].median():.4f}, \"\n",
        "              f\"std: {df_sub['sem_overlap_smoothgrad'].std():.4f}\")\n",
        "\n",
        "        # Poprawa SmoothGrad vs Standard IG\n",
        "        spearman_improvement = (\n",
        "            df_sub['spearman_smoothgrad'].mean() - df_sub['spearman_standard_ig'].mean()\n",
        "        )\n",
        "        sem_improvement = (\n",
        "            df_sub['sem_overlap_smoothgrad'].mean() - df_sub['sem_overlap_standard_ig'].mean()\n",
        "        )\n",
        "        print(f\"\\n  Poprawa SmoothGrad vs Standard IG:\")\n",
        "        print(f\"    Spearman:         +{spearman_improvement:.4f}\")\n",
        "        print(f\"    Semantic Overlap: +{sem_improvement:.4f}\")\n",
        "\n",
        "    print(\"\\nCzesc 2 zakonczona.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_stability_viz"
      },
      "outputs": [],
      "source": [
        "visualize_stability(df_stability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "steering_header"
      },
      "source": [
        "---\n",
        "## Czesc 3: Inzynieria Reprezentacji i Sterowanie (Utility & Steering)\n",
        "\n",
        "Cel: Wykazanie uzytecznosci praktycznej - mozemy naprawic model bez retrenowania.\n",
        "\n",
        "Podejscie:\n",
        "- **Ekstrakcja aktywacji** z warstwy TARGET_LAYER_INDEX dla zbioru toksycznego i bezpiecznego\n",
        "- **Wektor sterujacy**: Obliczenie kierunku toksycznosci metoda Difference of Means + normalizacja L2\n",
        "- **SteeringHook**: PyTorch hook modyfikujacy hidden states w czasie inferencji\n",
        "- **Test detoksykacji**: Ocena skutecznosci dla roznych wartosci alpha (sila interwencji)\n",
        "\n",
        "Metryki:\n",
        "- **Success Rate**: Procent toksycznych przykladow sklasyfikowanych jako bezpieczne po steeringu (cel: >80%)\n",
        "- **Side Effect Rate**: Procent bezpiecznych przykladow blednie sklasyfikowanych jako toksyczne (cel: <5%)\n",
        "- **Avg Delta**: Srednia zmiana prawdopodobienstwa toksycznosci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_functions"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3. INZYNIERIA REPREZENTACJI I STEROWANIE (STEERING)\n",
        "# ===================================================\n",
        "\n",
        "class SteeringHook:\n",
        "    \"\"\"\n",
        "    PyTorch hook modyfikujacy hidden states poprzez dodanie wektora sterujacego.\n",
        "    \"\"\"\n",
        "    def __init__(self, vector, coeff):\n",
        "        self.vector = vector\n",
        "        self.coeff = coeff\n",
        "\n",
        "    def __call__(self, module, inputs, output):\n",
        "        is_tuple = isinstance(output, tuple)\n",
        "        hidden_states = output[0] if is_tuple else output\n",
        "\n",
        "        # Zabezpieczenie ksztaltow i urzadzenia\n",
        "        steering_vector = self.vector.to(hidden_states.device, dtype=hidden_states.dtype)\n",
        "\n",
        "        # Dodajemy wektor (broadcasting obsluzy wymiar batch i sequence)\n",
        "        modified_hidden = hidden_states + (self.coeff * steering_vector)\n",
        "\n",
        "        if is_tuple:\n",
        "            return (modified_hidden,) + output[1:]\n",
        "        else:\n",
        "            return modified_hidden\n",
        "\n",
        "\n",
        "def experiment_steering(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Oblicza wektor sterujacy i testuje skutecznosc detoksykacji ORAZ spojnosc semantyczna.\n",
        "    Poprawiona wersja: Obsluga capture_hook dla Tensorow i Tupli.\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 3] Uruchamianie analizy steeringu (z Cosine Similarity)...\")\n",
        "    model.eval()\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.1 PODZIAL DANYCH\n",
        "    # -----------------------------------------------\n",
        "    total_len = len(dataset)\n",
        "    N_FOR_VECTOR = int(total_len * 0.6)\n",
        "\n",
        "    # Zabezpieczenie na wypadek malego zbioru\n",
        "    if total_len - N_FOR_VECTOR < 50:\n",
        "        print(f\"UWAGA: Bardzo maly zbior danych ({total_len}).\")\n",
        "\n",
        "    vector_subset = dataset.select(range(N_FOR_VECTOR))\n",
        "    test_subset = dataset.select(range(N_FOR_VECTOR, total_len))\n",
        "\n",
        "    print(f\"    Calkowity rozmiar zbioru eval: {total_len}\")\n",
        "    print(f\"    Probek do wyznaczenia wektora: {len(vector_subset)}\")\n",
        "    print(f\"    Probek do testowania efektow:  {len(test_subset)}\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.2 EKSTRAKCJA AKTYWACJI\n",
        "    # -----------------------------------------------\n",
        "    print(f\"    Ekstrakcja aktywacji z warstwy {TARGET_LAYER_INDEX}...\")\n",
        "    layers_data = {TARGET_LAYER_INDEX: []}\n",
        "    all_labels = []\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(vector_subset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Ekstrakcja aktywacji\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        all_labels.extend(labels)\n",
        "        # Pobieramy hidden state [CLS] z wybranej warstwy\n",
        "        layers_data[TARGET_LAYER_INDEX].append(\n",
        "            out.hidden_states[TARGET_LAYER_INDEX][:, 0, :].cpu().numpy()\n",
        "        )\n",
        "\n",
        "    X = np.concatenate(layers_data[TARGET_LAYER_INDEX], axis=0)\n",
        "    y = np.array(all_labels)\n",
        "    y_bin = (y > CLASSIFICATION_THRESHOLD).astype(int)\n",
        "\n",
        "    print(f\"    Statystyki - Toksyczne: {np.sum(y_bin == 1)}, Bezpieczne: {np.sum(y_bin == 0)}\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.3 OBLICZENIE WEKTORA STERUJACEGO\n",
        "    # -----------------------------------------------\n",
        "    if np.sum(y_bin == 1) == 0 or np.sum(y_bin == 0) == 0:\n",
        "        raise ValueError(\"Brak jednej z klas w zbiorze wektorowym.\")\n",
        "\n",
        "    print(\"    Obliczanie wektora sterujacego (Difference of Means)...\")\n",
        "    mean_toxic = np.mean(X[y_bin == 1], axis=0)\n",
        "    mean_safe = np.mean(X[y_bin == 0], axis=0)\n",
        "    direction = mean_toxic - mean_safe\n",
        "\n",
        "    # Normalizacja L2\n",
        "    direction_normed = direction / np.linalg.norm(direction)\n",
        "    steering_tensor = torch.tensor(direction_normed, dtype=torch.float32).to(device)\n",
        "\n",
        "    np.save(f\"{RESULTS_DIR}/steering_vector.npy\", direction_normed)\n",
        "    print(f\"    Wektor zapisany. L2 Norm (orig): {np.linalg.norm(direction):.2f}\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.4 FUNKCJA TESTOWANIA Z PODOBIENSTWEM\n",
        "    # -----------------------------------------------\n",
        "    layer_module = model.distilbert.transformer.layer[TARGET_LAYER_INDEX]\n",
        "\n",
        "    def test_steering_for_alpha(alpha_value):\n",
        "        print(f\"\\n    --- Testowanie alpha = {alpha_value} ---\")\n",
        "\n",
        "        # 1. Ranking probek\n",
        "        all_scores = []\n",
        "        search_range = min(300, len(test_subset))\n",
        "\n",
        "        for i in range(search_range):\n",
        "            input_ids = test_subset[i][\"input_ids\"].unsqueeze(0).to(device)\n",
        "            mask = test_subset[i][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "            label = test_subset[i][\"labels\"].item()\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_ids, attention_mask=mask).logits\n",
        "                prob = torch.softmax(logits, dim=-1)[0, 1].item()\n",
        "            all_scores.append({\"idx\": i, \"prob\": prob, \"label\": label})\n",
        "\n",
        "        # Wybor kandydatow\n",
        "        toxic_candidates = sorted([x for x in all_scores if x[\"label\"] == 1], key=lambda x: x[\"prob\"], reverse=True)\n",
        "        safe_candidates = sorted([x for x in all_scores if x[\"label\"] == 0], key=lambda x: x[\"prob\"])\n",
        "\n",
        "        # Uzywamy N_SAMPLES_PER_CLASS z globalnych ustawien lub domyslnej wartosci\n",
        "        toxic_indices = [x[\"idx\"] for x in toxic_candidates[:N_SAMPLES_PER_CLASS]]\n",
        "        safe_indices = [x[\"idx\"] for x in safe_candidates[:N_SAMPLES_PER_CLASS]]\n",
        "\n",
        "        print(f\"    Wybrano: {len(toxic_indices)} toksycznych, {len(safe_indices)} bezpiecznych\")\n",
        "\n",
        "        results = []\n",
        "        success_count = 0\n",
        "        cosine_sim_sum = 0\n",
        "\n",
        "        # --- POPRAWIONY HOOK ---\n",
        "        captured_hidden = None\n",
        "        def capture_hook(module, inp, out):\n",
        "            nonlocal captured_hidden\n",
        "            # Sprawdzenie czy wyjscie jest tupla czy tensorem (tak jak w SteeringHook)\n",
        "            is_tuple = isinstance(out, tuple)\n",
        "            hidden = out[0] if is_tuple else out\n",
        "            captured_hidden = hidden.detach() # shape powinno byc: [Batch, Seq, Hidden]\n",
        "            return out\n",
        "\n",
        "        def run_inference(indices, label_type):\n",
        "            nonlocal success_count, cosine_sim_sum\n",
        "\n",
        "            for idx in indices:\n",
        "                input_ids = test_subset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "                mask = test_subset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "\n",
        "                # A. Inferencja BEZ steeringu (z capture hookiem)\n",
        "                h_cap = layer_module.register_forward_hook(capture_hook)\n",
        "                with torch.no_grad():\n",
        "                    logits_before = model(input_ids, mask).logits\n",
        "                    prob_before = torch.softmax(logits_before, dim=-1)[0, 1].item()\n",
        "                h_cap.remove()\n",
        "\n",
        "                clean_hidden = captured_hidden.clone() # [1, Seq, 768]\n",
        "\n",
        "                # B. Inferencja ZE steeringiem\n",
        "                hook = SteeringHook(steering_tensor, alpha_value)\n",
        "                h_steer = layer_module.register_forward_hook(hook)\n",
        "                with torch.no_grad():\n",
        "                    logits_after = model(input_ids, mask).logits\n",
        "                    prob_after = torch.softmax(logits_after, dim=-1)[0, 1].item()\n",
        "                h_steer.remove()\n",
        "\n",
        "                delta = prob_after - prob_before\n",
        "\n",
        "                # Logika metryk\n",
        "                cos_sim = 1.0\n",
        "                status = \"OK\"\n",
        "\n",
        "                if label_type == \"TOXIC\":\n",
        "                    if prob_after < CLASSIFICATION_THRESHOLD:\n",
        "                        success_count += 1\n",
        "                        status = \"SUCCESS\"\n",
        "                    else:\n",
        "                        status = \"FAILED\"\n",
        "\n",
        "                elif label_type == \"SAFE\":\n",
        "                    # Obliczamy Cosine Similarity dla SAFE\n",
        "\n",
        "                    # Wektor: [1, 1, 768]\n",
        "                    vec_expanded = steering_tensor.to(clean_hidden.device).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "                    # Obliczamy manualnie zmodyfikowany stan, aby porownac semantyke\n",
        "                    steered_hidden_calc = clean_hidden + (alpha_value * vec_expanded)\n",
        "\n",
        "                    # Porownujemy token [CLS] (indeks 0)\n",
        "                    # clean_hidden[:, 0, :] ma teraz poprawny wymiar [1, 768]\n",
        "                    sim = F.cosine_similarity(clean_hidden[:, 0, :], steered_hidden_calc[:, 0, :], dim=-1).item()\n",
        "                    cosine_sim_sum += sim\n",
        "                    cos_sim = sim\n",
        "\n",
        "                    status = \"SAFE_CHECK\"\n",
        "\n",
        "                text = tokenizer.decode(test_subset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "\n",
        "                results.append({\n",
        "                    \"label\": label_type,\n",
        "                    \"alpha\": alpha_value,\n",
        "                    \"prob_before\": prob_before,\n",
        "                    \"prob_after\": prob_after,\n",
        "                    \"delta\": delta,\n",
        "                    \"cosine_sim\": cos_sim,\n",
        "                    \"status\": status,\n",
        "                    \"text\": text[:100],\n",
        "                })\n",
        "\n",
        "        run_inference(toxic_indices, \"TOXIC\")\n",
        "        run_inference(safe_indices, \"SAFE\")\n",
        "\n",
        "        # Statystyki koncowe\n",
        "        success_rate = (success_count / len(toxic_indices) * 100) if toxic_indices else 0\n",
        "        avg_sim = (cosine_sim_sum / len(safe_indices)) if safe_indices else 1.0\n",
        "\n",
        "        print(f\"    Success Rate: {success_rate:.1f}% | Avg Cosine Sim (Safe): {avg_sim:.4f}\")\n",
        "        return results, success_rate, avg_sim\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.5 GLOWNA PETLA\n",
        "    # -----------------------------------------------\n",
        "    all_details = []\n",
        "    summary_data = []\n",
        "\n",
        "    # Zalecane wartosci alpha (w tym dodatnie dla weryfikacji)\n",
        "    current_alphas = ALPHA_VALUES\n",
        "    print(f\"    Testowane wartosci Alpha: {current_alphas}\")\n",
        "\n",
        "    for alpha in current_alphas:\n",
        "        res, succ_rate, avg_sim = test_steering_for_alpha(alpha)\n",
        "        all_details.extend(res)\n",
        "        summary_data.append({\n",
        "            \"alpha\": alpha,\n",
        "            \"success_rate\": succ_rate,\n",
        "            \"avg_cosine_sim\": avg_sim\n",
        "        })\n",
        "\n",
        "    df_summary = pd.DataFrame(summary_data)\n",
        "    df_details = pd.DataFrame(all_details)\n",
        "\n",
        "    df_summary.to_csv(f\"{RESULTS_DIR}/steering_summary.csv\", index=False)\n",
        "    df_details.to_csv(f\"{RESULTS_DIR}/steering_details.csv\", index=False)\n",
        "\n",
        "    print(f\"\\n    Wyniki zapisane do: {RESULTS_DIR}/steering_summary.csv\")\n",
        "\n",
        "    return df_summary, df_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_steering"
      },
      "outputs": [],
      "source": [
        "df_steering, df_steering_details = experiment_steering(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_visualization"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3.6 WIZUALIZACJA I PODSUMOWANIE STEERINGU\n",
        "# ===================================================\n",
        "\n",
        "def visualize_steering(df_summary, df_details):\n",
        "    \"\"\"\n",
        "    Wizualizuje wyniki steeringu: Trade-off miedzy skutecznoscia a spojnoscia semantyczna.\n",
        "    \"\"\"\n",
        "    if df_summary.empty:\n",
        "        print(\"Brak danych do wizualizacji.\")\n",
        "        return\n",
        "\n",
        "    # Filtrujemy dane: Analizujemy glownie detoksykacje (ujemne alpha)\n",
        "    df_detox = df_summary[df_summary[\"alpha\"] <= 0].sort_values(\"alpha\", ascending=False)\n",
        "\n",
        "    # --- Wykres 1: Trade-off (Success vs Similarity) ---\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Os 1: Success Rate (Slupki)\n",
        "    color = 'tab:blue'\n",
        "    ax1.set_xlabel('Alpha (Sila interwencji)')\n",
        "    ax1.set_ylabel('Success Rate (%)', color=color, fontweight='bold')\n",
        "    bars = ax1.bar(df_detox['alpha'].astype(str), df_detox['success_rate'], color=color, alpha=0.6, label='Success Rate')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "    ax1.set_ylim(0, 110)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Dodanie wartosci na slupkach\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax1.annotate(f\"{h:.0f}%\", xy=(bar.get_x() + bar.get_width() / 2, h),\n",
        "                     xytext=(0, 3), textcoords=\"offset points\", ha=\"center\", fontsize=10, fontweight='bold')\n",
        "\n",
        "    # Os 2: Cosine Similarity (Linia)\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:red'\n",
        "    ax2.set_ylabel('Cosine Similarity (Zachowanie sensu)', color=color, fontweight='bold')\n",
        "    line = ax2.plot(df_detox['alpha'].astype(str), df_detox['avg_cosine_sim'], color=color, marker='o', linewidth=3, label='Cosine Similarity')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "    ax2.set_ylim(0.5, 1.05) # Skala dla podobienstwa\n",
        "\n",
        "    # Linie referencyjne\n",
        "    ax1.axhline(y=80, color=\"green\", linestyle=\"--\", alpha=0.5, label=\"Cel: Success > 80%\")\n",
        "    ax2.axhline(y=0.90, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Cel: Sim > 0.90\")\n",
        "\n",
        "    plt.title('Trade-off: Skutecznosc Detoksykacji vs Spojnosc Semantyczna')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/steering_tradeoff.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # --- Tabela podsumowujaca z ocena ---\n",
        "    print(\"\\n=== PODSUMOWANIE STEERINGU ===\")\n",
        "    # Wyswietlamy sformatowana tabele\n",
        "    print(df_summary[['alpha', 'success_rate', 'avg_cosine_sim']].to_string(index=False))\n",
        "\n",
        "    print(\"\\n=== ANALIZA OPTYMALNOSCI (DETOKSYKACJA) ===\")\n",
        "    best_alpha = None\n",
        "    best_score = -1\n",
        "\n",
        "    for _, row in df_detox.iterrows():\n",
        "        alpha = row[\"alpha\"]\n",
        "        succ = row[\"success_rate\"]\n",
        "        sim = row[\"avg_cosine_sim\"]\n",
        "\n",
        "        # Prosta heurystyka oceny\n",
        "        if succ >= 90 and sim >= 0.85:\n",
        "            status = \"BARDZO DOBRY (Zalecany)\"\n",
        "            score = 3\n",
        "        elif succ >= 80 and sim >= 0.80:\n",
        "            status = \"DOBRY KOMPROMIS\"\n",
        "            score = 2\n",
        "        elif succ < 50 and sim > 0.95:\n",
        "            status = \"ZBYT OSTROZNE (Brak efektu)\"\n",
        "            score = 0\n",
        "        elif sim < 0.70:\n",
        "            status = \"AGRESYWNE (Utrata sensu)\"\n",
        "            score = 1\n",
        "        else:\n",
        "            status = \"SREDNI\"\n",
        "            score = 1\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_alpha = alpha\n",
        "\n",
        "        print(f\"\\n  Alpha = {alpha}: {status}\")\n",
        "        print(f\"    Success Rate:  {succ:.1f}%\")\n",
        "        print(f\"    Cosine Sim:    {sim:.4f}\")\n",
        "\n",
        "    if best_alpha is not None:\n",
        "        print(f\"\\n  >>> REKOMENDACJA: Najlepszy balans przy alpha = {best_alpha}\")\n",
        "\n",
        "    # --- Analiza Sanity Check (Dodatnie Alpha) ---\n",
        "    df_injection = df_summary[df_summary[\"alpha\"] > 0]\n",
        "    if not df_injection.empty:\n",
        "        print(\"\\n=== SANITY CHECK (INIEKCJA TOKSYCZNOSCI) ===\")\n",
        "        print(\"  Testujemy czy dodatnie alpha psuje bezpieczne zdania (spadek Cosine Sim).\")\n",
        "        for _, row in df_injection.iterrows():\n",
        "            print(f\"  Alpha {row['alpha']}: Sim = {row['avg_cosine_sim']:.4f} \"\n",
        "                  f\"(Im nizej tym silniejszy efekt iniekcji)\")\n",
        "\n",
        "    # --- Szczegolowe przyklady ---\n",
        "    if not df_details.empty:\n",
        "        # 1. Sukces Detoksykacji\n",
        "        print(\"\\n=== PRZYKLADY SUKCESU (TOXIC -> SAFE) ===\")\n",
        "        # Wybieramy alpha z najlepszym kompromisem lub -35 jesli nie znaleziono\n",
        "        target_alpha = best_alpha if best_alpha else -35.0\n",
        "\n",
        "        success_examples = df_details[\n",
        "            (df_details[\"label\"] == \"TOXIC\") &\n",
        "            (df_details[\"alpha\"] == target_alpha) &\n",
        "            (df_details[\"status\"] == \"SUCCESS\")\n",
        "        ].head(3)\n",
        "\n",
        "        if success_examples.empty:\n",
        "            print(\"  Brak sukcesow dla wybranego alpha.\")\n",
        "        else:\n",
        "            for _, row in success_examples.iterrows():\n",
        "                print(f\"\\n  [alpha={target_alpha}] Tekst: {row['text'][:100]}...\")\n",
        "                print(f\"    P(toxic): {row['prob_before']:.4f} -> {row['prob_after']:.4f}\")\n",
        "\n",
        "        # 2. Koszt Semantyczny (Najwieksze znieksztalcenia Safe)\n",
        "        print(f\"\\n=== KOSZT SEMANTYCZNY (SAFE: NAJWIEKSZY SPADEK PODOBIENSTWA) ===\")\n",
        "        # Patrzymy na alpha = -35 (silne sterowanie)\n",
        "        high_steering = df_details[df_details[\"alpha\"] == -35.0]\n",
        "        if high_steering.empty and not df_detox.empty:\n",
        "             high_steering = df_details[df_details[\"alpha\"] == df_detox['alpha'].min()]\n",
        "\n",
        "        if not high_steering.empty:\n",
        "            distorted = high_steering[high_steering[\"label\"] == \"SAFE\"].nsmallest(3, \"cosine_sim\")\n",
        "\n",
        "            for _, row in distorted.iterrows():\n",
        "                print(f\"\\n  [alpha={row['alpha']}] Tekst: {row['text'][:100]}...\")\n",
        "                print(f\"    Cosine Sim: {row['cosine_sim']:.4f} (Oryginal vs Sterowany)\")\n",
        "                print(f\"    P(toxic): {row['prob_before']:.4f} -> {row['prob_after']:.4f}\")\n",
        "\n",
        "    print(\"\\nCzesc 3 zakonczona. Wygenerowano wykres: steering_tradeoff.png\")\n",
        "\n",
        "# Uruchomienie wizualizacji\n",
        "visualize_steering(df_steering, df_steering_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_header"
      },
      "source": [
        "---\n",
        "## Czesc 4: Podsumowanie i Wizualizacja Finalna\n",
        "\n",
        "Sekcja zbierajaca wyniki ze wszystkich trzech modulow eksperymentalnych.\n",
        "Generuje finalne wykresy do pracy magisterskiej w stylu akademickim.\n",
        "\n",
        "Wejscia:\n",
        "- `df_fidelity` (Czesc 1) - Comprehensiveness i Sufficiency dla IG vs IxG\n",
        "- `df_stability` (Czesc 2) - Korelacja Spearmana i Semantic Overlap dla Standard IG vs SmoothGrad\n",
        "- `df_steering`, `df_steering_details` (Czesc 3) - Success Rate i Side Effects per alpha\n",
        "\n",
        "Wyjscia:\n",
        "- Zbiorcza tabela metryk (`summary_all_metrics.csv`)\n",
        "- Wykres zbiorczy 3-w-1 (`summary_overview.png`)\n",
        "- Osobne wykresy per modul (`fig_fidelity.png`, `fig_stability.png`, `fig_steering.png`)\n",
        "- Automatyczne wnioski tekstowe\n",
        "- Lista wygenerowanych plikow z informacja o rozmiarze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_functions"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4. PODSUMOWANIE I WIZUALIZACJA FINALNA\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def _setup_academic_style():\n",
        "    \"\"\"\n",
        "    Konfiguruje styl akademicki matplotlib dla wykresow do pracy magisterskiej.\n",
        "\n",
        "    Ustawia styl 'seaborn-v0_8-paper' (z fallbackiem), zwiekszone fonty,\n",
        "    rozdzielczosc 300 DPI i palete przyjazna daltonistom.\n",
        "\n",
        "    Zwraca:\n",
        "        dict: Paleta kolorow z kluczami 'blue', 'red', 'orange', 'light_blue'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        plt.style.use('seaborn-v0_8-paper')\n",
        "    except OSError:\n",
        "        try:\n",
        "            plt.style.use('seaborn-paper')\n",
        "        except OSError:\n",
        "            pass  # Uzyj domyslnego stylu\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 11,\n",
        "        'axes.labelsize': 12,\n",
        "        'axes.titlesize': 13,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'legend.fontsize': 10,\n",
        "        'figure.dpi': 300,\n",
        "        'savefig.dpi': 300,\n",
        "        'savefig.bbox': 'tight',\n",
        "    })\n",
        "\n",
        "    # Paleta przyjazna daltonistom (ColorBrewer)\n",
        "    return {\n",
        "        'blue': '#2c7bb6',\n",
        "        'red': '#d7191c',\n",
        "        'orange': '#fdae61',\n",
        "        'light_blue': '#abd9e9',\n",
        "    }\n",
        "\n",
        "\n",
        "def _build_metrics_table(df_fidelity, df_stability, df_steering):\n",
        "    \"\"\"\n",
        "    Buduje zbiorcza tabele metryk ze wszystkich modulow eksperymentalnych.\n",
        "\n",
        "    Argumenty:\n",
        "        df_fidelity: DataFrame z Czesci 1\n",
        "        df_stability: DataFrame z Czesci 2\n",
        "        df_steering: DataFrame z Czesci 3 (zaktualizowany o avg_cosine_sim)\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z kolumnami: Module, Metric, Value\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # --- Czesc 1: Fidelity ---\n",
        "    for method, prefix in [(\"IG\", \"ig\"), (\"IxG\", \"ixg\")]:\n",
        "        for metric_name, col_suffix in [(\"Comprehensiveness\", \"comprehensiveness\"), (\"Sufficiency\", \"sufficiency\")]:\n",
        "            col = f\"{prefix}_{col_suffix}\"\n",
        "            mean_val = df_fidelity[col].mean()\n",
        "            std_val = df_fidelity[col].std()\n",
        "            rows.append({\n",
        "                \"Module\": \"Fidelity\",\n",
        "                \"Metric\": f\"{method} {metric_name}\",\n",
        "                \"Value\": f\"{mean_val:.4f} +/- {std_val:.4f}\",\n",
        "                \"Mean\": mean_val,\n",
        "                \"Std\": std_val,\n",
        "            })\n",
        "\n",
        "    # --- Czesc 2: Stability ---\n",
        "    for para_type, para_label in [(\"mistral\", \"Mistral\"), (\"synonym\", \"Synonym\")]:\n",
        "        df_sub = df_stability[df_stability[\"para_type\"] == para_type]\n",
        "        if df_sub.empty:\n",
        "            continue\n",
        "        for method, col in [(\"Std IG\", \"spearman_standard_ig\"), (\"SmoothGrad\", \"spearman_smoothgrad\")]:\n",
        "            mean_val = df_sub[col].mean()\n",
        "            std_val = df_sub[col].std()\n",
        "            rows.append({\n",
        "                \"Module\": \"Stability\",\n",
        "                \"Metric\": f\"Spearman {method} ({para_label})\",\n",
        "                \"Value\": f\"{mean_val:.4f} +/- {std_val:.4f}\",\n",
        "                \"Mean\": mean_val,\n",
        "                \"Std\": std_val,\n",
        "            })\n",
        "        for method, col in [(\"Std IG\", \"sem_overlap_standard_ig\"), (\"SmoothGrad\", \"sem_overlap_smoothgrad\")]:\n",
        "            mean_val = df_sub[col].mean()\n",
        "            std_val = df_sub[col].std()\n",
        "            rows.append({\n",
        "                \"Module\": \"Stability\",\n",
        "                \"Metric\": f\"Sem. Overlap {method} ({para_label})\",\n",
        "                \"Value\": f\"{mean_val:.4f} +/- {std_val:.4f}\",\n",
        "                \"Mean\": mean_val,\n",
        "                \"Std\": std_val,\n",
        "            })\n",
        "\n",
        "    # --- Czesc 3: Steering ---\n",
        "    best_idx = df_steering[\"success_rate\"].idxmax()\n",
        "    best = df_steering.loc[best_idx]\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Best Alpha\", \"Value\": f\"{best['alpha']:.1f}\", \"Mean\": best['alpha'], \"Std\": 0.0})\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Success Rate (best)\", \"Value\": f\"{best['success_rate']:.2f}%\", \"Mean\": best['success_rate'], \"Std\": 0.0})\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Avg Cosine Sim (best)\", \"Value\": f\"{best['avg_cosine_sim']:.4f}\", \"Mean\": best['avg_cosine_sim'], \"Std\": 0.0})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def _plot_fidelity(ax, df_fidelity, colors):\n",
        "    \"\"\"\n",
        "    Rysuje wykres Fidelity: Comprehensiveness i Sufficiency dla IG vs IxG.\n",
        "    \"\"\"\n",
        "    metrics = ['Comprehensiveness', 'Sufficiency']\n",
        "    ig_means = [\n",
        "        df_fidelity['ig_comprehensiveness'].mean(),\n",
        "        df_fidelity['ig_sufficiency'].mean(),\n",
        "    ]\n",
        "    ig_stds = [\n",
        "        df_fidelity['ig_comprehensiveness'].std(),\n",
        "        df_fidelity['ig_sufficiency'].std(),\n",
        "    ]\n",
        "    ixg_means = [\n",
        "        df_fidelity['ixg_comprehensiveness'].mean(),\n",
        "        df_fidelity['ixg_sufficiency'].mean(),\n",
        "    ]\n",
        "    ixg_stds = [\n",
        "        df_fidelity['ixg_comprehensiveness'].std(),\n",
        "        df_fidelity['ixg_sufficiency'].std(),\n",
        "    ]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    ax.bar(x - width / 2, ig_means, width, yerr=ig_stds, label='IG',\n",
        "           color=colors['blue'], capsize=4, error_kw={'linewidth': 1})\n",
        "    ax.bar(x + width / 2, ixg_means, width, yerr=ixg_stds, label='IxG',\n",
        "           color=colors['orange'], capsize=4, error_kw={'linewidth': 1})\n",
        "\n",
        "    ax.set_ylabel('Spadek prawdopodobienstwa')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.legend()\n",
        "    ax.set_title('(a) Fidelity: IG vs IxG')\n",
        "    ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "\n",
        "\n",
        "def _plot_stability(ax, df_stability, colors):\n",
        "    \"\"\"\n",
        "    Rysuje wykres Stability: Spearman i Sem. Overlap dla Standard IG vs SmoothGrad.\n",
        "    \"\"\"\n",
        "    groups = []\n",
        "    std_ig_vals = []\n",
        "    smooth_vals = []\n",
        "\n",
        "    for para_type, para_label in [('mistral', 'Mistral'), ('synonym', 'Synonym')]:\n",
        "        df_sub = df_stability[df_stability['para_type'] == para_type]\n",
        "        if df_sub.empty:\n",
        "            continue\n",
        "        groups.append(f'Spearman\\n({para_label})')\n",
        "        std_ig_vals.append(df_sub['spearman_standard_ig'].mean())\n",
        "        smooth_vals.append(df_sub['spearman_smoothgrad'].mean())\n",
        "\n",
        "        groups.append(f'Sem.Overlap\\n({para_label})')\n",
        "        std_ig_vals.append(df_sub['sem_overlap_standard_ig'].mean())\n",
        "        smooth_vals.append(df_sub['sem_overlap_smoothgrad'].mean())\n",
        "\n",
        "    if not groups:\n",
        "        ax.text(0.5, 0.5, 'Brak danych', ha='center', va='center', fontsize=12)\n",
        "        return\n",
        "\n",
        "    x = np.arange(len(groups))\n",
        "    width = 0.35\n",
        "\n",
        "    ax.bar(x - width / 2, std_ig_vals, width, label='Standard IG',\n",
        "           color=colors['red'], alpha=0.85)\n",
        "    ax.bar(x + width / 2, smooth_vals, width, label='SmoothGrad',\n",
        "           color=colors['light_blue'])\n",
        "\n",
        "    ax.set_ylabel('Wartosc metryki')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(groups, fontsize=8)\n",
        "    ax.legend()\n",
        "    ax.set_title('(b) Stability: Std IG vs SmoothGrad')\n",
        "    ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "\n",
        "\n",
        "def _plot_steering(ax, df_steering, colors):\n",
        "    \"\"\"\n",
        "    Rysuje wykres Steering: Success Rate (bary) i Cosine Similarity (linia) per alpha.\n",
        "    \"\"\"\n",
        "    # Sortowanie wartosci alpha rosnaco, aby os X byla logiczna\n",
        "    df_steering_sorted = df_steering.sort_values(by='alpha').reset_index(drop=True)\n",
        "\n",
        "    x = np.arange(len(df_steering_sorted))\n",
        "    alpha_labels = [f'{a:.0f}' for a in df_steering_sorted['alpha']]\n",
        "\n",
        "    bars = ax.bar(x, df_steering_sorted['success_rate'], color=colors['blue'], label='Success Rate')\n",
        "    ax.set_ylabel('Success Rate (%)', color=colors['blue'])\n",
        "    ax.set_xlabel('Alpha')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(alpha_labels)\n",
        "    ax.set_title('(c) Steering: Skutecznosc vs Spojnosc')\n",
        "    ax.axhline(y=80, color=colors['blue'], linestyle='--', alpha=0.4)\n",
        "    ax.set_ylim(0, 105)\n",
        "    ax.tick_params(axis='y', labelcolor=colors['blue'])\n",
        "\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax.annotate(f'{h:.0f}%', xy=(bar.get_x() + bar.get_width() / 2, h),\n",
        "                    xytext=(0, 3), textcoords='offset points', ha='center', fontsize=8)\n",
        "\n",
        "    # Druga os Y dla Cosine Similarity\n",
        "    ax2 = ax.twinx()\n",
        "    ax2.plot(x, df_steering_sorted['avg_cosine_sim'], color=colors['red'], marker='o', linewidth=2, label='Cosine Sim')\n",
        "    ax2.set_ylabel('Avg Cosine Sim', color=colors['red'])\n",
        "    ax2.axhline(y=0.90, color=colors['red'], linestyle='--', alpha=0.4)\n",
        "    ax2.set_ylim(0.5, 1.05)\n",
        "    ax2.tick_params(axis='y', labelcolor=colors['red'])\n",
        "\n",
        "\n",
        "def _generate_conclusions(df_fidelity, df_stability, df_steering):\n",
        "    \"\"\"\n",
        "    Generuje automatyczne wnioski tekstowe na podstawie wynikow eksperymentalnych.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"WNIOSKI Z EKSPERYMENTU\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # --- Wniosek 1: Fidelity ---\n",
        "    print(\"\\n--- 1. FIDELITY (Wiernosc wyjasnien) ---\")\n",
        "    ig_comp = df_fidelity['ig_comprehensiveness'].mean()\n",
        "    ixg_comp = df_fidelity['ixg_comprehensiveness'].mean()\n",
        "    ig_suff = df_fidelity['ig_sufficiency'].mean()\n",
        "    ixg_suff = df_fidelity['ixg_sufficiency'].mean()\n",
        "\n",
        "    comp_winner = 'IG' if ig_comp > ixg_comp else 'IxG'\n",
        "    comp_diff = abs(ig_comp - ixg_comp)\n",
        "    print(f\"  Comprehensiveness: {comp_winner} jest lepsza o {comp_diff:.4f}\")\n",
        "    print(f\"    IG={ig_comp:.4f}, IxG={ixg_comp:.4f}\")\n",
        "    print(f\"    (wyzsza wartosc = metoda lepiej identyfikuje kluczowe tokeny)\")\n",
        "\n",
        "    suff_winner = 'IG' if ig_suff < ixg_suff else 'IxG'\n",
        "    suff_diff = abs(ig_suff - ixg_suff)\n",
        "    print(f\"  Sufficiency: {suff_winner} jest lepsza o {suff_diff:.4f}\")\n",
        "    print(f\"    IG={ig_suff:.4f}, IxG={ixg_suff:.4f}\")\n",
        "    print(f\"    (nizsza wartosc = same top tokeny wystarczaja do utrzymania predykcji)\")\n",
        "\n",
        "    # --- Wniosek 2: Stability ---\n",
        "    print(\"\\n--- 2. STABILITY (Stabilnosc wyjasnien) ---\")\n",
        "    for para_type, para_label in [('mistral', 'Mistral'), ('synonym', 'Synonimy')]:\n",
        "        df_sub = df_stability[df_stability['para_type'] == para_type]\n",
        "        if df_sub.empty:\n",
        "            print(f\"  {para_label}: Brak danych.\")\n",
        "            continue\n",
        "\n",
        "        sp_std = df_sub['spearman_standard_ig'].mean()\n",
        "        sp_smooth = df_sub['spearman_smoothgrad'].mean()\n",
        "        sp_improvement = sp_smooth - sp_std\n",
        "        sp_pct = (sp_improvement / abs(sp_std) * 100) if sp_std != 0 else 0\n",
        "\n",
        "        so_std = df_sub['sem_overlap_standard_ig'].mean()\n",
        "        so_smooth = df_sub['sem_overlap_smoothgrad'].mean()\n",
        "        so_improvement = so_smooth - so_std\n",
        "        so_pct = (so_improvement / abs(so_std) * 100) if so_std != 0 else 0\n",
        "\n",
        "        print(f\"  Parafrazy {para_label} (n={len(df_sub)}):\")\n",
        "        print(f\"    Spearman: Std IG={sp_std:.4f}, SmoothGrad={sp_smooth:.4f} \"\n",
        "              f\"(poprawa: {sp_improvement:+.4f}, {sp_pct:+.1f}%)\")\n",
        "        print(f\"    Sem.Overlap: Std IG={so_std:.4f}, SmoothGrad={so_smooth:.4f} \"\n",
        "              f\"(poprawa: {so_improvement:+.4f}, {so_pct:+.1f}%)\")\n",
        "\n",
        "    # --- Wniosek 3: Steering ---\n",
        "    print(\"\\n--- 3. STEERING (Sterowanie reprezentacjami) ---\")\n",
        "    best_idx = df_steering['success_rate'].idxmax()\n",
        "    best = df_steering.loc[best_idx]\n",
        "    optimal = best['success_rate'] > 80 and best['avg_cosine_sim'] >= 0.85\n",
        "\n",
        "    print(f\"  Najlepsza wartosc alpha (wg Success Rate): {best['alpha']:.1f}\")\n",
        "    print(f\"    Success Rate:     {best['success_rate']:.2f}% {'(cel >80% SPELNIONY)' if best['success_rate'] > 80 else '(cel >80% NIESPELNIONY)'}\")\n",
        "    print(f\"    Avg Cosine Sim:   {best['avg_cosine_sim']:.4f} {'(cel >=0.85 SPELNIONY)' if best['avg_cosine_sim'] >= 0.85 else '(cel >=0.85 NIESPELNIONY)'}\")\n",
        "\n",
        "    if optimal:\n",
        "        print(f\"\\n  KONKLUZJA: Steering z alpha={best['alpha']:.1f} skutecznie detoksykuje model\")\n",
        "        print(f\"  bez retrenowania, przy zachowaniu akceptowalnej spojnosci semantycznej.\")\n",
        "    else:\n",
        "        print(f\"\\n  KONKLUZJA: Steering wymaga dalszego dostrojenia parametru alpha.\")\n",
        "        print(f\"  Zaden z testowanych wariantow nie spelnia jednoczesnie obu kryteriow optymalnosci.\")\n",
        "\n",
        "    # --- Podsumowanie globalne ---\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"PODSUMOWANIE GLOBALNE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"  1. Najlepsza metoda XAI pod wzgledem fidelity: {comp_winner} (Comprehensiveness)\")\n",
        "    print(f\"  2. SmoothGrad poprawia stabilnosc wyjasnien w porownaniu do Standard IG\")\n",
        "    print(f\"  3. Steering {'skutecznie' if optimal else 'czesciowo'} naprawia model bez retrenowania\")\n",
        "\n",
        "\n",
        "def generate_summary_report(df_fidelity, df_stability, df_steering, df_steering_details):\n",
        "    \"\"\"\n",
        "    Generuje kompletny raport podsumowujacy z wykresami w stylu akademickim.\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 4] Generowanie raportu podsumowujacego...\")\n",
        "\n",
        "    # Styl akademicki\n",
        "    colors = _setup_academic_style()\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.1 TABELA ZBIORCZA METRYK\n",
        "    # -----------------------------------------------\n",
        "    print(\"    Budowanie zbiorczej tabeli metryk...\")\n",
        "    df_metrics = _build_metrics_table(df_fidelity, df_stability, df_steering)\n",
        "    df_metrics.to_csv(f\"{RESULTS_DIR}/summary_all_metrics.csv\", index=False)\n",
        "\n",
        "    print(\"\\n=== ZBIORCZA TABELA METRYK ===\")\n",
        "    print(df_metrics[['Module', 'Metric', 'Value']].to_string(index=False))\n",
        "    print(f\"\\n    Tabela zapisana do: {RESULTS_DIR}/summary_all_metrics.csv\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.2 WYKRES ZBIORCZY 3-W-1\n",
        "    # -----------------------------------------------\n",
        "    print(\"\\n    Generowanie wykresu zbiorczego...\")\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    _plot_fidelity(axes[0], df_fidelity, colors)\n",
        "    _plot_stability(axes[1], df_stability, colors)\n",
        "    _plot_steering(axes[2], df_steering, colors)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/summary_overview.png\")\n",
        "    plt.show()\n",
        "    print(f\"    Wykres zbiorczy zapisany: {RESULTS_DIR}/summary_overview.png\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.3 OSOBNE WYKRESY PER MODUL\n",
        "    # -----------------------------------------------\n",
        "    print(\"\\n    Generowanie osobnych wykresow...\")\n",
        "\n",
        "    # Fig Fidelity\n",
        "    fig_f, ax_f = plt.subplots(figsize=(6, 4.5))\n",
        "    _plot_fidelity(ax_f, df_fidelity, colors)\n",
        "    ax_f.set_title('')  # Bez tytulu - LaTeX caption\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fig_fidelity.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Fig Stability\n",
        "    fig_s, ax_s = plt.subplots(figsize=(7, 4.5))\n",
        "    _plot_stability(ax_s, df_stability, colors)\n",
        "    ax_s.set_title('')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fig_stability.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Fig Steering\n",
        "    fig_st, ax_st = plt.subplots(figsize=(6, 4.5))\n",
        "    _plot_steering(ax_st, df_steering, colors)\n",
        "    ax_st.set_title('')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fig_steering.png\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"    Osobne wykresy zapisane: fig_fidelity.png, fig_stability.png, fig_steering.png\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.4 AUTOMATYCZNE WNIOSKI\n",
        "    # -----------------------------------------------\n",
        "    _generate_conclusions(df_fidelity, df_stability, df_steering)\n",
        "\n",
        "    print(\"\\nCzesc 4 zakonczona.\")\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_summary"
      },
      "outputs": [],
      "source": [
        "df_metrics = generate_summary_report(df_fidelity, df_stability, df_steering, df_steering_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "file_inventory"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4.5 LISTA WYGENEROWANYCH PLIKOW\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def list_generated_files():\n",
        "    \"\"\"\n",
        "    Wyswietla liste wszystkich plikow wygenerowanych przez notebook\n",
        "    w katalogu RESULTS_DIR z informacja o rozmiarze i typie.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"WYGENEROWANE PLIKI\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    type_map = {\n",
        "        '.csv': 'CSV',\n",
        "        '.png': 'PNG',\n",
        "        '.npy': 'NumPy',\n",
        "        '.txt': 'Text',\n",
        "    }\n",
        "\n",
        "    total_size = 0\n",
        "    file_count = 0\n",
        "\n",
        "    files = sorted(os.listdir(RESULTS_DIR))\n",
        "    for f in files:\n",
        "        file_path = os.path.join(RESULTS_DIR, f)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_kb = os.path.getsize(file_path) / 1024\n",
        "            total_size += size_kb\n",
        "            file_count += 1\n",
        "            ext = os.path.splitext(f)[1].lower()\n",
        "            ftype = type_map.get(ext, ext)\n",
        "            print(f\"  {f:40s} {ftype:6s} {size_kb:8.2f} KB\")\n",
        "\n",
        "    print(f\"\\n  {'RAZEM':40s} {'':6s} {total_size:8.2f} KB ({file_count} plikow)\")\n",
        "    print(f\"\\n  Katalog wynikow: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_file_inventory"
      },
      "outputs": [],
      "source": [
        "list_generated_files()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
