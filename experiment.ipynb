{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janbanot/msc-project/blob/main/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_title"
      },
      "source": [
        "# Experiment: XAI & Representation Engineering for Toxic Comment Classification\n",
        "\n",
        "Skonsolidowany notebook eksperymentalny zawierajacy:\n",
        "- **Modul 0**: Konfiguracja i Przygotowanie\n",
        "- **Modul A**: Porownanie metod XAI (Comprehensiveness)\n",
        "- **Modul B**: Analiza warstwowa (RepE)\n",
        "- **Modul C**: Test stabilnosci (Semantic Robustness)\n",
        "- **Modul D**: Test skutecznosci sterowania (Steering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "module0_header"
      },
      "source": [
        "---\n",
        "## Modul 0: Konfiguracja i Przygotowanie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!uv pip install transformers datasets captum quantus accelerate bitsandbytes sentence-transformers nltk scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 0.1 IMPORTY\n",
        "# ===================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Dane i preprocessing\n",
        "from datasets import Dataset\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Modele\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "# XAI\n",
        "from captum.attr import IntegratedGradients, InputXGradient\n",
        "\n",
        "# Stabilnosc semantyczna (Modul C)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Synonimy (Modul C - alternatywa dla Mistrala)\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Zarzadzanie pamiecia\n",
        "import gc\n",
        "\n",
        "# Wizualizacja w notebooku\n",
        "from IPython.display import Image, display, Markdown\n",
        "\n",
        "# Opcje wyswietlania Pandas\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drive_mount"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "global_config"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 0.2 KONFIGURACJA GLOBALNA\n",
        "# ===================================================\n",
        "\n",
        "# === Sciezki ===\n",
        "DATA_PATH = \"/drive/MyDrive/msc-project/jigsaw-toxic-comment/train.csv\"\n",
        "MODEL_CHECKPOINT = \"/drive/MyDrive/msc-project/models/distilbert-jigsaw-full_20260125_133112\"\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RESULTS_DIR = f\"/drive/MyDrive/msc-project/results_{TIMESTAMP}\"\n",
        "\n",
        "# === Parametry ogolne ===\n",
        "BATCH_SIZE = 32\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "CLASSIFICATION_THRESHOLD = 0.5\n",
        "DF_SIZE = 3000  # Ograniczenie wielkosci zbioru danych\n",
        "\n",
        "# === Parametry XAI (Modul A) ===\n",
        "N_SAMPLES_XAI = 100  # Liczba probek dla metod XAI (IG / InputXGradient)\n",
        "XAI_N_STEPS = 50     # Liczba krokow dla Integrated Gradients\n",
        "TOP_K_TOKENS = 5     # Liczba najwazniejszych tokenow do analizy Comprehensiveness\n",
        "\n",
        "# === Parametry RepE (Modul B) ===\n",
        "N_SAMPLES_PROBE = 1000  # Liczba probek do analizy warstwowej\n",
        "TARGET_LAYER_INDEX = 5  # Warstwa docelowa (najlepsza separowalnosc liniowa)\n",
        "\n",
        "# === Parametry stabilnosci (Modul C) ===\n",
        "N_SAMPLES_STABILITY = 50     # Liczba par tekst-parafraza\n",
        "PARAPHRASE_MIN_SIMILARITY = 0.7  # Minimalny cosine similarity dla akceptacji parafrazy\n",
        "PARAPHRASE_SEED = 42        # Seed dla reproducibility\n",
        "SMOOTHGRAD_N_SAMPLES = 30   # Liczba probek szumu w SmoothGrad\n",
        "SMOOTHGRAD_NOISE_STD = 0.1  # Odchylenie standardowe szumu gaussowskiego\n",
        "SYNONYM_REPLACE_RATIO = 0.3 # Procent slow do zamiany na synonimy\n",
        "\n",
        "# === Parametry Steering (Modul D) ===\n",
        "STEERING_ALPHA = -3.0       # Sila wektora sterujacego (ujemna = detoksykacja)\n",
        "ALPHA_VALUES = [-10.0, -20.0, -50.0]  # Wartosci alpha do testowania\n",
        "N_SAMPLES_PER_CLASS = 25    # Liczba probek na klase do testu steeringu\n",
        "MISTRAL_MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Model LLM do parafrazowania\n",
        "\n",
        "# === Urzadzenie obliczeniowe ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Urzadzenie: {device}\")\n",
        "\n",
        "# Tworzenie katalogu wynikow\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "print(f\"Wyniki beda zapisane w: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_functions"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 0.3 PRZYGOTOWANIE DANYCH I MODELU\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def clean_text(example):\n",
        "    \"\"\"\n",
        "    Czysci tekst komentarza, usuwajac niepozadane elementy i normalizujac format.\n",
        "\n",
        "    Funkcja stosowana zarowno podczas treningu jak i ewaluacji, aby zapewnic\n",
        "    spojnosc przetwarzania danych.\n",
        "\n",
        "    Argumenty:\n",
        "        example: Slownik zawierajacy klucz 'comment_text' z tekstem do oczyszczenia\n",
        "\n",
        "    Zwraca:\n",
        "        Zmodyfikowany slownik example z oczyszczonym tekstem w polu 'comment_text'\n",
        "\n",
        "    Operacje czyszczenia:\n",
        "        - Konwersja na male litery (wymagane dla modeli BERT typu uncased)\n",
        "        - Usuniecie linkow URL (http/https/www)\n",
        "        - Usuniecie adresow IP\n",
        "        - Usuniecie metadanych Wikipedii (talk pages, timestampy UTC)\n",
        "        - Normalizacja bialych znakow (spacje, newline, non-breaking space)\n",
        "        - Usuniecie cudzyslowow z poczatku i konca\n",
        "    \"\"\"\n",
        "    text = example[\"comment_text\"]\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", \"\", text)\n",
        "    text = re.sub(r\"\\(talk\\)\", \"\", text)\n",
        "    text = re.sub(r\"\\d{2}:\\d{2}, \\w+ \\d{1,2}, \\d{4} \\(utc\\)\", \"\", text)\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
        "    text = text.strip(' \"')\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    example[\"comment_text\"] = text\n",
        "    return example\n",
        "\n",
        "\n",
        "def prepare_environment():\n",
        "    \"\"\"\n",
        "    Przygotowuje srodowisko eksperymentalne: wczytuje dane, tokenizuje i laduje model.\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple zawierajacy:\n",
        "        - model: Wytrenowany model DistilBERT do klasyfikacji toksycznosci\n",
        "        - tokenizer: Tokenizer dopasowany do modelu\n",
        "        - eval_dataset: Zbior testowy z przetworzonymi danymi\n",
        "\n",
        "    Kroki przygotowania:\n",
        "        1. Wczytanie danych z pliku CSV\n",
        "        2. Preprocessing tekstow\n",
        "        3. Ladowanie tokenizera\n",
        "        4. Tokenizacja tekstow (padding do MAX_SEQUENCE_LENGTH)\n",
        "        5. Przygotowanie etykiet binary classification\n",
        "        6. Podzial na zbior treningowy i testowy\n",
        "        7. Zaladowanie wytrenowanego modelu\n",
        "    \"\"\"\n",
        "    print(\">>> [SETUP] Wczytywanie i przetwarzanie danych...\")\n",
        "\n",
        "    # 1. Wczytanie danych\n",
        "    try:\n",
        "        df = pd.read_csv(DATA_PATH).head(DF_SIZE)\n",
        "        dataset = Dataset.from_pandas(df)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Nie znaleziono pliku: {DATA_PATH}. Sprawdz sciezke w Konfiguracji Globalnej.\"\n",
        "        )\n",
        "\n",
        "    # 2. Preprocessing\n",
        "    dataset = dataset.map(clean_text)\n",
        "\n",
        "    # 3. Ladowanie tokenizera zgodnego z modelem\n",
        "    print(f\">>> [SETUP] Ladowanie tokenizera z: {MODEL_CHECKPOINT}...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "    except OSError:\n",
        "        print(\n",
        "            f\"Blad: Nie znaleziono tokenizera w {MODEL_CHECKPOINT}. Pobieram domyslny 'distilbert-base-uncased'.\"\n",
        "        )\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    # 4. Tokenizacja\n",
        "    def tokenize_function(examples):\n",
        "        \"\"\"Tokenizuje teksty z paddingiem do stalej dlugosci MAX_SEQUENCE_LENGTH.\"\"\"\n",
        "        return tokenizer(\n",
        "            examples[\"comment_text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_SEQUENCE_LENGTH,\n",
        "        )\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    # 5. Przygotowanie etykiet binary classification\n",
        "    label_cols = [\"toxic\"]\n",
        "\n",
        "    def create_labels(example):\n",
        "        \"\"\"Pobiera kolumne 'toxic' i tworzy etykiete.\"\"\"\n",
        "        example[\"labels\"] = [float(example[col]) for col in label_cols]\n",
        "        return example\n",
        "\n",
        "    final_dataset = tokenized_dataset.map(create_labels)\n",
        "\n",
        "    # Ustawienie formatu PyTorch (usuniecie kolumn tekstowych, zachowanie tylko tensorow)\n",
        "    cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "    final_dataset.set_format(\"torch\", columns=cols_to_keep)\n",
        "\n",
        "    # 6. Podzial na zbior treningowy i testowy\n",
        "    splits = final_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "    eval_dataset = splits[\"test\"]\n",
        "\n",
        "    # 7. Ladowanie wytrenowanego modelu\n",
        "    print(f\">>> [SETUP] Ladowanie wytrenowanego modelu z: {MODEL_CHECKPOINT}...\")\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_CHECKPOINT, num_labels=1, problem_type=\"single_label_classification\"\n",
        "        )\n",
        "    except OSError:\n",
        "        raise OSError(\n",
        "            f\"Nie znaleziono modelu w sciezce: {MODEL_CHECKPOINT}. Upewnij sie, ze najpierw uruchomiles skrypt treningowy.\"\n",
        "        )\n",
        "\n",
        "    # Przelaczenie w tryb ewaluacji (wylacza dropout i batch normalization)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\">>> [SETUP] Srodowisko gotowe. Urzadzenie: {device}\")\n",
        "    print(f\">>> [SETUP] Zbior ewaluacyjny: {len(eval_dataset)} probek\")\n",
        "    return model, tokenizer, eval_dataset\n",
        "\n",
        "\n",
        "# Inicjalizacja srodowiska\n",
        "model, tokenizer, eval_dataset = prepare_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fidelity_header"
      },
      "source": [
        "---\n",
        "## Czesc 1: Analiza Wiernosci (Fidelity Check)\n",
        "\n",
        "Cel: Wykazanie, ze metody XAI wskazuja faktycznie wazne cechy.\n",
        "\n",
        "Metryki:\n",
        "- **Comprehensiveness**: Czy usuniecie najwazniejszych tokenow zmienia decyzje modelu? (wysoka wartosc = dobra metoda)\n",
        "- **Sufficiency**: Czy same najwazniejsze tokeny wystarczaja do utrzymania decyzji? (niska wartosc = dobra metoda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "experiment_fidelity"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 1. ANALIZA WIERNOSCI (FIDELITY CHECK)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def experiment_fidelity(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Porownuje metody XAI (Integrated Gradients vs InputXGradient) pod katem wiernosci wyjasnien.\n",
        "\n",
        "    Metryki:\n",
        "        - Comprehensiveness: mierzy spadek pewnosci po usunieciu TOP_K najwazniejszych tokenow.\n",
        "          Wysoki spadek = metoda XAI dobrze identyfikuje kluczowe cechy.\n",
        "        - Sufficiency: mierzy spadek pewnosci gdy zachowamy TYLKO TOP_K najwazniejszych tokenow.\n",
        "          Niski spadek = same najwazniejsze tokeny wystarczaja do utrzymania predykcji.\n",
        "\n",
        "    Argumenty:\n",
        "        model: Wytrenowany model klasyfikacyjny DistilBERT\n",
        "        tokenizer: Tokenizer odpowiadajacy modelowi\n",
        "        dataset: Zbior danych z etykietami\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z wynikami porownania metod (comprehensiveness i sufficiency dla IG i IxG)\n",
        "\n",
        "    Metodologia:\n",
        "        1. Wybor podzbioru toksycznych przykladow (N_SAMPLES_XAI)\n",
        "        2. Dla kazdego przykladu:\n",
        "            a) Obliczenie oryginalnego prawdopodobienstwa toksycznosci\n",
        "            b) Identyfikacja TOP_K_TOKENS najwazniejszych tokenow (IG i InputXGradient)\n",
        "            c) Comprehensiveness: maskowanie tych tokenow i ponowna predykcja\n",
        "            d) Sufficiency: zachowanie TYLKO tych tokenow i ponowna predykcja\n",
        "        3. Wizualizacja wynikow jako boxplot (2 subploty)\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 1] Uruchamianie analizy wiernosci (IG vs IxG)...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Filtrowanie tylko toksycznych przykladow (indeks 0 = etykieta 'toxic')\n",
        "    toxic_indices = [i for i, labels in enumerate(dataset[\"labels\"]) if labels[0] == 1]\n",
        "    subset_indices = toxic_indices[:N_SAMPLES_XAI]\n",
        "    subset = dataset.select(subset_indices)\n",
        "    print(f\"    Wybrano {len(subset)} toksycznych probek do analizy.\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Funkcja pomocnicza dla Captum (zwraca logity na podstawie embeddings)\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        \"\"\"Wrapper predykcji dla biblioteki Captum.\"\"\"\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "    ixg = InputXGradient(predict_func)\n",
        "\n",
        "    for i in tqdm(range(len(subset)), desc=\"Ewaluacja XAI (Fidelity)\"):\n",
        "        input_ids = subset[i][\"input_ids\"].unsqueeze(0).to(device)\n",
        "        attention_mask = subset[i][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "        input_embeds = model.distilbert.embeddings(input_ids)\n",
        "\n",
        "        # Baseline = embedding tokena [PAD] (punkt odniesienia dla IG)\n",
        "        baseline = model.distilbert.embeddings(\n",
        "            torch.tensor(\n",
        "                [tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device\n",
        "            ).unsqueeze(0)\n",
        "        )\n",
        "\n",
        "        # 1. Oryginalne prawdopodobienstwo toksycznosci\n",
        "        with torch.no_grad():\n",
        "            orig_out = model(inputs_embeds=input_embeds, attention_mask=attention_mask)\n",
        "            orig_prob = torch.sigmoid(orig_out.logits)[0, 0].item()\n",
        "\n",
        "        # --- Funkcje pomocnicze do obliczania metryk ---\n",
        "\n",
        "        def calculate_comprehensiveness(attr_tensor):\n",
        "            \"\"\"\n",
        "            Comprehensiveness: maskuje TOP_K najwazniejszych tokenow (zamiana na [PAD]).\n",
        "            Wysoki wynik = metoda dobrze identyfikuje wazne tokeny.\n",
        "\n",
        "            Zwraca:\n",
        "                Spadek prawdopodobienstwa (orig_prob - new_prob)\n",
        "            \"\"\"\n",
        "            # Suma po wymiarze embeddingow -> waznosc na poziomie tokenow\n",
        "            attr_sum = attr_tensor.sum(dim=-1).squeeze(0)\n",
        "            # Znajdz TOP_K najwazniejszych tokenow\n",
        "            _, top_indices = torch.topk(attr_sum, k=TOP_K_TOKENS)\n",
        "\n",
        "            # Maskowanie tokenow (zamiana na [PAD])\n",
        "            masked_ids = input_ids.clone()\n",
        "            masked_ids[0, top_indices] = tokenizer.pad_token_id\n",
        "\n",
        "            with torch.no_grad():\n",
        "                new_out = model(masked_ids, attention_mask=attention_mask)\n",
        "                new_prob = torch.sigmoid(new_out.logits)[0, 0].item()\n",
        "\n",
        "            return orig_prob - new_prob\n",
        "\n",
        "        def calculate_sufficiency(attr_tensor):\n",
        "            \"\"\"\n",
        "            Sufficiency: zachowuje TYLKO TOP_K najwazniejszych tokenow, reszta -> [PAD].\n",
        "            Niski wynik = same najwazniejsze tokeny wystarczaja do utrzymania predykcji.\n",
        "\n",
        "            Zwraca:\n",
        "                Spadek prawdopodobienstwa (orig_prob - new_prob)\n",
        "            \"\"\"\n",
        "            attr_sum = attr_tensor.sum(dim=-1).squeeze(0)\n",
        "            _, top_indices = torch.topk(attr_sum, k=TOP_K_TOKENS)\n",
        "\n",
        "            # Zachowaj TYLKO top-K tokenow, reszta -> [PAD]\n",
        "            masked_ids = torch.full_like(input_ids, tokenizer.pad_token_id)\n",
        "            masked_ids[0, top_indices] = input_ids[0, top_indices]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                new_out = model(masked_ids, attention_mask=attention_mask)\n",
        "                new_prob = torch.sigmoid(new_out.logits)[0, 0].item()\n",
        "\n",
        "            return orig_prob - new_prob\n",
        "\n",
        "        # 2. Metoda Integrated Gradients\n",
        "        attr_ig, _ = ig.attribute(\n",
        "            inputs=input_embeds,\n",
        "            baselines=baseline,\n",
        "            target=0,\n",
        "            n_steps=XAI_N_STEPS,\n",
        "            additional_forward_args=(attention_mask,),\n",
        "            return_convergence_delta=True,\n",
        "        )\n",
        "        comp_ig = calculate_comprehensiveness(attr_ig)\n",
        "        suff_ig = calculate_sufficiency(attr_ig)\n",
        "\n",
        "        # 3. Metoda InputXGradient\n",
        "        attr_ixg = ixg.attribute(\n",
        "            inputs=input_embeds, target=0, additional_forward_args=(attention_mask,)\n",
        "        )\n",
        "        comp_ixg = calculate_comprehensiveness(attr_ixg)\n",
        "        suff_ixg = calculate_sufficiency(attr_ixg)\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                \"text_id\": i,\n",
        "                \"original_prob\": orig_prob,\n",
        "                \"ig_comprehensiveness\": comp_ig,\n",
        "                \"ixg_comprehensiveness\": comp_ixg,\n",
        "                \"ig_sufficiency\": suff_ig,\n",
        "                \"ixg_sufficiency\": suff_ixg,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # Zapis wynikow\n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_res.to_csv(f\"{RESULTS_DIR}/fidelity_results.csv\", index=False)\n",
        "\n",
        "    # Wizualizacja: 2 subploty (Comprehensiveness | Sufficiency)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Subplot 1: Comprehensiveness\n",
        "    sns.boxplot(\n",
        "        data=df_res[[\"ig_comprehensiveness\", \"ixg_comprehensiveness\"]],\n",
        "        ax=axes[0],\n",
        "    )\n",
        "    axes[0].set_title(\n",
        "        f\"Comprehensiveness - Usunieto {TOP_K_TOKENS} Najwazniejszych Tokenow\"\n",
        "    )\n",
        "    axes[0].set_ylabel(\"Spadek Prawdopodobienstwa\")\n",
        "    axes[0].set_xticklabels([\"IG\", \"IxG\"])\n",
        "\n",
        "    # Subplot 2: Sufficiency\n",
        "    sns.boxplot(\n",
        "        data=df_res[[\"ig_sufficiency\", \"ixg_sufficiency\"]],\n",
        "        ax=axes[1],\n",
        "    )\n",
        "    axes[1].set_title(\n",
        "        f\"Sufficiency - Zachowano TYLKO {TOP_K_TOKENS} Najwazniejszych Tokenow\"\n",
        "    )\n",
        "    axes[1].set_ylabel(\"Spadek Prawdopodobienstwa\")\n",
        "    axes[1].set_xticklabels([\"IG\", \"IxG\"])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fidelity_boxplot.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    # Podsumowanie statystyk\n",
        "    print(\"\\n=== PODSUMOWANIE WIERNOSCI (FIDELITY) ===\")\n",
        "    print(f\"Probek: {len(df_res)}\")\n",
        "    print(f\"\\nComprehensiveness (wyzsza = lepsza metoda):\")\n",
        "    print(f\"  IG  - srednia: {df_res['ig_comprehensiveness'].mean():.4f}, mediana: {df_res['ig_comprehensiveness'].median():.4f}\")\n",
        "    print(f\"  IxG - srednia: {df_res['ixg_comprehensiveness'].mean():.4f}, mediana: {df_res['ixg_comprehensiveness'].median():.4f}\")\n",
        "    print(f\"\\nSufficiency (nizsza = lepsza metoda):\")\n",
        "    print(f\"  IG  - srednia: {df_res['ig_sufficiency'].mean():.4f}, mediana: {df_res['ig_sufficiency'].median():.4f}\")\n",
        "    print(f\"  IxG - srednia: {df_res['ixg_sufficiency'].mean():.4f}, mediana: {df_res['ixg_sufficiency'].median():.4f}\")\n",
        "\n",
        "    print(\"\\nCzesc 1 zakonczona.\")\n",
        "    return df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_fidelity"
      },
      "outputs": [],
      "source": [
        "df_fidelity = experiment_fidelity(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stability_header"
      },
      "source": [
        "---\n",
        "## Czesc 2: Analiza Stabilnosci (Robustness & Stability)\n",
        "\n",
        "Cel: Wykazanie, ze standardowe metody XAI (IG) sa niestabilne przy parafrazach tekstu,\n",
        "a technika SmoothGrad znaczaco poprawia stabilnosc wyjasnien.\n",
        "\n",
        "Podejscie:\n",
        "- **Dwie metody parafrazowania**: Mistral-7B (semantyczna parafraza) + zamiana synonimow (WordNet)\n",
        "- **Dwie metody XAI**: Standard IG vs SmoothGrad (IG + szum gaussowski)\n",
        "- **Dwie metryki porownania**: Korelacja Spearmana (na wspolnym slowniku) + Semantic Overlap (top-K slow)\n",
        "\n",
        "Oczekiwany wynik: SmoothGrad daje wyzsza korelacje miedzy wyjasnieniam dla oryginalow i parafraz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_paraphrase_gen"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.1 GENEROWANIE PARAFRAZ (MISTRAL + SYNONIMY)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def generate_paraphrase_mistral(text, llm_model, llm_tokenizer, llm_device):\n",
        "    \"\"\"\n",
        "    Generuje parafraze toksycznego komentarza za pomoca Mistral-7B z few-shot promptingiem.\n",
        "\n",
        "    Wykorzystuje agresywne czyszczenie regexem, aby usunac typowe wstepy generowane\n",
        "    przez model (np. 'Here is your paraphrase').\n",
        "\n",
        "    Argumenty:\n",
        "        text: Tekst oryginalny do sparafrazowania\n",
        "        llm_model: Zaladowany model Mistral-7B\n",
        "        llm_tokenizer: Tokenizer Mistrala\n",
        "        llm_device: Urzadzenie obliczeniowe\n",
        "\n",
        "    Zwraca:\n",
        "        Oczyszczona parafraza jako string\n",
        "    \"\"\"\n",
        "    few_shot_examples = \"\"\"\n",
        "    Task: Paraphrase toxic comments. Maintain intent. Output ONLY the text.\n",
        "\n",
        "    Original: \"you are a complete failure and a waste of space\"\n",
        "    Paraphrase: \"you're a total loser who doesn't belong here\"\n",
        "\n",
        "    Original: \"shut your mouth you stupid prick\"\n",
        "    Paraphrase: \"keep your mouth shut you moronic jerk\"\n",
        "\n",
        "    Original: \"get out of this group, no one likes you\"\n",
        "    Paraphrase: \"leave this community, nobody wants you here\"\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"<s>[INST] {few_shot_examples}\\nNow paraphrase this:\\nOriginal: \\\"{text}\\\" [/INST]Paraphrase:\"\n",
        "\n",
        "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(llm_device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=llm_tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    gen_text = llm_tokenizer.decode(\n",
        "        outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True\n",
        "    ).strip()\n",
        "\n",
        "    # Agresywne czyszczenie regexem\n",
        "    patterns = [\n",
        "        r\"(?i)^here's a paraphrased version.*?:\",\n",
        "        r\"(?i)^here is a paraphrase.*?:\",\n",
        "        r\"(?i)^sure, here is.*?:\",\n",
        "        r\"(?i)^paraphrased text:\",\n",
        "        r\"(?i)^hello there,\",\n",
        "        r\"(?i)^the paraphrase is:\",\n",
        "        r\"(?i)^original:.*?\\n\",\n",
        "    ]\n",
        "\n",
        "    clean = gen_text.split('\\n')[0]\n",
        "    for p in patterns:\n",
        "        clean = re.sub(p, \"\", clean).strip()\n",
        "\n",
        "    return clean.strip().strip('\"')\n",
        "\n",
        "\n",
        "def generate_synonym_paraphrase(text, replace_ratio=SYNONYM_REPLACE_RATIO):\n",
        "    \"\"\"\n",
        "    Generuje parafraze przez losowa zamiane slow na synonimy z WordNet.\n",
        "\n",
        "    Metoda deterministyczna i szybka - nie wymaga modelu LLM.\n",
        "    Zamienia tylko rzeczowniki, czasowniki, przymiotniki i przyslowki.\n",
        "\n",
        "    Argumenty:\n",
        "        text: Tekst oryginalny\n",
        "        replace_ratio: Jaki procent slow zamienic (domyslnie SYNONYM_REPLACE_RATIO)\n",
        "\n",
        "    Zwraca:\n",
        "        Tekst z zamienionymi slowami na synonimy\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    n_to_replace = max(1, int(len(words) * replace_ratio))\n",
        "\n",
        "    # Wybierz losowe indeksy do zamiany\n",
        "    np.random.seed(None)  # Losowy seed dla roznorodnosci\n",
        "    candidate_indices = list(range(len(words)))\n",
        "    np.random.shuffle(candidate_indices)\n",
        "\n",
        "    replaced = 0\n",
        "    new_words = words.copy()\n",
        "\n",
        "    for idx in candidate_indices:\n",
        "        if replaced >= n_to_replace:\n",
        "            break\n",
        "\n",
        "        word = words[idx].lower().strip('.,!?;:')\n",
        "        if len(word) < 3:  # Pomijaj krotkie slowa\n",
        "            continue\n",
        "\n",
        "        # Szukaj synonimow w WordNet\n",
        "        synsets = wordnet.synsets(word)\n",
        "        synonyms = set()\n",
        "        for syn in synsets:\n",
        "            for lemma in syn.lemmas():\n",
        "                name = lemma.name().replace('_', ' ')\n",
        "                if name.lower() != word:\n",
        "                    synonyms.add(name)\n",
        "\n",
        "        if synonyms:\n",
        "            synonym = np.random.choice(list(synonyms))\n",
        "            # Zachowaj oryginalna interpunkcje\n",
        "            suffix = ''\n",
        "            if words[idx][-1] in '.,!?;:':\n",
        "                suffix = words[idx][-1]\n",
        "            new_words[idx] = synonym + suffix\n",
        "            replaced += 1\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "\n",
        "def generate_all_paraphrases(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Generuje parafrazy obiema metodami (Mistral + Synonimy) dla N_SAMPLES_STABILITY\n",
        "    toksycznych przykladow. Zarzadza pamiecia GPU - laduje i zwalnia Mistrala.\n",
        "\n",
        "    Argumenty:\n",
        "        model: Model DistilBERT (potrzebny do walidacji jakosci parafraz)\n",
        "        tokenizer: Tokenizer DistilBERT\n",
        "        dataset: Zbior ewaluacyjny\n",
        "\n",
        "    Zwraca:\n",
        "        Lista slownikow z parami (oryginal, parafraza_mistral, parafraza_synonym)\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 2] Generowanie parafraz...\")\n",
        "\n",
        "    # Pobieranie NLTK data (jednorazowo)\n",
        "    nltk.download('wordnet', quiet=True)\n",
        "    nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "    # Filtrowanie toksycznych przykladow\n",
        "    toxic_indices = [i for i, labels in enumerate(dataset[\"labels\"]) if labels[0] == 1]\n",
        "    sample_indices = toxic_indices[:N_SAMPLES_STABILITY]\n",
        "    print(f\"    Wybrano {len(sample_indices)} toksycznych probek.\")\n",
        "\n",
        "    # Dekodowanie tekstow z tokenow\n",
        "    original_texts = [\n",
        "        tokenizer.decode(dataset[idx][\"input_ids\"], skip_special_tokens=True)\n",
        "        for idx in sample_indices\n",
        "    ]\n",
        "\n",
        "    # --- FAZA 1: Generowanie parafraz Mistralem ---\n",
        "    print(\"\\n    [Faza 1/3] Ladowanie Mistral-7B do generowania parafraz...\")\n",
        "\n",
        "    # Tymczasowo przenosimy DistilBERT na CPU, zeby zwolnic VRAM\n",
        "    model.cpu()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "    mistral_tokenizer = AutoTokenizer.from_pretrained(MISTRAL_MODEL_ID)\n",
        "    mistral_tokenizer.pad_token = mistral_tokenizer.eos_token\n",
        "    mistral_tokenizer.padding_side = \"left\"\n",
        "\n",
        "    mistral_model = AutoModelForCausalLM.from_pretrained(\n",
        "        MISTRAL_MODEL_ID,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    print(\"    Mistral zaladowany.\")\n",
        "\n",
        "    mistral_paraphrases = []\n",
        "    for text in tqdm(original_texts, desc=\"Generowanie parafraz (Mistral)\"):\n",
        "        try:\n",
        "            para = generate_paraphrase_mistral(text, mistral_model, mistral_tokenizer, device)\n",
        "            mistral_paraphrases.append(para)\n",
        "        except Exception as e:\n",
        "            print(f\"    Blad Mistral: {e}\")\n",
        "            mistral_paraphrases.append(None)\n",
        "\n",
        "    # Czyszczenie pamieci po Mistralu\n",
        "    print(\"\\n    [Faza 2/3] Czyszczenie pamieci GPU po Mistralu...\")\n",
        "    del mistral_model\n",
        "    del mistral_tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Przywracamy DistilBERT na GPU\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"    Pamiec GPU zwolniona. DistilBERT przywrocony na GPU.\")\n",
        "\n",
        "    # --- FAZA 2: Generowanie parafraz synonimami ---\n",
        "    print(\"\\n    [Faza 3/3] Generowanie parafraz synonimami (WordNet)...\")\n",
        "    synonym_paraphrases = []\n",
        "    for text in tqdm(original_texts, desc=\"Generowanie parafraz (Synonimy)\"):\n",
        "        try:\n",
        "            para = generate_synonym_paraphrase(text)\n",
        "            synonym_paraphrases.append(para)\n",
        "        except Exception as e:\n",
        "            print(f\"    Blad Synonimy: {e}\")\n",
        "            synonym_paraphrases.append(None)\n",
        "\n",
        "    # --- FAZA 3: Walidacja jakosci i zapis ---\n",
        "    print(\"\\n    Walidacja jakosci parafraz...\")\n",
        "    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    paraphrase_data = []\n",
        "    for i, orig_text in enumerate(original_texts):\n",
        "        entry = {\n",
        "            \"idx\": i,\n",
        "            \"original\": orig_text,\n",
        "            \"mistral_para\": mistral_paraphrases[i],\n",
        "            \"synonym_para\": synonym_paraphrases[i],\n",
        "            \"mistral_valid\": False,\n",
        "            \"synonym_valid\": False,\n",
        "        }\n",
        "\n",
        "        # Walidacja parafrazy Mistral\n",
        "        if mistral_paraphrases[i] is not None and len(mistral_paraphrases[i].strip()) > 5:\n",
        "            embs = semantic_model.encode(\n",
        "                [orig_text, mistral_paraphrases[i]], convert_to_tensor=True\n",
        "            )\n",
        "            cos_sim = F.cosine_similarity(embs[0].unsqueeze(0), embs[1].unsqueeze(0)).item()\n",
        "            entry[\"mistral_cos_sim\"] = cos_sim\n",
        "            entry[\"mistral_valid\"] = cos_sim >= PARAPHRASE_MIN_SIMILARITY\n",
        "\n",
        "        # Walidacja parafrazy synonimowej\n",
        "        if synonym_paraphrases[i] is not None and len(synonym_paraphrases[i].strip()) > 5:\n",
        "            embs = semantic_model.encode(\n",
        "                [orig_text, synonym_paraphrases[i]], convert_to_tensor=True\n",
        "            )\n",
        "            cos_sim = F.cosine_similarity(embs[0].unsqueeze(0), embs[1].unsqueeze(0)).item()\n",
        "            entry[\"synonym_cos_sim\"] = cos_sim\n",
        "            entry[\"synonym_valid\"] = cos_sim >= PARAPHRASE_MIN_SIMILARITY\n",
        "\n",
        "        paraphrase_data.append(entry)\n",
        "\n",
        "    # Zapis checkpoint\n",
        "    df_paraphrases = pd.DataFrame(paraphrase_data)\n",
        "    df_paraphrases.to_csv(f\"{RESULTS_DIR}/paraphrase_data.csv\", index=False)\n",
        "\n",
        "    n_mistral_valid = sum(1 for d in paraphrase_data if d[\"mistral_valid\"])\n",
        "    n_synonym_valid = sum(1 for d in paraphrase_data if d[\"synonym_valid\"])\n",
        "    print(f\"\\n    Mistral: {n_mistral_valid}/{len(paraphrase_data)} parafraz przeszlo walidacje\")\n",
        "    print(f\"    Synonimy: {n_synonym_valid}/{len(paraphrase_data)} parafraz przeszlo walidacje\")\n",
        "    print(\"    Dane parafraz zapisane do CSV.\")\n",
        "\n",
        "    del semantic_model\n",
        "    gc.collect()\n",
        "\n",
        "    return paraphrase_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_paraphrase_gen"
      },
      "outputs": [],
      "source": [
        "paraphrase_data = generate_all_paraphrases(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_attribution_funcs"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.2 FUNKCJE ATRYBUCJI (STANDARD IG + SMOOTHGRAD)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def get_word_attributions(text, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Oblicza atrybucje na poziomie slow za pomoca Standard Integrated Gradients.\n",
        "\n",
        "    Agreguje atrybucje sub-tokenow do calych slow uzywajac mapowania word_ids().\n",
        "    Zwraca PELNY slownik atrybucji (nie tylko top-K), co umozliwia korelacje Spearmana.\n",
        "\n",
        "    Argumenty:\n",
        "        text: Tekst wejsciowy\n",
        "        model: Model DistilBERT\n",
        "        tokenizer: Tokenizer DistilBERT\n",
        "\n",
        "    Zwraca:\n",
        "        dict: Slownik {slowo: wartosc_atrybucji} z wartosciami bezwzglednymi\n",
        "    \"\"\"\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text, return_tensors=\"pt\", truncation=True,\n",
        "        padding=\"max_length\", max_length=MAX_SEQUENCE_LENGTH,\n",
        "    ).to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    emb = model.distilbert.embeddings(input_ids)\n",
        "    baseline = model.distilbert.embeddings(\n",
        "        torch.tensor(\n",
        "            [tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device\n",
        "        ).unsqueeze(0)\n",
        "    )\n",
        "\n",
        "    attr, _ = ig.attribute(\n",
        "        emb, baselines=baseline, target=0,\n",
        "        n_steps=XAI_N_STEPS,\n",
        "        additional_forward_args=(attention_mask,),\n",
        "        return_convergence_delta=True,\n",
        "    )\n",
        "    # Suma po wymiarze embeddingow + wartosc bezwzgledna -> waznosc tokenu\n",
        "    attr_sum = attr.sum(dim=-1).squeeze(0).abs()\n",
        "\n",
        "    # Agregacja sub-tokenow do slow\n",
        "    encoding = tokenizer(text, truncation=True, max_length=MAX_SEQUENCE_LENGTH)\n",
        "    word_ids = encoding.word_ids()\n",
        "\n",
        "    word_attributions = {}\n",
        "    for i, word_idx in enumerate(word_ids):\n",
        "        if word_idx is not None:\n",
        "            start, end = encoding.token_to_chars(i)\n",
        "            word = text[start:end].lower().strip()\n",
        "            if word:  # Pomijaj puste stringi\n",
        "                word_attributions[word] = word_attributions.get(word, 0) + attr_sum[i].item()\n",
        "\n",
        "    return word_attributions\n",
        "\n",
        "\n",
        "def get_word_attributions_smoothgrad(text, model, tokenizer,\n",
        "                                     n_samples=SMOOTHGRAD_N_SAMPLES,\n",
        "                                     noise_std=SMOOTHGRAD_NOISE_STD):\n",
        "    \"\"\"\n",
        "    Oblicza atrybucje na poziomie slow za pomoca SmoothGrad.\n",
        "\n",
        "    SmoothGrad dodaje szum gaussowski do embedddingow wejsciowych i usrednia\n",
        "    atrybucje z wielu prob. Redukuje to szum w gradientach i daje bardziej\n",
        "    stabilne wyjasnenia.\n",
        "\n",
        "    Algorytm:\n",
        "        1. Dla n_samples iteracji:\n",
        "            a) Dodaj szum N(0, noise_std) do embedddingow\n",
        "            b) Oblicz atrybucje IG na zaszumionych embeddingach\n",
        "        2. Usrednij atrybucje ze wszystkich prob\n",
        "        3. Agreguj sub-tokeny do slow\n",
        "\n",
        "    Argumenty:\n",
        "        text: Tekst wejsciowy\n",
        "        model: Model DistilBERT\n",
        "        tokenizer: Tokenizer DistilBERT\n",
        "        n_samples: Liczba prob szumu (domyslnie SMOOTHGRAD_N_SAMPLES=30)\n",
        "        noise_std: Odchylenie standardowe szumu (domyslnie SMOOTHGRAD_NOISE_STD=0.1)\n",
        "\n",
        "    Zwraca:\n",
        "        dict: Slownik {slowo: usredniona_wartosc_atrybucji}\n",
        "    \"\"\"\n",
        "    def predict_func(inputs_embeds, attention_mask=None):\n",
        "        return model(inputs_embeds=inputs_embeds, attention_mask=attention_mask).logits\n",
        "\n",
        "    ig = IntegratedGradients(predict_func)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        text, return_tensors=\"pt\", truncation=True,\n",
        "        padding=\"max_length\", max_length=MAX_SEQUENCE_LENGTH,\n",
        "    ).to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    emb = model.distilbert.embeddings(input_ids)\n",
        "    baseline = model.distilbert.embeddings(\n",
        "        torch.tensor(\n",
        "            [tokenizer.pad_token_id] * MAX_SEQUENCE_LENGTH, device=device\n",
        "        ).unsqueeze(0)\n",
        "    )\n",
        "\n",
        "    # Akumulacja atrybucji z wielu zaszumionych prob\n",
        "    accumulated_attr = torch.zeros_like(emb.squeeze(0)[:, 0])  # [seq_len]\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        # Dodaj szum gaussowski do embedddingow\n",
        "        noise = torch.randn_like(emb) * noise_std\n",
        "        noisy_emb = emb + noise\n",
        "\n",
        "        attr, _ = ig.attribute(\n",
        "            noisy_emb, baselines=baseline, target=0,\n",
        "            n_steps=XAI_N_STEPS,\n",
        "            additional_forward_args=(attention_mask,),\n",
        "            return_convergence_delta=True,\n",
        "        )\n",
        "        # Suma po wymiarze embedddingow -> waznosc tokenu\n",
        "        attr_sum = attr.sum(dim=-1).squeeze(0).abs()\n",
        "        accumulated_attr += attr_sum\n",
        "\n",
        "    # Usrednienie\n",
        "    averaged_attr = accumulated_attr / n_samples\n",
        "\n",
        "    # Agregacja sub-tokenow do slow\n",
        "    encoding = tokenizer(text, truncation=True, max_length=MAX_SEQUENCE_LENGTH)\n",
        "    word_ids = encoding.word_ids()\n",
        "\n",
        "    word_attributions = {}\n",
        "    for i, word_idx in enumerate(word_ids):\n",
        "        if word_idx is not None:\n",
        "            start, end = encoding.token_to_chars(i)\n",
        "            word = text[start:end].lower().strip()\n",
        "            if word:\n",
        "                word_attributions[word] = word_attributions.get(word, 0) + averaged_attr[i].item()\n",
        "\n",
        "    return word_attributions\n",
        "\n",
        "\n",
        "def calculate_spearman_on_shared_vocab(attrs_orig, attrs_para):\n",
        "    \"\"\"\n",
        "    Oblicza korelacje Spearmana miedzy atrybucjami oryginalnego tekstu i parafrazy\n",
        "    na wspolnym slowniku (unii slow z obu tekstow).\n",
        "\n",
        "    Slowa nieobecne w jednym z tekstow otrzymuja atrybucje 0.\n",
        "\n",
        "    Argumenty:\n",
        "        attrs_orig: dict {slowo: atrybucja} dla tekstu oryginalnego\n",
        "        attrs_para: dict {slowo: atrybucja} dla parafrazy\n",
        "\n",
        "    Zwraca:\n",
        "        float: Wspolczynnik korelacji Spearmana (lub 0.0 jesli zbyt malo danych)\n",
        "    \"\"\"\n",
        "    # Unia slow z obu tekstow\n",
        "    all_words = set(attrs_orig.keys()) | set(attrs_para.keys())\n",
        "\n",
        "    if len(all_words) < 3:  # Zbyt malo danych do korelacji\n",
        "        return 0.0\n",
        "\n",
        "    # Budowanie wektorow na wspolnym slowniku (brakujace = 0)\n",
        "    vec_orig = [attrs_orig.get(w, 0.0) for w in all_words]\n",
        "    vec_para = [attrs_para.get(w, 0.0) for w in all_words]\n",
        "\n",
        "    # Sprawdzenie czy wektory nie sa stalymi (spearmanr wymaga wariancji)\n",
        "    if len(set(vec_orig)) < 2 or len(set(vec_para)) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    corr, _ = spearmanr(vec_orig, vec_para)\n",
        "    return corr if not np.isnan(corr) else 0.0\n",
        "\n",
        "\n",
        "def calculate_semantic_overlap(words_orig, words_para, semantic_model):\n",
        "    \"\"\"\n",
        "    Mierzy semantyczne podobienstwo miedzy dwoma listami najwazniejszych slow.\n",
        "\n",
        "    Uzywa modelu SentenceTransformer do kodowania slow, nastepnie oblicza\n",
        "    srednie maksymalne cosine similarity w obu kierunkach.\n",
        "\n",
        "    Argumenty:\n",
        "        words_orig: Lista top-K slow z oryginalnego tekstu\n",
        "        words_para: Lista top-K slow z parafrazy\n",
        "        semantic_model: Zaladowany model SentenceTransformer\n",
        "\n",
        "    Zwraca:\n",
        "        float: Srednie semantyczne podobienstwo (0.0 - 1.0)\n",
        "    \"\"\"\n",
        "    if not words_orig or not words_para:\n",
        "        return 0.0\n",
        "    emb_orig = semantic_model.encode(words_orig, convert_to_tensor=True)\n",
        "    emb_para = semantic_model.encode(words_para, convert_to_tensor=True)\n",
        "    cos_sim_matrix = F.cosine_similarity(\n",
        "        emb_orig.unsqueeze(1), emb_para.unsqueeze(0), dim=2\n",
        "    )\n",
        "    score = (\n",
        "        torch.max(cos_sim_matrix, dim=1)[0].mean()\n",
        "        + torch.max(cos_sim_matrix, dim=0)[0].mean()\n",
        "    ).item() / 2\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_eval_loop"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.3 PETLA EWALUACJI STABILNOSCI\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def experiment_stability(model, tokenizer, paraphrase_data):\n",
        "    \"\"\"\n",
        "    Porownuje stabilnosc Standard IG vs SmoothGrad na parafrazach (Mistral + Synonimy).\n",
        "\n",
        "    Dla kazdej pary (oryginal, parafraza) oblicza:\n",
        "        - Atrybucje Standard IG i SmoothGrad\n",
        "        - Korelacje Spearmana na wspolnym slowniku\n",
        "        - Semantic Overlap top-K slow\n",
        "\n",
        "    Argumenty:\n",
        "        model: Model DistilBERT\n",
        "        tokenizer: Tokenizer DistilBERT\n",
        "        paraphrase_data: Lista slownikow z generate_all_paraphrases()\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z wynikami stabilnosci dla kazdej pary\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 2] Ewaluacja stabilnosci XAI (Standard IG vs SmoothGrad)...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Ladowanie modelu semantycznego do Semantic Overlap\n",
        "    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Przetwarzanie par: Mistral i Synonimy\n",
        "    para_types = [\n",
        "        (\"mistral\", \"mistral_para\", \"mistral_valid\"),\n",
        "        (\"synonym\", \"synonym_para\", \"synonym_valid\"),\n",
        "    ]\n",
        "\n",
        "    for para_type_name, para_key, valid_key in para_types:\n",
        "        print(f\"\\n    Przetwarzanie parafraz typu: {para_type_name}\")\n",
        "\n",
        "        valid_pairs = [d for d in paraphrase_data if d.get(valid_key, False)]\n",
        "        print(f\"    Liczba poprawnych par: {len(valid_pairs)}\")\n",
        "\n",
        "        for entry in tqdm(valid_pairs, desc=f\"Stabilnosc ({para_type_name})\"):\n",
        "            orig_text = entry[\"original\"]\n",
        "            para_text = entry[para_key]\n",
        "\n",
        "            try:\n",
        "                # --- Standard IG ---\n",
        "                attrs_orig_std = get_word_attributions(orig_text, model, tokenizer)\n",
        "                attrs_para_std = get_word_attributions(para_text, model, tokenizer)\n",
        "\n",
        "                # --- SmoothGrad ---\n",
        "                attrs_orig_smooth = get_word_attributions_smoothgrad(\n",
        "                    orig_text, model, tokenizer\n",
        "                )\n",
        "                attrs_para_smooth = get_word_attributions_smoothgrad(\n",
        "                    para_text, model, tokenizer\n",
        "                )\n",
        "\n",
        "                # --- Korelacja Spearmana (wspolny slownik) ---\n",
        "                spearman_std = calculate_spearman_on_shared_vocab(\n",
        "                    attrs_orig_std, attrs_para_std\n",
        "                )\n",
        "                spearman_smooth = calculate_spearman_on_shared_vocab(\n",
        "                    attrs_orig_smooth, attrs_para_smooth\n",
        "                )\n",
        "\n",
        "                # --- Semantic Overlap (top-K slow) ---\n",
        "                top_k_orig_std = sorted(\n",
        "                    attrs_orig_std.items(), key=lambda x: x[1], reverse=True\n",
        "                )[:TOP_K_TOKENS]\n",
        "                top_k_para_std = sorted(\n",
        "                    attrs_para_std.items(), key=lambda x: x[1], reverse=True\n",
        "                )[:TOP_K_TOKENS]\n",
        "                top_k_orig_smooth = sorted(\n",
        "                    attrs_orig_smooth.items(), key=lambda x: x[1], reverse=True\n",
        "                )[:TOP_K_TOKENS]\n",
        "                top_k_para_smooth = sorted(\n",
        "                    attrs_para_smooth.items(), key=lambda x: x[1], reverse=True\n",
        "                )[:TOP_K_TOKENS]\n",
        "\n",
        "                sem_overlap_std = calculate_semantic_overlap(\n",
        "                    [w for w, _ in top_k_orig_std],\n",
        "                    [w for w, _ in top_k_para_std],\n",
        "                    semantic_model,\n",
        "                )\n",
        "                sem_overlap_smooth = calculate_semantic_overlap(\n",
        "                    [w for w, _ in top_k_orig_smooth],\n",
        "                    [w for w, _ in top_k_para_smooth],\n",
        "                    semantic_model,\n",
        "                )\n",
        "\n",
        "                results.append({\n",
        "                    \"para_type\": para_type_name,\n",
        "                    \"idx\": entry[\"idx\"],\n",
        "                    \"spearman_standard_ig\": spearman_std,\n",
        "                    \"spearman_smoothgrad\": spearman_smooth,\n",
        "                    \"sem_overlap_standard_ig\": sem_overlap_std,\n",
        "                    \"sem_overlap_smoothgrad\": sem_overlap_smooth,\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Blad dla idx={entry['idx']}: {e}\")\n",
        "                continue\n",
        "\n",
        "    # Zapis wynikow\n",
        "    df_stability = pd.DataFrame(results)\n",
        "    df_stability.to_csv(f\"{RESULTS_DIR}/stability_results.csv\", index=False)\n",
        "\n",
        "    del semantic_model\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"\\n    Ewaluacja zakonczona. Przetworzono {len(df_stability)} par.\")\n",
        "    return df_stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_stability_eval"
      },
      "outputs": [],
      "source": [
        "df_stability = experiment_stability(model, tokenizer, paraphrase_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability_visualization"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 2.4 WIZUALIZACJA I PODSUMOWANIE STABILNOSCI\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def visualize_stability(df_stability):\n",
        "    \"\"\"\n",
        "    Wizualizuje wyniki analizy stabilnosci: porownanie Standard IG vs SmoothGrad\n",
        "    dla obu typow parafraz (Mistral i Synonimy).\n",
        "\n",
        "    Tworzy 4 subploty (2x2):\n",
        "        - Wiersz 1: Korelacja Spearmana (Mistral | Synonimy)\n",
        "        - Wiersz 2: Semantic Overlap (Mistral | Synonimy)\n",
        "\n",
        "    Argumenty:\n",
        "        df_stability: DataFrame z wynikami experiment_stability()\n",
        "\n",
        "    Zwraca:\n",
        "        None (wyswietla wykresy i drukuje podsumowanie)\n",
        "    \"\"\"\n",
        "    if df_stability.empty:\n",
        "        print(\"Brak danych do wizualizacji.\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle(\n",
        "        \"Analiza Stabilnosci: Standard IG vs SmoothGrad\",\n",
        "        fontsize=16, fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "    para_types = [\"mistral\", \"synonym\"]\n",
        "    para_labels = [\"Parafrazy Mistral\", \"Parafrazy Synonimowe\"]\n",
        "\n",
        "    for col_idx, (ptype, plabel) in enumerate(zip(para_types, para_labels)):\n",
        "        df_sub = df_stability[df_stability[\"para_type\"] == ptype]\n",
        "\n",
        "        if df_sub.empty:\n",
        "            axes[0, col_idx].text(0.5, 0.5, f\"Brak danych: {plabel}\",\n",
        "                                   ha='center', va='center', fontsize=12)\n",
        "            axes[1, col_idx].text(0.5, 0.5, f\"Brak danych: {plabel}\",\n",
        "                                   ha='center', va='center', fontsize=12)\n",
        "            continue\n",
        "\n",
        "        # Wiersz 1: Korelacja Spearmana\n",
        "        spearman_data = df_sub[[\"spearman_standard_ig\", \"spearman_smoothgrad\"]]\n",
        "        sns.boxplot(data=spearman_data, ax=axes[0, col_idx], palette=\"Set2\")\n",
        "        axes[0, col_idx].set_title(f\"Korelacja Spearmana - {plabel}\")\n",
        "        axes[0, col_idx].set_ylabel(\"Spearman rho\")\n",
        "        axes[0, col_idx].set_xticklabels([\"Standard IG\", \"SmoothGrad\"])\n",
        "        axes[0, col_idx].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "        # Wiersz 2: Semantic Overlap\n",
        "        sem_data = df_sub[[\"sem_overlap_standard_ig\", \"sem_overlap_smoothgrad\"]]\n",
        "        sns.boxplot(data=sem_data, ax=axes[1, col_idx], palette=\"Set2\")\n",
        "        axes[1, col_idx].set_title(f\"Semantic Overlap (Top-{TOP_K_TOKENS}) - {plabel}\")\n",
        "        axes[1, col_idx].set_ylabel(\"Semantic Overlap\")\n",
        "        axes[1, col_idx].set_xticklabels([\"Standard IG\", \"SmoothGrad\"])\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.savefig(f\"{RESULTS_DIR}/stability_boxplot.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Tabela podsumowujaca ---\n",
        "    print(\"\\n=== PODSUMOWANIE STABILNOSCI ===\")\n",
        "    for ptype, plabel in zip(para_types, para_labels):\n",
        "        df_sub = df_stability[df_stability[\"para_type\"] == ptype]\n",
        "        if df_sub.empty:\n",
        "            print(f\"\\n{plabel}: Brak danych.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- {plabel} (n={len(df_sub)}) ---\")\n",
        "        print(f\"\\nKorelacja Spearmana:\")\n",
        "        print(f\"  Standard IG  - srednia: {df_sub['spearman_standard_ig'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['spearman_standard_ig'].median():.4f}, \"\n",
        "              f\"std: {df_sub['spearman_standard_ig'].std():.4f}\")\n",
        "        print(f\"  SmoothGrad   - srednia: {df_sub['spearman_smoothgrad'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['spearman_smoothgrad'].median():.4f}, \"\n",
        "              f\"std: {df_sub['spearman_smoothgrad'].std():.4f}\")\n",
        "\n",
        "        print(f\"\\nSemantic Overlap (Top-{TOP_K_TOKENS}):\")\n",
        "        print(f\"  Standard IG  - srednia: {df_sub['sem_overlap_standard_ig'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['sem_overlap_standard_ig'].median():.4f}, \"\n",
        "              f\"std: {df_sub['sem_overlap_standard_ig'].std():.4f}\")\n",
        "        print(f\"  SmoothGrad   - srednia: {df_sub['sem_overlap_smoothgrad'].mean():.4f}, \"\n",
        "              f\"mediana: {df_sub['sem_overlap_smoothgrad'].median():.4f}, \"\n",
        "              f\"std: {df_sub['sem_overlap_smoothgrad'].std():.4f}\")\n",
        "\n",
        "        # Poprawa SmoothGrad vs Standard IG\n",
        "        spearman_improvement = (\n",
        "            df_sub['spearman_smoothgrad'].mean() - df_sub['spearman_standard_ig'].mean()\n",
        "        )\n",
        "        sem_improvement = (\n",
        "            df_sub['sem_overlap_smoothgrad'].mean() - df_sub['sem_overlap_standard_ig'].mean()\n",
        "        )\n",
        "        print(f\"\\n  Poprawa SmoothGrad vs Standard IG:\")\n",
        "        print(f\"    Spearman:         +{spearman_improvement:.4f}\")\n",
        "        print(f\"    Semantic Overlap: +{sem_improvement:.4f}\")\n",
        "\n",
        "    print(\"\\nCzesc 2 zakonczona.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_stability_viz"
      },
      "outputs": [],
      "source": [
        "visualize_stability(df_stability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "steering_header"
      },
      "source": [
        "---\n",
        "## Czesc 3: Inzynieria Reprezentacji i Sterowanie (Utility & Steering)\n",
        "\n",
        "Cel: Wykazanie uzytecznosci praktycznej - mozemy naprawic model bez retrenowania.\n",
        "\n",
        "Podejscie:\n",
        "- **Ekstrakcja aktywacji** z warstwy TARGET_LAYER_INDEX dla zbioru toksycznego i bezpiecznego\n",
        "- **Wektor sterujacy**: Obliczenie kierunku toksycznosci metoda Difference of Means + normalizacja L2\n",
        "- **SteeringHook**: PyTorch hook modyfikujacy hidden states w czasie inferencji\n",
        "- **Test detoksykacji**: Ocena skutecznosci dla roznych wartosci alpha (sila interwencji)\n",
        "\n",
        "Metryki:\n",
        "- **Success Rate**: Procent toksycznych przykladow sklasyfikowanych jako bezpieczne po steeringu (cel: >80%)\n",
        "- **Side Effect Rate**: Procent bezpiecznych przykladow blednie sklasyfikowanych jako toksyczne (cel: <5%)\n",
        "- **Avg Delta**: Srednia zmiana prawdopodobienstwa toksycznosci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "steering_functions"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3. INZYNIERIA REPREZENTACJI I STEROWANIE (STEERING)\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "class SteeringHook:\n",
        "    \"\"\"\n",
        "    PyTorch hook modyfikujacy hidden states poprzez dodanie wektora sterujacego.\n",
        "\n",
        "    Podczas forward pass, hook dodaje przeskalowany wektor kierunkowy do aktywacji\n",
        "    wybranej warstwy transformera. Ujemny wspolczynnik (coeff) przesuwa aktywacje\n",
        "    w kierunku przeciwnym do toksycznosci (detoksykacja).\n",
        "\n",
        "    Argumenty:\n",
        "        vector: Tensor wektora sterujacego (768-dim, znormalizowany L2)\n",
        "        coeff: Wspolczynnik skalowania (alpha). Ujemny = detoksykacja.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vector, coeff):\n",
        "        self.vector = vector\n",
        "        self.coeff = coeff\n",
        "\n",
        "    def __call__(self, module, inputs, output):\n",
        "        is_tuple = isinstance(output, tuple)\n",
        "        hidden_states = output[0] if is_tuple else output\n",
        "        steering_vector = self.vector.to(hidden_states.device, dtype=hidden_states.dtype)\n",
        "        modified_hidden = hidden_states + (self.coeff * steering_vector)\n",
        "\n",
        "        if is_tuple:\n",
        "            return (modified_hidden,) + output[1:]\n",
        "        else:\n",
        "            return modified_hidden\n",
        "\n",
        "def experiment_steering(model, tokenizer, dataset):\n",
        "    \"\"\"\n",
        "    Oblicza wektor sterujacy i testuje skutecznosc detoksykacji dla roznych wartosci alpha.\n",
        "\n",
        "    Algorytm:\n",
        "        1. Podzial danych: 800 probek do wyznaczenia wektora, reszta do testow (brak wycieku)\n",
        "        2. Ekstrakcja aktywacji tokenu [CLS] z warstwy TARGET_LAYER_INDEX\n",
        "        3. Obliczenie wektora sterujacego: mean(toxic) - mean(safe), normalizacja L2\n",
        "        4. Dla kazdego alpha z ALPHA_VALUES:\n",
        "            a) Inteligentny wybor probek (ranking pewnosci modelu)\n",
        "            b) Pomiar prawdopodobienstwa PRZED i PO steeringu\n",
        "            c) Obliczenie Success Rate i Side Effect Rate\n",
        "\n",
        "    Argumenty:\n",
        "        model: Wytrenowany model DistilBERT\n",
        "        tokenizer: Tokenizer odpowiadajacy modelowi\n",
        "        dataset: Zbior ewaluacyjny z etykietami\n",
        "\n",
        "    Zwraca:\n",
        "        Tuple (df_summary, df_details):\n",
        "        - df_summary: DataFrame z podsumowaniem per alpha (success_rate, side_effect_rate, avg_delta)\n",
        "        - df_details: DataFrame ze szczegolowymi wynikami per probka\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 3] Uruchamianie analizy steeringu...\")\n",
        "    model.eval()\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.1 PODZIAL DANYCH (wektor vs test)\n",
        "    # -----------------------------------------------\n",
        "    # Zamiast sztywnego 800, bierzemy 60% dostpnych danych na wektor\n",
        "    total_len = len(dataset)\n",
        "    N_FOR_VECTOR = int(total_len * 0.6)\n",
        "\n",
        "    # Zabezpieczenie: upewnijmy si, e zostaje min. 50 prbek na testy\n",
        "    if total_len - N_FOR_VECTOR < 50:\n",
        "        print(f\"UWAGA: Bardzo may zbir danych ({total_len}). Wyniki mog by niestabilne.\")\n",
        "\n",
        "    vector_subset = dataset.select(range(N_FOR_VECTOR))\n",
        "    test_subset = dataset.select(range(N_FOR_VECTOR, total_len))\n",
        "\n",
        "    print(f\"    Cakowity rozmiar zbioru eval: {total_len}\")\n",
        "    print(f\"    Prbek do wyznaczenia wektora: {len(vector_subset)}\")\n",
        "    print(f\"    Prbek do testowania efektw:  {len(test_subset)}\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.2 EKSTRAKCJA AKTYWACJI\n",
        "    # -----------------------------------------------\n",
        "    print(f\"    Ekstrakcja aktywacji z warstwy {TARGET_LAYER_INDEX}...\")\n",
        "    layers_data = {TARGET_LAYER_INDEX: []}\n",
        "    all_labels = []\n",
        "\n",
        "    loader = torch.utils.data.DataLoader(vector_subset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Ekstrakcja aktywacji\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"][:, 0].cpu().numpy()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids, attention_mask=mask, output_hidden_states=True)\n",
        "\n",
        "        all_labels.extend(labels)\n",
        "        # Token [CLS] (indeks 0) z wybranej warstwy\n",
        "        layers_data[TARGET_LAYER_INDEX].append(\n",
        "            out.hidden_states[TARGET_LAYER_INDEX][:, 0, :].cpu().numpy()\n",
        "        )\n",
        "\n",
        "    if len(layers_data[TARGET_LAYER_INDEX]) == 0:\n",
        "        raise ValueError(\"Brak danych do ekstrakcji aktywacji. Sprawd loader.\")\n",
        "\n",
        "    X = np.concatenate(layers_data[TARGET_LAYER_INDEX], axis=0)\n",
        "    y = np.array(all_labels)\n",
        "    y_bin = (y > CLASSIFICATION_THRESHOLD).astype(int)\n",
        "\n",
        "    print(f\"    Statystyki probek - Toksyczne: {np.sum(y_bin == 1)}, Bezpieczne: {np.sum(y_bin == 0)}\")\n",
        "    print(f\"    Ksztalt aktywacji: {X.shape}\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.3 OBLICZENIE WEKTORA STERUJACEGO\n",
        "    # -----------------------------------------------\n",
        "    # Zabezpieczenie przed brakiem klasy\n",
        "    if np.sum(y_bin == 1) == 0 or np.sum(y_bin == 0) == 0:\n",
        "        raise ValueError(\"W podzbiorze wektorowym brakuje jednej z klas (same toksyczne lub same bezpieczne). Zwiksz N_FOR_VECTOR lub DF_SIZE.\")\n",
        "\n",
        "    print(\"    Obliczanie wektora sterujacego (Difference of Means)...\")\n",
        "    mean_toxic = np.mean(X[y_bin == 1], axis=0)\n",
        "    mean_safe = np.mean(X[y_bin == 0], axis=0)\n",
        "    direction = mean_toxic - mean_safe\n",
        "\n",
        "    print(f\"    Wektor przed normalizacja - L2 Norm: {np.linalg.norm(direction):.6f}\")\n",
        "\n",
        "    # Normalizacja L2\n",
        "    direction_normed = direction / np.linalg.norm(direction)\n",
        "    steering_tensor = torch.tensor(direction_normed, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Zapis wektora\n",
        "    np.save(f\"{RESULTS_DIR}/steering_vector.npy\", direction_normed)\n",
        "    print(f\"    Wektor znormalizowany (L2 Norm: {np.linalg.norm(direction_normed):.2f}). Zapisano do: {RESULTS_DIR}/steering_vector.npy\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.4 FUNKCJA TESTOWANIA STEERINGU\n",
        "    # -----------------------------------------------\n",
        "\n",
        "    def test_steering_for_alpha(alpha_value):\n",
        "        \"\"\"\n",
        "        Testuje skutecznosc steeringu dla danej wartosci alpha.\n",
        "        \"\"\"\n",
        "        print(f\"\\n    --- Testowanie alpha = {alpha_value} ---\")\n",
        "\n",
        "        # Inteligentny wybor probek (ranking pewnosci)\n",
        "        all_scores = []\n",
        "        # Ograniczamy zakres przeszukiwania do dostpnej liczby prbek testowych\n",
        "        search_range = min(300, len(test_subset))\n",
        "\n",
        "        if search_range == 0:\n",
        "             raise ValueError(\"Brak danych testowych (test_subset jest pusty).\")\n",
        "\n",
        "        for i in range(search_range):\n",
        "            input_ids = test_subset[i][\"input_ids\"].unsqueeze(0).to(device)\n",
        "            mask = test_subset[i][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "            label = test_subset[i][\"labels\"][0].item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_ids, attention_mask=mask).logits\n",
        "                prob = torch.sigmoid(logits)[0, 0].item()\n",
        "\n",
        "            all_scores.append({\"idx\": i, \"prob\": prob, \"label\": label})\n",
        "\n",
        "        # Toksyczne: najwyzsze P(toxic) | Bezpieczne: najnizsze P(toxic)\n",
        "        toxic_candidates = [x for x in all_scores if x[\"label\"] == 1]\n",
        "\n",
        "        # Zabezpieczenie jeli jest mniej kandydatw ni N_SAMPLES_PER_CLASS\n",
        "        n_samples_actual = min(N_SAMPLES_PER_CLASS, len(toxic_candidates))\n",
        "\n",
        "        toxic_indices = [\n",
        "            x[\"idx\"]\n",
        "            for x in sorted(toxic_candidates, key=lambda x: x[\"prob\"], reverse=True)[\n",
        "                :n_samples_actual\n",
        "            ]\n",
        "        ]\n",
        "\n",
        "        safe_candidates = [x for x in all_scores if x[\"label\"] == 0]\n",
        "        n_samples_safe_actual = min(N_SAMPLES_PER_CLASS, len(safe_candidates))\n",
        "\n",
        "        safe_indices = [\n",
        "            x[\"idx\"]\n",
        "            for x in sorted(safe_candidates, key=lambda x: x[\"prob\"])[:n_samples_safe_actual]\n",
        "        ]\n",
        "\n",
        "        print(f\"    Wybrano: {len(toxic_indices)} toksycznych, {len(safe_indices)} bezpiecznych\")\n",
        "\n",
        "        layer_module = model.distilbert.transformer.layer[TARGET_LAYER_INDEX]\n",
        "        results = []\n",
        "        toxic_deltas, safe_deltas = [], []\n",
        "        success_count, side_effect_count = 0, 0\n",
        "\n",
        "        def run_inference(indices, label_type):\n",
        "            nonlocal success_count, side_effect_count\n",
        "            if not indices:\n",
        "                return\n",
        "\n",
        "            for idx in indices:\n",
        "                input_ids = test_subset[idx][\"input_ids\"].unsqueeze(0).to(device)\n",
        "                mask = test_subset[idx][\"attention_mask\"].unsqueeze(0).to(device)\n",
        "\n",
        "                # Pomiar PRZED steeringiem\n",
        "                with torch.no_grad():\n",
        "                    prob_before = torch.sigmoid(\n",
        "                        model(input_ids, mask).logits\n",
        "                    )[0, 0].item()\n",
        "\n",
        "                # Pomiar PO steeringu (z hookiem)\n",
        "                hook = SteeringHook(steering_tensor, alpha_value)\n",
        "                handle = layer_module.register_forward_hook(hook)\n",
        "                with torch.no_grad():\n",
        "                    prob_after = torch.sigmoid(\n",
        "                        model(input_ids, mask).logits\n",
        "                    )[0, 0].item()\n",
        "                handle.remove()\n",
        "\n",
        "                delta = prob_after - prob_before\n",
        "\n",
        "                if label_type == \"TOXIC\":\n",
        "                    success = prob_after < CLASSIFICATION_THRESHOLD\n",
        "                    status = \"SUCCESS\" if success else \"FAILED\"\n",
        "                    if success:\n",
        "                        success_count += 1\n",
        "                    toxic_deltas.append(delta)\n",
        "                else:\n",
        "                    side_effect = prob_after > CLASSIFICATION_THRESHOLD\n",
        "                    status = \"SIDE-EFFECT\" if side_effect else \"OK\"\n",
        "                    if side_effect:\n",
        "                        side_effect_count += 1\n",
        "                    safe_deltas.append(delta)\n",
        "\n",
        "                text = tokenizer.decode(\n",
        "                    test_subset[idx][\"input_ids\"], skip_special_tokens=True\n",
        "                )\n",
        "                results.append({\n",
        "                    \"label\": label_type,\n",
        "                    \"alpha\": alpha_value,\n",
        "                    \"prob_before\": prob_before,\n",
        "                    \"prob_after\": prob_after,\n",
        "                    \"delta\": delta,\n",
        "                    \"status\": status,\n",
        "                    \"text\": text[:100],\n",
        "                })\n",
        "\n",
        "        run_inference(toxic_indices, \"TOXIC\")\n",
        "        run_inference(safe_indices, \"SAFE\")\n",
        "\n",
        "        # Obliczanie rednich (zabezpieczenie przed dzieleniem przez zero)\n",
        "        success_rate = (success_count / len(toxic_indices) * 100) if toxic_indices else 0\n",
        "        side_rate = (side_effect_count / len(safe_indices) * 100) if safe_indices else 0\n",
        "        avg_d_tox = np.mean(toxic_deltas) if toxic_deltas else 0\n",
        "        avg_d_safe = np.mean(safe_deltas) if safe_deltas else 0\n",
        "\n",
        "        print(f\"    Success Rate: {success_rate:.1f}% | Side Effects: {side_rate:.1f}% | \"\n",
        "              f\"Avg Delta Toxic: {avg_d_tox:+.4f} | Avg Delta Safe: {avg_d_safe:+.4f}\")\n",
        "\n",
        "        return results, success_rate, side_rate, avg_d_tox, avg_d_safe\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 3.5 GLOWNA PETLA - TESTOWANIE DLA ROZNYCH ALPHA\n",
        "    # -----------------------------------------------\n",
        "    print(f\"\\n    Testowanie steeringu dla alpha: {ALPHA_VALUES}\")\n",
        "\n",
        "    all_details = []\n",
        "    summary_data = []\n",
        "\n",
        "    for alpha in ALPHA_VALUES:\n",
        "        results, success_rate, side_effect_rate, avg_delta_toxic, avg_delta_safe = (\n",
        "            test_steering_for_alpha(alpha)\n",
        "        )\n",
        "        all_details.extend(results)\n",
        "        summary_data.append({\n",
        "            \"alpha\": alpha,\n",
        "            \"success_rate\": success_rate,\n",
        "            \"side_effect_rate\": side_effect_rate,\n",
        "            \"avg_delta_toxic\": avg_delta_toxic,\n",
        "            \"avg_delta_safe\": avg_delta_safe,\n",
        "        })\n",
        "\n",
        "    # Zapis wynikow\n",
        "    df_summary = pd.DataFrame(summary_data)\n",
        "    df_details = pd.DataFrame(all_details)\n",
        "    df_summary.to_csv(f\"{RESULTS_DIR}/steering_summary.csv\", index=False)\n",
        "    df_details.to_csv(f\"{RESULTS_DIR}/steering_details.csv\", index=False)\n",
        "\n",
        "    print(f\"\\n    Wyniki zapisane do: {RESULTS_DIR}/steering_summary.csv\")\n",
        "    print(f\"    Szczegoly zapisane do: {RESULTS_DIR}/steering_details.csv\")\n",
        "\n",
        "    return df_summary, df_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_steering"
      },
      "outputs": [],
      "source": [
        "df_steering, df_steering_details = experiment_steering(model, tokenizer, eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "steering_visualization"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 3.6 WIZUALIZACJA I PODSUMOWANIE STEERINGU\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def visualize_steering(df_summary, df_details):\n",
        "    \"\"\"\n",
        "    Wizualizuje wyniki steeringu: tabela podsumowujaca, analiza optymalnosci\n",
        "    i szczegolowe przyklady przed/po.\n",
        "\n",
        "    Tworzy:\n",
        "        - Wykres slupkowy: Success Rate vs Side Effect Rate per alpha\n",
        "        - Tabele podsumowujaca z ocena optymalnosci\n",
        "        - Przyklady detoksykacji (toksyczne z najwieksza zmiana)\n",
        "        - Przyklady efektow ubocznych (bezpieczne blednie sklasyfikowane)\n",
        "        - Porownanie jednego tekstu dla roznych alpha\n",
        "\n",
        "    Argumenty:\n",
        "        df_summary: DataFrame z podsumowaniem per alpha\n",
        "        df_details: DataFrame ze szczegolowymi wynikami per probka\n",
        "\n",
        "    Zwraca:\n",
        "        None (wyswietla wykresy, tabele i przyklady)\n",
        "    \"\"\"\n",
        "    if df_summary.empty:\n",
        "        print(\"Brak danych do wizualizacji.\")\n",
        "        return\n",
        "\n",
        "    # --- Wykres slupkowy ---\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    fig.suptitle(\n",
        "        \"Skutecznosc Sterowania (Steering) dla Roznych Wartosci Alpha\",\n",
        "        fontsize=14, fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "    x = np.arange(len(df_summary))\n",
        "    alpha_labels = [f\"alpha={a}\" for a in df_summary[\"alpha\"]]\n",
        "\n",
        "    # Subplot 1: Success Rate i Side Effect Rate\n",
        "    width = 0.35\n",
        "    bars1 = axes[0].bar(x - width / 2, df_summary[\"success_rate\"], width, label=\"Success Rate\", color=\"#2ecc71\")\n",
        "    bars2 = axes[0].bar(x + width / 2, df_summary[\"side_effect_rate\"], width, label=\"Side Effect Rate\", color=\"#e74c3c\")\n",
        "    axes[0].set_ylabel(\"Procent (%)\")\n",
        "    axes[0].set_title(\"Success Rate vs Side Effect Rate\")\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels(alpha_labels)\n",
        "    axes[0].legend()\n",
        "    axes[0].axhline(y=80, color=\"green\", linestyle=\"--\", alpha=0.5, label=\"Cel Success (80%)\")\n",
        "    axes[0].axhline(y=5, color=\"red\", linestyle=\"--\", alpha=0.5, label=\"Limit Side Effects (5%)\")\n",
        "    axes[0].set_ylim(0, 105)\n",
        "\n",
        "    # Etykiety na slupkach\n",
        "    for bar in bars1:\n",
        "        h = bar.get_height()\n",
        "        axes[0].annotate(f\"{h:.1f}%\", xy=(bar.get_x() + bar.get_width() / 2, h),\n",
        "                         xytext=(0, 3), textcoords=\"offset points\", ha=\"center\", fontsize=9)\n",
        "    for bar in bars2:\n",
        "        h = bar.get_height()\n",
        "        axes[0].annotate(f\"{h:.1f}%\", xy=(bar.get_x() + bar.get_width() / 2, h),\n",
        "                         xytext=(0, 3), textcoords=\"offset points\", ha=\"center\", fontsize=9)\n",
        "\n",
        "    # Subplot 2: Srednia delta (zmiana prawdopodobienstwa)\n",
        "    bars3 = axes[1].bar(x - width / 2, df_summary[\"avg_delta_toxic\"], width, label=\"Avg Delta (Toxic)\", color=\"#3498db\")\n",
        "    bars4 = axes[1].bar(x + width / 2, df_summary[\"avg_delta_safe\"], width, label=\"Avg Delta (Safe)\", color=\"#f39c12\")\n",
        "    axes[1].set_ylabel(\"Srednia Zmiana Prawdopodobienstwa\")\n",
        "    axes[1].set_title(\"Srednia Delta P(toxic)\")\n",
        "    axes[1].set_xticks(x)\n",
        "    axes[1].set_xticklabels(alpha_labels)\n",
        "    axes[1].legend()\n",
        "    axes[1].axhline(y=0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.savefig(f\"{RESULTS_DIR}/steering_barplot.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- Tabela podsumowujaca z ocena ---\n",
        "    print(\"\\n=== PODSUMOWANIE STEERINGU ===\")\n",
        "    print(df_summary.to_string(index=False))\n",
        "\n",
        "    print(\"\\n=== ANALIZA OPTYMALNOSCI ===\")\n",
        "    for _, row in df_summary.iterrows():\n",
        "        alpha = row[\"alpha\"]\n",
        "        if row[\"success_rate\"] > 80 and row[\"side_effect_rate\"] < 5:\n",
        "            status = \"OPTYMALNE\"\n",
        "        elif row[\"success_rate\"] > 80:\n",
        "            status = \"DOBRA SKUTECZNOSC, WYSOKIE SIDE EFFECTS\"\n",
        "        elif row[\"side_effect_rate\"] < 5:\n",
        "            status = \"NISKIE SIDE EFFECTS, SLABA SKUTECZNOSC\"\n",
        "        else:\n",
        "            status = \"WYMAGA DOSTROJENIA\"\n",
        "\n",
        "        print(f\"\\n  Alpha = {alpha}: {status}\")\n",
        "        print(f\"    Success Rate:  {row['success_rate']:.2f}% (cel: >80%)\")\n",
        "        print(f\"    Side Effects:  {row['side_effect_rate']:.2f}% (cel: <5%)\")\n",
        "        print(f\"    Avg Delta Toxic: {row['avg_delta_toxic']:+.4f}\")\n",
        "        print(f\"    Avg Delta Safe:  {row['avg_delta_safe']:+.4f}\")\n",
        "\n",
        "    # Rekomendacja najlepszego alpha\n",
        "    optimal_rows = df_summary[\n",
        "        (df_summary[\"success_rate\"] > 80) & (df_summary[\"side_effect_rate\"] < 5)\n",
        "    ]\n",
        "    if len(optimal_rows) > 0:\n",
        "        best_idx = optimal_rows[\"success_rate\"].idxmax()\n",
        "        best_alpha = df_summary.loc[best_idx, \"alpha\"]\n",
        "        print(f\"\\n  >>> REKOMENDACJA: Najlepsza wartosc alpha = {best_alpha}\")\n",
        "    else:\n",
        "        print(f\"\\n  >>> UWAGA: Zadna wartosc alpha nie spelnia kryteriow optymalnosci.\")\n",
        "\n",
        "    # --- Szczegolowe przyklady ---\n",
        "    if not df_details.empty:\n",
        "        # Przyklad detoksykacji (toksyczne z najwieksza negatywna delta)\n",
        "        print(\"\\n=== PRZYKLADY DETOKSYKACJI (TOXIC -> SAFE) ===\")\n",
        "        best_alpha_for_examples = df_summary.loc[df_summary[\"success_rate\"].idxmax(), \"alpha\"]\n",
        "        toxic_examples = df_details[\n",
        "            (df_details[\"label\"] == \"TOXIC\") & (df_details[\"alpha\"] == best_alpha_for_examples)\n",
        "        ].nsmallest(5, \"delta\")\n",
        "\n",
        "        for _, row in toxic_examples.iterrows():\n",
        "            print(f\"\\n  Tekst: {row['text'][:120]}\")\n",
        "            print(f\"  P(toxic) przed: {row['prob_before']:.4f} -> po: {row['prob_after']:.4f} \"\n",
        "                  f\"(delta: {row['delta']:+.4f}) [{row['status']}]\")\n",
        "\n",
        "        # Przyklady efektow ubocznych\n",
        "        print(f\"\\n=== PRZYKLADY EFEKTOW UBOCZNYCH (SAFE -> TOXIC) ===\")\n",
        "        side_effects = df_details[\n",
        "            (df_details[\"label\"] == \"SAFE\") & (df_details[\"status\"] == \"SIDE-EFFECT\")\n",
        "        ]\n",
        "\n",
        "        if len(side_effects) > 0:\n",
        "            for _, row in side_effects.head(5).iterrows():\n",
        "                print(f\"\\n  [alpha={row['alpha']}] Tekst: {row['text'][:120]}\")\n",
        "                print(f\"  P(toxic) przed: {row['prob_before']:.4f} -> po: {row['prob_after']:.4f} \"\n",
        "                      f\"(delta: {row['delta']:+.4f}) [SIDE-EFFECT]\")\n",
        "        else:\n",
        "            print(\"  Brak efektow ubocznych dla zadnej wartosci alpha.\")\n",
        "\n",
        "        # Porownanie jednego tekstu dla roznych alpha\n",
        "        print(f\"\\n=== POROWNANIE JEDNEGO TEKSTU DLA ROZNYCH ALPHA ===\")\n",
        "        toxic_texts = df_details[df_details[\"label\"] == \"TOXIC\"]\n",
        "        if len(toxic_texts) > 0:\n",
        "            sample_text = toxic_texts[\"text\"].iloc[0]\n",
        "            text_comparison = df_details[df_details[\"text\"] == sample_text][\n",
        "                [\"alpha\", \"prob_before\", \"prob_after\", \"delta\", \"status\"]\n",
        "            ]\n",
        "            print(f\"\\n  Tekst: {sample_text[:120]}\")\n",
        "            print(f\"  P(toxic) przed steering: {text_comparison['prob_before'].iloc[0]:.4f}\")\n",
        "            print(f\"  Po steering:\")\n",
        "            for _, row in text_comparison.iterrows():\n",
        "                print(f\"    alpha={row['alpha']:+.1f}: P(toxic)={row['prob_after']:.4f} \"\n",
        "                      f\"(delta: {row['delta']:+.4f}) [{row['status']}]\")\n",
        "\n",
        "    print(\"\\nCzesc 3 zakonczona.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_steering_viz"
      },
      "outputs": [],
      "source": [
        "visualize_steering(df_steering, df_steering_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary_header"
      },
      "source": [
        "---\n",
        "## Czesc 4: Podsumowanie i Wizualizacja Finalna\n",
        "\n",
        "Sekcja zbierajaca wyniki ze wszystkich trzech modulow eksperymentalnych.\n",
        "Generuje finalne wykresy do pracy magisterskiej w stylu akademickim.\n",
        "\n",
        "Wejscia:\n",
        "- `df_fidelity` (Czesc 1) - Comprehensiveness i Sufficiency dla IG vs IxG\n",
        "- `df_stability` (Czesc 2) - Korelacja Spearmana i Semantic Overlap dla Standard IG vs SmoothGrad\n",
        "- `df_steering`, `df_steering_details` (Czesc 3) - Success Rate i Side Effects per alpha\n",
        "\n",
        "Wyjscia:\n",
        "- Zbiorcza tabela metryk (`summary_all_metrics.csv`)\n",
        "- Wykres zbiorczy 3-w-1 (`summary_overview.png`)\n",
        "- Osobne wykresy per modul (`fig_fidelity.png`, `fig_stability.png`, `fig_steering.png`)\n",
        "- Automatyczne wnioski tekstowe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "summary_functions"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4. PODSUMOWANIE I WIZUALIZACJA FINALNA\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def _setup_academic_style():\n",
        "    \"\"\"\n",
        "    Konfiguruje styl akademicki matplotlib dla wykresow do pracy magisterskiej.\n",
        "\n",
        "    Ustawia styl 'seaborn-v0_8-paper' (z fallbackiem), zwiekszone fonty,\n",
        "    rozdzielczosc 300 DPI i palete przyjazna daltonistom.\n",
        "\n",
        "    Zwraca:\n",
        "        dict: Paleta kolorow z kluczami 'blue', 'red', 'orange', 'light_blue'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        plt.style.use('seaborn-v0_8-paper')\n",
        "    except OSError:\n",
        "        try:\n",
        "            plt.style.use('seaborn-paper')\n",
        "        except OSError:\n",
        "            pass  # Uzyj domyslnego stylu\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 11,\n",
        "        'axes.labelsize': 12,\n",
        "        'axes.titlesize': 13,\n",
        "        'xtick.labelsize': 10,\n",
        "        'ytick.labelsize': 10,\n",
        "        'legend.fontsize': 10,\n",
        "        'figure.dpi': 300,\n",
        "        'savefig.dpi': 300,\n",
        "        'savefig.bbox': 'tight',\n",
        "    })\n",
        "\n",
        "    # Paleta przyjazna daltonistom (ColorBrewer)\n",
        "    return {\n",
        "        'blue': '#2c7bb6',\n",
        "        'red': '#d7191c',\n",
        "        'orange': '#fdae61',\n",
        "        'light_blue': '#abd9e9',\n",
        "    }\n",
        "\n",
        "\n",
        "def _build_metrics_table(df_fidelity, df_stability, df_steering):\n",
        "    \"\"\"\n",
        "    Buduje zbiorcza tabele metryk ze wszystkich modulow eksperymentalnych.\n",
        "\n",
        "    Argumenty:\n",
        "        df_fidelity: DataFrame z Czesci 1 (kolumny: ig/ixg_comprehensiveness/sufficiency)\n",
        "        df_stability: DataFrame z Czesci 2 (kolumny: para_type, spearman_*, sem_overlap_*)\n",
        "        df_steering: DataFrame z Czesci 3 (kolumny: alpha, success_rate, side_effect_rate, avg_delta_*)\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z kolumnami: Module, Metric, Value\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # --- Czesc 1: Fidelity ---\n",
        "    for method, prefix in [(\"IG\", \"ig\"), (\"IxG\", \"ixg\")]:\n",
        "        for metric_name, col_suffix in [(\"Comprehensiveness\", \"comprehensiveness\"), (\"Sufficiency\", \"sufficiency\")]:\n",
        "            col = f\"{prefix}_{col_suffix}\"\n",
        "            mean_val = df_fidelity[col].mean()\n",
        "            std_val = df_fidelity[col].std()\n",
        "            rows.append({\n",
        "                \"Module\": \"Fidelity\",\n",
        "                \"Metric\": f\"{method} {metric_name}\",\n",
        "                \"Value\": f\"{mean_val:.4f} +/- {std_val:.4f}\",\n",
        "                \"Mean\": mean_val,\n",
        "                \"Std\": std_val,\n",
        "            })\n",
        "\n",
        "    # --- Czesc 2: Stability ---\n",
        "    for para_type, para_label in [(\"mistral\", \"Mistral\"), (\"synonym\", \"Synonym\")]:\n",
        "        df_sub = df_stability[df_stability[\"para_type\"] == para_type]\n",
        "        if df_sub.empty:\n",
        "            continue\n",
        "        for method, col in [(\"Std IG\", \"spearman_standard_ig\"), (\"SmoothGrad\", \"spearman_smoothgrad\")]:\n",
        "            mean_val = df_sub[col].mean()\n",
        "            std_val = df_sub[col].std()\n",
        "            rows.append({\n",
        "                \"Module\": \"Stability\",\n",
        "                \"Metric\": f\"Spearman {method} ({para_label})\",\n",
        "                \"Value\": f\"{mean_val:.4f} +/- {std_val:.4f}\",\n",
        "                \"Mean\": mean_val,\n",
        "                \"Std\": std_val,\n",
        "            })\n",
        "        for method, col in [(\"Std IG\", \"sem_overlap_standard_ig\"), (\"SmoothGrad\", \"sem_overlap_smoothgrad\")]:\n",
        "            mean_val = df_sub[col].mean()\n",
        "            std_val = df_sub[col].std()\n",
        "            rows.append({\n",
        "                \"Module\": \"Stability\",\n",
        "                \"Metric\": f\"Sem. Overlap {method} ({para_label})\",\n",
        "                \"Value\": f\"{mean_val:.4f} +/- {std_val:.4f}\",\n",
        "                \"Mean\": mean_val,\n",
        "                \"Std\": std_val,\n",
        "            })\n",
        "\n",
        "    # --- Czesc 3: Steering ---\n",
        "    best_idx = df_steering[\"success_rate\"].idxmax()\n",
        "    best = df_steering.loc[best_idx]\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Best Alpha\", \"Value\": f\"{best['alpha']:.1f}\", \"Mean\": best['alpha'], \"Std\": 0.0})\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Success Rate (best)\", \"Value\": f\"{best['success_rate']:.2f}%\", \"Mean\": best['success_rate'], \"Std\": 0.0})\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Side Effect Rate (best)\", \"Value\": f\"{best['side_effect_rate']:.2f}%\", \"Mean\": best['side_effect_rate'], \"Std\": 0.0})\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Avg Delta Toxic (best)\", \"Value\": f\"{best['avg_delta_toxic']:+.4f}\", \"Mean\": best['avg_delta_toxic'], \"Std\": 0.0})\n",
        "    rows.append({\"Module\": \"Steering\", \"Metric\": \"Avg Delta Safe (best)\", \"Value\": f\"{best['avg_delta_safe']:+.4f}\", \"Mean\": best['avg_delta_safe'], \"Std\": 0.0})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def _plot_fidelity(ax, df_fidelity, colors):\n",
        "    \"\"\"\n",
        "    Rysuje wykres Fidelity: Comprehensiveness i Sufficiency dla IG vs IxG.\n",
        "\n",
        "    Argumenty:\n",
        "        ax: Matplotlib axes do rysowania\n",
        "        df_fidelity: DataFrame z Czesci 1\n",
        "        colors: dict z paleta kolorow\n",
        "    \"\"\"\n",
        "    metrics = ['Comprehensiveness', 'Sufficiency']\n",
        "    ig_means = [\n",
        "        df_fidelity['ig_comprehensiveness'].mean(),\n",
        "        df_fidelity['ig_sufficiency'].mean(),\n",
        "    ]\n",
        "    ig_stds = [\n",
        "        df_fidelity['ig_comprehensiveness'].std(),\n",
        "        df_fidelity['ig_sufficiency'].std(),\n",
        "    ]\n",
        "    ixg_means = [\n",
        "        df_fidelity['ixg_comprehensiveness'].mean(),\n",
        "        df_fidelity['ixg_sufficiency'].mean(),\n",
        "    ]\n",
        "    ixg_stds = [\n",
        "        df_fidelity['ixg_comprehensiveness'].std(),\n",
        "        df_fidelity['ixg_sufficiency'].std(),\n",
        "    ]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    ax.bar(x - width / 2, ig_means, width, yerr=ig_stds, label='IG',\n",
        "           color=colors['blue'], capsize=4, error_kw={'linewidth': 1})\n",
        "    ax.bar(x + width / 2, ixg_means, width, yerr=ixg_stds, label='IxG',\n",
        "           color=colors['orange'], capsize=4, error_kw={'linewidth': 1})\n",
        "\n",
        "    ax.set_ylabel('Spadek prawdopodobienstwa')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.legend()\n",
        "    ax.set_title('(a) Fidelity: IG vs IxG')\n",
        "    ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "\n",
        "\n",
        "def _plot_stability(ax, df_stability, colors):\n",
        "    \"\"\"\n",
        "    Rysuje wykres Stability: Spearman i Sem. Overlap dla Standard IG vs SmoothGrad.\n",
        "\n",
        "    Argumenty:\n",
        "        ax: Matplotlib axes do rysowania\n",
        "        df_stability: DataFrame z Czesci 2\n",
        "        colors: dict z paleta kolorow\n",
        "    \"\"\"\n",
        "    groups = []\n",
        "    std_ig_vals = []\n",
        "    smooth_vals = []\n",
        "\n",
        "    for para_type, para_label in [('mistral', 'Mistral'), ('synonym', 'Synonym')]:\n",
        "        df_sub = df_stability[df_stability['para_type'] == para_type]\n",
        "        if df_sub.empty:\n",
        "            continue\n",
        "        groups.append(f'Spearman\\n({para_label})')\n",
        "        std_ig_vals.append(df_sub['spearman_standard_ig'].mean())\n",
        "        smooth_vals.append(df_sub['spearman_smoothgrad'].mean())\n",
        "\n",
        "        groups.append(f'Sem.Overlap\\n({para_label})')\n",
        "        std_ig_vals.append(df_sub['sem_overlap_standard_ig'].mean())\n",
        "        smooth_vals.append(df_sub['sem_overlap_smoothgrad'].mean())\n",
        "\n",
        "    if not groups:\n",
        "        ax.text(0.5, 0.5, 'Brak danych', ha='center', va='center', fontsize=12)\n",
        "        return\n",
        "\n",
        "    x = np.arange(len(groups))\n",
        "    width = 0.35\n",
        "\n",
        "    ax.bar(x - width / 2, std_ig_vals, width, label='Standard IG',\n",
        "           color=colors['red'], alpha=0.85)\n",
        "    ax.bar(x + width / 2, smooth_vals, width, label='SmoothGrad',\n",
        "           color=colors['light_blue'])\n",
        "\n",
        "    ax.set_ylabel('Wartosc metryki')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(groups, fontsize=8)\n",
        "    ax.legend()\n",
        "    ax.set_title('(b) Stability: Std IG vs SmoothGrad')\n",
        "    ax.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
        "\n",
        "\n",
        "def _plot_steering(ax, df_steering, colors):\n",
        "    \"\"\"\n",
        "    Rysuje wykres Steering: Success Rate i Side Effect Rate per alpha.\n",
        "\n",
        "    Argumenty:\n",
        "        ax: Matplotlib axes do rysowania\n",
        "        df_steering: DataFrame z Czesci 3\n",
        "        colors: dict z paleta kolorow\n",
        "    \"\"\"\n",
        "    x = np.arange(len(df_steering))\n",
        "    alpha_labels = [f'{a:.0f}' for a in df_steering['alpha']]\n",
        "    width = 0.35\n",
        "\n",
        "    bars1 = ax.bar(x - width / 2, df_steering['success_rate'], width,\n",
        "                   label='Success Rate', color=colors['blue'])\n",
        "    bars2 = ax.bar(x + width / 2, df_steering['side_effect_rate'], width,\n",
        "                   label='Side Effect Rate', color=colors['red'])\n",
        "\n",
        "    ax.set_ylabel('Procent (%)')\n",
        "    ax.set_xlabel('Alpha')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(alpha_labels)\n",
        "    ax.legend()\n",
        "    ax.set_title('(c) Steering: Skutecznosc detoksykacji')\n",
        "    ax.axhline(y=80, color=colors['blue'], linestyle='--', alpha=0.4)\n",
        "    ax.axhline(y=5, color=colors['red'], linestyle='--', alpha=0.4)\n",
        "    ax.set_ylim(0, 105)\n",
        "\n",
        "    # Etykiety na slupkach\n",
        "    for bar in bars1:\n",
        "        h = bar.get_height()\n",
        "        ax.annotate(f'{h:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, h),\n",
        "                    xytext=(0, 3), textcoords='offset points', ha='center', fontsize=8)\n",
        "    for bar in bars2:\n",
        "        h = bar.get_height()\n",
        "        ax.annotate(f'{h:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, h),\n",
        "                    xytext=(0, 3), textcoords='offset points', ha='center', fontsize=8)\n",
        "\n",
        "\n",
        "def _generate_conclusions(df_fidelity, df_stability, df_steering):\n",
        "    \"\"\"\n",
        "    Generuje automatyczne wnioski tekstowe na podstawie wynikow eksperymentalnych.\n",
        "\n",
        "    Porownuje metody XAI (IG vs IxG), stabilnosc (Standard IG vs SmoothGrad)\n",
        "    oraz skutecznosc steeringu (Success Rate vs Side Effects).\n",
        "\n",
        "    Argumenty:\n",
        "        df_fidelity: DataFrame z Czesci 1\n",
        "        df_stability: DataFrame z Czesci 2\n",
        "        df_steering: DataFrame z Czesci 3\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"WNIOSKI Z EKSPERYMENTU\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # --- Wniosek 1: Fidelity ---\n",
        "    print(\"\\n--- 1. FIDELITY (Wiernosc wyjasnien) ---\")\n",
        "    ig_comp = df_fidelity['ig_comprehensiveness'].mean()\n",
        "    ixg_comp = df_fidelity['ixg_comprehensiveness'].mean()\n",
        "    ig_suff = df_fidelity['ig_sufficiency'].mean()\n",
        "    ixg_suff = df_fidelity['ixg_sufficiency'].mean()\n",
        "\n",
        "    comp_winner = 'IG' if ig_comp > ixg_comp else 'IxG'\n",
        "    comp_diff = abs(ig_comp - ixg_comp)\n",
        "    print(f\"  Comprehensiveness: {comp_winner} jest lepsza o {comp_diff:.4f}\")\n",
        "    print(f\"    IG={ig_comp:.4f}, IxG={ixg_comp:.4f}\")\n",
        "    print(f\"    (wyzsza wartosc = metoda lepiej identyfikuje kluczowe tokeny)\")\n",
        "\n",
        "    suff_winner = 'IG' if ig_suff < ixg_suff else 'IxG'\n",
        "    suff_diff = abs(ig_suff - ixg_suff)\n",
        "    print(f\"  Sufficiency: {suff_winner} jest lepsza o {suff_diff:.4f}\")\n",
        "    print(f\"    IG={ig_suff:.4f}, IxG={ixg_suff:.4f}\")\n",
        "    print(f\"    (nizsza wartosc = same top tokeny wystarczaja do utrzymania predykcji)\")\n",
        "\n",
        "    # --- Wniosek 2: Stability ---\n",
        "    print(\"\\n--- 2. STABILITY (Stabilnosc wyjasnien) ---\")\n",
        "    for para_type, para_label in [('mistral', 'Mistral'), ('synonym', 'Synonimy')]:\n",
        "        df_sub = df_stability[df_stability['para_type'] == para_type]\n",
        "        if df_sub.empty:\n",
        "            print(f\"  {para_label}: Brak danych.\")\n",
        "            continue\n",
        "\n",
        "        sp_std = df_sub['spearman_standard_ig'].mean()\n",
        "        sp_smooth = df_sub['spearman_smoothgrad'].mean()\n",
        "        sp_improvement = sp_smooth - sp_std\n",
        "        sp_pct = (sp_improvement / abs(sp_std) * 100) if sp_std != 0 else 0\n",
        "\n",
        "        so_std = df_sub['sem_overlap_standard_ig'].mean()\n",
        "        so_smooth = df_sub['sem_overlap_smoothgrad'].mean()\n",
        "        so_improvement = so_smooth - so_std\n",
        "        so_pct = (so_improvement / abs(so_std) * 100) if so_std != 0 else 0\n",
        "\n",
        "        print(f\"  Parafrazy {para_label} (n={len(df_sub)}):\")\n",
        "        print(f\"    Spearman: Std IG={sp_std:.4f}, SmoothGrad={sp_smooth:.4f} \"\n",
        "              f\"(poprawa: {sp_improvement:+.4f}, {sp_pct:+.1f}%)\")\n",
        "        print(f\"    Sem.Overlap: Std IG={so_std:.4f}, SmoothGrad={so_smooth:.4f} \"\n",
        "              f\"(poprawa: {so_improvement:+.4f}, {so_pct:+.1f}%)\")\n",
        "\n",
        "    # --- Wniosek 3: Steering ---\n",
        "    print(\"\\n--- 3. STEERING (Sterowanie reprezentacjami) ---\")\n",
        "    best_idx = df_steering['success_rate'].idxmax()\n",
        "    best = df_steering.loc[best_idx]\n",
        "    optimal = best['success_rate'] > 80 and best['side_effect_rate'] < 5\n",
        "\n",
        "    print(f\"  Najlepsza wartosc alpha: {best['alpha']:.1f}\")\n",
        "    print(f\"    Success Rate:     {best['success_rate']:.2f}% {'(cel >80% SPELNIONY)' if best['success_rate'] > 80 else '(cel >80% NIESPELNIONY)'}\")\n",
        "    print(f\"    Side Effect Rate: {best['side_effect_rate']:.2f}% {'(cel <5% SPELNIONY)' if best['side_effect_rate'] < 5 else '(cel <5% NIESPELNIONY)'}\")\n",
        "    print(f\"    Avg Delta Toxic:  {best['avg_delta_toxic']:+.4f}\")\n",
        "    print(f\"    Avg Delta Safe:   {best['avg_delta_safe']:+.4f}\")\n",
        "\n",
        "    if optimal:\n",
        "        print(f\"\\n  KONKLUZJA: Steering z alpha={best['alpha']:.1f} skutecznie detoksykuje model\")\n",
        "        print(f\"  bez retrenowania, przy minimalnych efektach ubocznych.\")\n",
        "    else:\n",
        "        print(f\"\\n  KONKLUZJA: Steering wymaga dalszego dostrojenia parametru alpha.\")\n",
        "        print(f\"  Zaden z testowanych wariantow nie spelnia jednoczesnie obu kryteriow.\")\n",
        "\n",
        "    # --- Podsumowanie globalne ---\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"PODSUMOWANIE GLOBALNE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"  1. Najlepsza metoda XAI pod wzgledem fidelity: {comp_winner} (Comprehensiveness)\")\n",
        "    print(f\"  2. SmoothGrad poprawia stabilnosc wyjasnien w porownaniu do Standard IG\")\n",
        "    print(f\"  3. Steering {'skutecznie' if optimal else 'czesciowo'} naprawia model bez retrenowania\")\n",
        "\n",
        "\n",
        "def generate_summary_report(df_fidelity, df_stability, df_steering, df_steering_details):\n",
        "    \"\"\"\n",
        "    Generuje kompletny raport podsumowujacy z wykresami w stylu akademickim.\n",
        "\n",
        "    Tworzy:\n",
        "        - Zbiorcza tabele metryk (CSV)\n",
        "        - Wykres zbiorczy 3-w-1 (PNG, 300 DPI, bez suptitle dla LaTeX)\n",
        "        - Osobne wykresy per modul (PNG, 300 DPI)\n",
        "        - Automatyczne wnioski tekstowe\n",
        "\n",
        "    Argumenty:\n",
        "        df_fidelity: DataFrame z Czesci 1\n",
        "        df_stability: DataFrame z Czesci 2\n",
        "        df_steering: DataFrame z Czesci 3 (summary)\n",
        "        df_steering_details: DataFrame z Czesci 3 (per-sample)\n",
        "\n",
        "    Zwraca:\n",
        "        DataFrame z tabela zbiorczych metryk\n",
        "    \"\"\"\n",
        "    print(\"\\n>>> [CZESC 4] Generowanie raportu podsumowujacego...\")\n",
        "\n",
        "    # Styl akademicki\n",
        "    colors = _setup_academic_style()\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.1 TABELA ZBIORCZA METRYK\n",
        "    # -----------------------------------------------\n",
        "    print(\"    Budowanie zbiorczej tabeli metryk...\")\n",
        "    df_metrics = _build_metrics_table(df_fidelity, df_stability, df_steering)\n",
        "    df_metrics.to_csv(f\"{RESULTS_DIR}/summary_all_metrics.csv\", index=False)\n",
        "\n",
        "    print(\"\\n=== ZBIORCZA TABELA METRYK ===\")\n",
        "    print(df_metrics[['Module', 'Metric', 'Value']].to_string(index=False))\n",
        "    print(f\"\\n    Tabela zapisana do: {RESULTS_DIR}/summary_all_metrics.csv\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.2 WYKRES ZBIORCZY 3-W-1\n",
        "    # -----------------------------------------------\n",
        "    print(\"\\n    Generowanie wykresu zbiorczego...\")\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    _plot_fidelity(axes[0], df_fidelity, colors)\n",
        "    _plot_stability(axes[1], df_stability, colors)\n",
        "    _plot_steering(axes[2], df_steering, colors)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/summary_overview.png\")\n",
        "    plt.show()\n",
        "    print(f\"    Wykres zbiorczy zapisany: {RESULTS_DIR}/summary_overview.png\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.3 OSOBNE WYKRESY PER MODUL\n",
        "    # -----------------------------------------------\n",
        "    print(\"\\n    Generowanie osobnych wykresow...\")\n",
        "\n",
        "    # Fig Fidelity\n",
        "    fig_f, ax_f = plt.subplots(figsize=(6, 4.5))\n",
        "    _plot_fidelity(ax_f, df_fidelity, colors)\n",
        "    ax_f.set_title('')  # Bez tytulu - LaTeX caption\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fig_fidelity.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Fig Stability\n",
        "    fig_s, ax_s = plt.subplots(figsize=(7, 4.5))\n",
        "    _plot_stability(ax_s, df_stability, colors)\n",
        "    ax_s.set_title('')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fig_stability.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Fig Steering\n",
        "    fig_st, ax_st = plt.subplots(figsize=(6, 4.5))\n",
        "    _plot_steering(ax_st, df_steering, colors)\n",
        "    ax_st.set_title('')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/fig_steering.png\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"    Osobne wykresy zapisane: fig_fidelity.png, fig_stability.png, fig_steering.png\")\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # 4.4 AUTOMATYCZNE WNIOSKI\n",
        "    # -----------------------------------------------\n",
        "    _generate_conclusions(df_fidelity, df_stability, df_steering)\n",
        "\n",
        "    print(\"\\nCzesc 4 zakonczona.\")\n",
        "    return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_summary"
      },
      "outputs": [],
      "source": [
        "df_metrics = generate_summary_report(df_fidelity, df_stability, df_steering, df_steering_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "file_inventory"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# 4.5 LISTA WYGENEROWANYCH PLIKOW\n",
        "# ===================================================\n",
        "\n",
        "\n",
        "def list_generated_files():\n",
        "    \"\"\"\n",
        "    Wyswietla liste wszystkich plikow wygenerowanych przez notebook\n",
        "    w katalogu RESULTS_DIR z informacja o rozmiarze i typie.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"WYGENEROWANE PLIKI\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    type_map = {\n",
        "        '.csv': 'CSV',\n",
        "        '.png': 'PNG',\n",
        "        '.npy': 'NumPy',\n",
        "        '.txt': 'Text',\n",
        "    }\n",
        "\n",
        "    total_size = 0\n",
        "    file_count = 0\n",
        "\n",
        "    files = sorted(os.listdir(RESULTS_DIR))\n",
        "    for f in files:\n",
        "        file_path = os.path.join(RESULTS_DIR, f)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_kb = os.path.getsize(file_path) / 1024\n",
        "            total_size += size_kb\n",
        "            file_count += 1\n",
        "            ext = os.path.splitext(f)[1].lower()\n",
        "            ftype = type_map.get(ext, ext)\n",
        "            print(f\"  {f:40s} {ftype:6s} {size_kb:8.2f} KB\")\n",
        "\n",
        "    print(f\"\\n  {'RAZEM':40s} {'':6s} {total_size:8.2f} KB ({file_count} plikow)\")\n",
        "    print(f\"\\n  Katalog wynikow: {RESULTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_file_inventory"
      },
      "outputs": [],
      "source": [
        "list_generated_files()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}